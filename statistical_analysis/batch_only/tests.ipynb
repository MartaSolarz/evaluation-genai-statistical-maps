{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Batch-only Analysis\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "2. M1-M5 tests: Main Effects (model, country, license, map usage type, task type)\n",
    "3. C1-C6 tests: Map Characteristics (graphical complexity, spatial aggregation level, map source, viz technique, symbol scaling, diagram structure)\n",
    "4. I1-I4 tests: Interactions (model×map usage type, graphical complexity×map usage type, model×graphical complexity, model×spatial aggregation level)\n",
    "5. P1 test: Profiles"
   ],
   "id": "23957d30276d0b08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.001172Z",
     "start_time": "2025-10-05T13:48:00.568534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import shapiro, kruskal, mannwhitneyu, levene, t, sem, rankdata, chi2, kendalltau\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_batch = pd.read_csv('../../data/cleaned_data/data_batch_only.csv', index_col='answer_id')\n",
    "\n",
    "df_batch.sample(5)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               model_name provider_country licence_type         map_code  \\\n",
       "answer_id                                                                  \n",
       "389                GPT o3              USA         paid   MULTI-G-INST-2   \n",
       "411                GPT o3              USA         paid    MULTI-D-ATL-1   \n",
       "66                 GPT-4o              USA         paid  SINGLE-D-INST-4   \n",
       "1818          DeepSeek-R1            China         free    MULTI-G-ATL-2   \n",
       "449        Gemini 1.5 Pro              USA         paid   SINGLE-G-ATL-2   \n",
       "\n",
       "          graphical_complexity viz_technique        symbol_scaling  \\\n",
       "answer_id                                                            \n",
       "389                       high           NaN  proportional symbols   \n",
       "411                       high           NaN     graduated symbols   \n",
       "66                         low    choropleth                   NaN   \n",
       "1818                      high           NaN     graduated symbols   \n",
       "449                        low     cartogram                   NaN   \n",
       "\n",
       "          diagram_structure          map_source  question_id nuts_level  \\\n",
       "answer_id                                                                 \n",
       "389              structural  statistical_office          101    country   \n",
       "411                 uniform               atlas          123     region   \n",
       "66                      NaN  statistical_office           66     region   \n",
       "1818             structural               atlas           90    country   \n",
       "449                     NaN               atlas           17    country   \n",
       "\n",
       "           map_usage_type       task_type test_mode  score  \n",
       "answer_id                                                   \n",
       "389               reading          locate     batch   0.00  \n",
       "411              analysis       associate     batch   4.55  \n",
       "66                reading  retrieve value     batch   0.00  \n",
       "1818       interpretation         predict     batch   4.25  \n",
       "449        interpretation    cause/effect     batch   3.80  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>provider_country</th>\n",
       "      <th>licence_type</th>\n",
       "      <th>map_code</th>\n",
       "      <th>graphical_complexity</th>\n",
       "      <th>viz_technique</th>\n",
       "      <th>symbol_scaling</th>\n",
       "      <th>diagram_structure</th>\n",
       "      <th>map_source</th>\n",
       "      <th>question_id</th>\n",
       "      <th>nuts_level</th>\n",
       "      <th>map_usage_type</th>\n",
       "      <th>task_type</th>\n",
       "      <th>test_mode</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>GPT o3</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>MULTI-G-INST-2</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proportional symbols</td>\n",
       "      <td>structural</td>\n",
       "      <td>statistical_office</td>\n",
       "      <td>101</td>\n",
       "      <td>country</td>\n",
       "      <td>reading</td>\n",
       "      <td>locate</td>\n",
       "      <td>batch</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>GPT o3</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>MULTI-D-ATL-1</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated symbols</td>\n",
       "      <td>uniform</td>\n",
       "      <td>atlas</td>\n",
       "      <td>123</td>\n",
       "      <td>region</td>\n",
       "      <td>analysis</td>\n",
       "      <td>associate</td>\n",
       "      <td>batch</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>SINGLE-D-INST-4</td>\n",
       "      <td>low</td>\n",
       "      <td>choropleth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>statistical_office</td>\n",
       "      <td>66</td>\n",
       "      <td>region</td>\n",
       "      <td>reading</td>\n",
       "      <td>retrieve value</td>\n",
       "      <td>batch</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>DeepSeek-R1</td>\n",
       "      <td>China</td>\n",
       "      <td>free</td>\n",
       "      <td>MULTI-G-ATL-2</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated symbols</td>\n",
       "      <td>structural</td>\n",
       "      <td>atlas</td>\n",
       "      <td>90</td>\n",
       "      <td>country</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>predict</td>\n",
       "      <td>batch</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Gemini 1.5 Pro</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>SINGLE-G-ATL-2</td>\n",
       "      <td>low</td>\n",
       "      <td>cartogram</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>atlas</td>\n",
       "      <td>17</td>\n",
       "      <td>country</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>cause/effect</td>\n",
       "      <td>batch</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.173755Z",
     "start_time": "2025-10-05T13:48:01.168301Z"
    }
   },
   "cell_type": "code",
   "source": "df_batch.info()",
   "id": "c602d04327beb32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1728 entries, 1 to 2304\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   model_name            1728 non-null   object \n",
      " 1   provider_country      1728 non-null   object \n",
      " 2   licence_type          1728 non-null   object \n",
      " 3   map_code              1728 non-null   object \n",
      " 4   graphical_complexity  1728 non-null   object \n",
      " 5   viz_technique         864 non-null    object \n",
      " 6   symbol_scaling        1188 non-null   object \n",
      " 7   diagram_structure     1188 non-null   object \n",
      " 8   map_source            1728 non-null   object \n",
      " 9   question_id           1728 non-null   int64  \n",
      " 10  nuts_level            1728 non-null   object \n",
      " 11  map_usage_type        1728 non-null   object \n",
      " 12  task_type             1728 non-null   object \n",
      " 13  test_mode             1728 non-null   object \n",
      " 14  score                 1728 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 216.0+ KB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.199318Z",
     "start_time": "2025-10-05T13:48:01.196410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_reading = df_batch[df_batch['map_usage_type'] == 'reading']\n",
    "df_analysis = df_batch[df_batch['map_usage_type'] == 'analysis']\n",
    "df_interpretation = df_batch[df_batch['map_usage_type'] == 'interpretation']"
   ],
   "id": "74ed0fa7c5055014",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Exploratory Data Analysis",
   "id": "5af6b68eab04b3bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.251468Z",
     "start_time": "2025-10-05T13:48:01.248668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"1. BASIC INFORMATION\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total observations: {len(df_batch)}\")\n",
    "print(f\"Unique questions: {df_batch['question_id'].nunique()}\")\n",
    "print(f\"Unique models: {df_batch['model_name'].nunique()}\")\n",
    "print(f\"Models analyzed: {', '.join(sorted(df_batch['model_name'].unique()))}\")\n",
    "\n",
    "# Check if test_mode is all 'batch'\n",
    "test_modes = df_batch['test_mode'].unique()\n",
    "print(f\"\\nTest mode(s): {', '.join(test_modes)}\")\n",
    "if len(test_modes) > 1 or test_modes[0] != 'batch':\n",
    "    print(\"WARNING: Dataset contains non-batch observations!\")"
   ],
   "id": "9bdcf53f99e4b7f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. BASIC INFORMATION\n",
      "--------------------------------------------------------------------------------\n",
      "Total observations: 1728\n",
      "Unique questions: 144\n",
      "Unique models: 12\n",
      "Models analyzed: Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, DeepSeek-R1, GPT o3, GPT-4o, Gemini 1.5 Pro, Gemma 3, Grok-3, MiniMax-01, Mistral Large, Qwen2.5-Max, Sonar\n",
      "\n",
      "Test mode(s): batch\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.288857Z",
     "start_time": "2025-10-05T13:48:01.286171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"2. MODEL DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "model_counts = df_batch['model_name'].value_counts().sort_index()\n",
    "print(\"\\nObservations per model:\")\n",
    "for model, count in model_counts.items():\n",
    "    print(f\"  {model}: {count}\")\n",
    "\n",
    "# Check balance\n",
    "balance_ratio = model_counts.max() / model_counts.min()\n",
    "print(f\"\\nBalance ratio (max/min): {balance_ratio:.2f}\")\n",
    "if balance_ratio > 2:\n",
    "    print(\"WARNING: Imbalanced design - some models have >2x observations of others\")\n",
    "else:\n",
    "    print(\"Design reasonably balanced across models\")"
   ],
   "id": "5596a470e40cdd82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. MODEL DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Observations per model:\n",
      "  Claude 3.5 Sonnet v2: 144\n",
      "  Claude 3.7 Sonnet: 144\n",
      "  DeepSeek-R1: 144\n",
      "  GPT o3: 144\n",
      "  GPT-4o: 144\n",
      "  Gemini 1.5 Pro: 144\n",
      "  Gemma 3: 144\n",
      "  Grok-3: 144\n",
      "  MiniMax-01: 144\n",
      "  Mistral Large: 144\n",
      "  Qwen2.5-Max: 144\n",
      "  Sonar: 144\n",
      "\n",
      "Balance ratio (max/min): 1.00\n",
      "Design reasonably balanced across models\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.321656Z",
     "start_time": "2025-10-05T13:48:01.315686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"3. ZERO VALUES ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "zeros_total = (df_batch['score'] == 0).sum()\n",
    "zeros_pct = (zeros_total / len(df_batch)) * 100\n",
    "print(f\"Zero values: {zeros_total} ({zeros_pct:.2f}%)\")\n",
    "\n",
    "# Zeros per model\n",
    "print(\"Zero values by model:\")\n",
    "for model in sorted(df_batch['model_name'].unique()):\n",
    "    model_data = df_batch[df_batch['model_name'] == model]\n",
    "    zeros = (model_data['score'] == 0).sum()\n",
    "    zeros_pct_model = (zeros / len(model_data)) * 100\n",
    "    print(f\"  {model}: {zeros} ({zeros_pct_model:.1f}%)\")\n",
    "\n",
    "print(\"\\nNote: Zeros represent failed responses, not missing data.\")\n",
    "print(\"All analyses include zeros as legitimate failure outcomes.\")"
   ],
   "id": "453324c340dbe922",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. ZERO VALUES ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Zero values: 458 (26.50%)\n",
      "Zero values by model:\n",
      "  Claude 3.5 Sonnet v2: 28 (19.4%)\n",
      "  Claude 3.7 Sonnet: 21 (14.6%)\n",
      "  DeepSeek-R1: 48 (33.3%)\n",
      "  GPT o3: 29 (20.1%)\n",
      "  GPT-4o: 44 (30.6%)\n",
      "  Gemini 1.5 Pro: 34 (23.6%)\n",
      "  Gemma 3: 45 (31.2%)\n",
      "  Grok-3: 36 (25.0%)\n",
      "  MiniMax-01: 47 (32.6%)\n",
      "  Mistral Large: 36 (25.0%)\n",
      "  Qwen2.5-Max: 41 (28.5%)\n",
      "  Sonar: 49 (34.0%)\n",
      "\n",
      "Note: Zeros represent failed responses, not missing data.\n",
      "All analyses include zeros as legitimate failure outcomes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.386742Z",
     "start_time": "2025-10-05T13:48:01.344189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"4. DESCRIPTIVE STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def descriptive_statistics(df, value_col, group_col=None, ci=0.95):\n",
    "    def calc_stats(series, ci_level):\n",
    "        n = len(series)\n",
    "        mean_val = series.mean()\n",
    "        sem_val = sem(series)\n",
    "        ci_low, ci_high = t.interval(ci_level, n-1, loc=mean_val, scale=sem_val)\n",
    "        stats_dict = {\n",
    "            \"M\": mean_val,\n",
    "            \"95% CI\": (ci_low, ci_high),\n",
    "            \"Mdn\": series.median(),\n",
    "            \"SD\": series.std(),\n",
    "            \"Range\": (series.min(), series.max()),\n",
    "            \"Q1\": series.quantile(0.25),\n",
    "            \"Q3\": series.quantile(0.75),\n",
    "            \"N\": n\n",
    "        }\n",
    "        return stats_dict\n",
    "\n",
    "    if group_col is None:\n",
    "        stats_overall = calc_stats(df[value_col], ci)\n",
    "        print(\"\\nOverall statistics:\")\n",
    "        print(f\"  M = {stats_overall['M']:.3f}, 95% CI = ({stats_overall['95% CI'][0]:.2f}, {stats_overall['95% CI'][1]:.2f}), \"\n",
    "              f\"Mdn = {stats_overall['Mdn']:.3f}, SD = {stats_overall['SD']:.3f}\")\n",
    "        print(f\"  Range: [{stats_overall['Range'][0]:.1f}, {stats_overall['Range'][1]:.1f}]\")\n",
    "        print(f\"  Q1 = {stats_overall['Q1']:.2f}, Q3 = {stats_overall['Q3']:.2f}\")\n",
    "    else:\n",
    "        print(f\"\\nStatistics by '{group_col}':\")\n",
    "        for group in sorted(df[group_col].unique()):\n",
    "            group_data = df[df[group_col] == group][value_col]\n",
    "            stats_group = calc_stats(group_data, ci)\n",
    "            print(f\"{group}:\")\n",
    "            print(f\"  M = {stats_group['M']:.2f}, 95% CI = ({stats_group['95% CI'][0]:.2f}, {stats_group['95% CI'][1]:.2f}), \"\n",
    "                  f\"Mdn = {stats_group['Mdn']:.2f}, SD = {stats_group['SD']:.2f}, \"\n",
    "                  f\"Range = [{stats_group['Range'][0]:.1f}, {stats_group['Range'][1]:.1f}], \"\n",
    "                  f\"Q1 = {stats_group['Q1']:.2f}, Q3 = {stats_group['Q3']:.2f}, N = {stats_group['N']}\")\n",
    "\n",
    "\n",
    "print(\"Overall dataset:\")\n",
    "descriptive_statistics(df_batch, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "descriptive_statistics(df_reading, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "descriptive_statistics(df_analysis, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "descriptive_statistics(df_interpretation, value_col='score', group_col='model_name')\n"
   ],
   "id": "655b75f3c3645ac6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. DESCRIPTIVE STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Overall dataset:\n",
      "\n",
      "Statistics by 'model_name':\n",
      "Claude 3.5 Sonnet v2:\n",
      "  M = 3.58, 95% CI = (3.27, 3.88), Mdn = 4.43, SD = 1.86, Range = [0.0, 5.0], Q1 = 3.43, Q3 = 5.00, N = 144\n",
      "Claude 3.7 Sonnet:\n",
      "  M = 3.94, 95% CI = (3.66, 4.21), Mdn = 4.53, SD = 1.68, Range = [0.0, 5.0], Q1 = 4.05, Q3 = 5.00, N = 144\n",
      "DeepSeek-R1:\n",
      "  M = 2.80, 95% CI = (2.46, 3.14), Mdn = 3.90, SD = 2.07, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 144\n",
      "GPT o3:\n",
      "  M = 3.51, 95% CI = (3.21, 3.82), Mdn = 4.30, SD = 1.84, Range = [0.0, 5.0], Q1 = 3.40, Q3 = 4.80, N = 144\n",
      "GPT-4o:\n",
      "  M = 2.98, 95% CI = (2.64, 3.32), Mdn = 4.00, SD = 2.05, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.56, N = 144\n",
      "Gemini 1.5 Pro:\n",
      "  M = 3.29, 95% CI = (2.97, 3.61), Mdn = 4.10, SD = 1.93, Range = [0.0, 5.0], Q1 = 2.41, Q3 = 4.80, N = 144\n",
      "Gemma 3:\n",
      "  M = 2.98, 95% CI = (2.64, 3.32), Mdn = 4.05, SD = 2.06, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 144\n",
      "Grok-3:\n",
      "  M = 3.35, 95% CI = (3.02, 3.68), Mdn = 4.30, SD = 2.01, Range = [0.0, 5.0], Q1 = 1.54, Q3 = 5.00, N = 144\n",
      "MiniMax-01:\n",
      "  M = 2.88, 95% CI = (2.54, 3.21), Mdn = 4.00, SD = 2.06, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 144\n",
      "Mistral Large:\n",
      "  M = 3.33, 95% CI = (3.00, 3.65), Mdn = 4.28, SD = 1.98, Range = [0.0, 5.0], Q1 = 2.06, Q3 = 4.80, N = 144\n",
      "Qwen2.5-Max:\n",
      "  M = 2.95, 95% CI = (2.62, 3.28), Mdn = 3.90, SD = 2.00, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.51, N = 144\n",
      "Sonar:\n",
      "  M = 2.65, 95% CI = (2.31, 2.98), Mdn = 3.67, SD = 2.02, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.33, N = 144\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "\n",
      "Statistics by 'model_name':\n",
      "Claude 3.5 Sonnet v2:\n",
      "  M = 3.36, 95% CI = (2.69, 4.03), Mdn = 5.00, SD = 2.30, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "Claude 3.7 Sonnet:\n",
      "  M = 3.50, 95% CI = (2.87, 4.14), Mdn = 4.70, SD = 2.17, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "DeepSeek-R1:\n",
      "  M = 2.53, 95% CI = (1.84, 3.22), Mdn = 3.95, SD = 2.38, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.93, N = 48\n",
      "GPT o3:\n",
      "  M = 3.17, 95% CI = (2.51, 3.83), Mdn = 4.50, SD = 2.28, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "GPT-4o:\n",
      "  M = 2.09, 95% CI = (1.39, 2.79), Mdn = 0.00, SD = 2.41, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.93, N = 48\n",
      "Gemini 1.5 Pro:\n",
      "  M = 3.10, 95% CI = (2.43, 3.78), Mdn = 4.60, SD = 2.33, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "Gemma 3:\n",
      "  M = 2.05, 95% CI = (1.37, 2.74), Mdn = 0.00, SD = 2.36, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 48\n",
      "Grok-3:\n",
      "  M = 3.42, 95% CI = (2.78, 4.07), Mdn = 4.70, SD = 2.23, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "MiniMax-01:\n",
      "  M = 2.23, 95% CI = (1.54, 2.91), Mdn = 0.00, SD = 2.36, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.60, N = 48\n",
      "Mistral Large:\n",
      "  M = 3.24, 95% CI = (2.57, 3.92), Mdn = 4.70, SD = 2.32, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "Qwen2.5-Max:\n",
      "  M = 2.78, 95% CI = (2.09, 3.48), Mdn = 4.50, SD = 2.40, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "Sonar:\n",
      "  M = 2.46, 95% CI = (1.79, 3.13), Mdn = 3.90, SD = 2.31, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.58, N = 48\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "\n",
      "Statistics by 'model_name':\n",
      "Claude 3.5 Sonnet v2:\n",
      "  M = 3.64, 95% CI = (3.11, 4.16), Mdn = 4.30, SD = 1.81, Range = [0.0, 5.0], Q1 = 3.90, Q3 = 4.85, N = 48\n",
      "Claude 3.7 Sonnet:\n",
      "  M = 3.89, 95% CI = (3.41, 4.38), Mdn = 4.50, SD = 1.67, Range = [0.0, 5.0], Q1 = 4.10, Q3 = 4.90, N = 48\n",
      "DeepSeek-R1:\n",
      "  M = 2.50, 95% CI = (1.88, 3.13), Mdn = 3.85, SD = 2.16, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.30, N = 48\n",
      "GPT o3:\n",
      "  M = 3.51, 95% CI = (3.00, 4.02), Mdn = 4.10, SD = 1.76, Range = [0.0, 5.0], Q1 = 3.60, Q3 = 4.62, N = 48\n",
      "GPT-4o:\n",
      "  M = 2.94, 95% CI = (2.37, 3.51), Mdn = 3.74, SD = 1.97, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.35, N = 48\n",
      "Gemini 1.5 Pro:\n",
      "  M = 3.07, 95% CI = (2.48, 3.66), Mdn = 4.10, SD = 2.04, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 48\n",
      "Gemma 3:\n",
      "  M = 3.12, 95% CI = (2.55, 3.69), Mdn = 4.10, SD = 1.95, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.30, N = 48\n",
      "Grok-3:\n",
      "  M = 3.23, 95% CI = (2.64, 3.81), Mdn = 4.20, SD = 2.02, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 48\n",
      "MiniMax-01:\n",
      "  M = 2.44, 95% CI = (1.83, 3.05), Mdn = 3.88, SD = 2.10, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.30, N = 48\n",
      "Mistral Large:\n",
      "  M = 2.90, 95% CI = (2.29, 3.51), Mdn = 4.10, SD = 2.11, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 48\n",
      "Qwen2.5-Max:\n",
      "  M = 2.62, 95% CI = (2.01, 3.22), Mdn = 3.83, SD = 2.08, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.30, N = 48\n",
      "Sonar:\n",
      "  M = 2.54, 95% CI = (1.95, 3.12), Mdn = 3.70, SD = 2.02, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.06, N = 48\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "\n",
      "Statistics by 'model_name':\n",
      "Claude 3.5 Sonnet v2:\n",
      "  M = 3.73, 95% CI = (3.33, 4.14), Mdn = 4.17, SD = 1.40, Range = [0.0, 5.0], Q1 = 3.43, Q3 = 4.75, N = 48\n",
      "Claude 3.7 Sonnet:\n",
      "  M = 4.41, 95% CI = (4.17, 4.65), Mdn = 4.70, SD = 0.84, Range = [0.0, 5.0], Q1 = 4.04, Q3 = 5.00, N = 48\n",
      "DeepSeek-R1:\n",
      "  M = 3.37, 95% CI = (2.93, 3.80), Mdn = 3.98, SD = 1.50, Range = [0.0, 5.0], Q1 = 2.70, Q3 = 4.26, N = 48\n",
      "GPT o3:\n",
      "  M = 3.86, 95% CI = (3.48, 4.24), Mdn = 4.25, SD = 1.32, Range = [0.0, 5.0], Q1 = 3.68, Q3 = 4.71, N = 48\n",
      "GPT-4o:\n",
      "  M = 3.90, 95% CI = (3.56, 4.24), Mdn = 4.25, SD = 1.17, Range = [0.0, 5.0], Q1 = 3.88, Q3 = 4.50, N = 48\n",
      "Gemini 1.5 Pro:\n",
      "  M = 3.69, 95% CI = (3.33, 4.05), Mdn = 4.03, SD = 1.25, Range = [0.0, 5.0], Q1 = 3.23, Q3 = 4.51, N = 48\n",
      "Gemma 3:\n",
      "  M = 3.75, 95% CI = (3.34, 4.17), Mdn = 4.12, SD = 1.43, Range = [0.0, 5.0], Q1 = 3.84, Q3 = 4.59, N = 48\n",
      "Grok-3:\n",
      "  M = 3.40, 95% CI = (2.88, 3.92), Mdn = 4.05, SD = 1.79, Range = [0.0, 5.0], Q1 = 2.98, Q3 = 4.75, N = 48\n",
      "MiniMax-01:\n",
      "  M = 3.96, 95% CI = (3.66, 4.25), Mdn = 4.25, SD = 1.03, Range = [0.0, 5.0], Q1 = 3.79, Q3 = 4.51, N = 48\n",
      "Mistral Large:\n",
      "  M = 3.84, 95% CI = (3.47, 4.21), Mdn = 4.05, SD = 1.28, Range = [0.0, 5.0], Q1 = 3.75, Q3 = 4.55, N = 48\n",
      "Qwen2.5-Max:\n",
      "  M = 3.46, 95% CI = (3.09, 3.83), Mdn = 3.98, SD = 1.28, Range = [0.0, 5.0], Q1 = 2.73, Q3 = 4.30, N = 48\n",
      "Sonar:\n",
      "  M = 2.95, 95% CI = (2.46, 3.44), Mdn = 3.48, SD = 1.69, Range = [0.0, 5.0], Q1 = 2.38, Q3 = 4.25, N = 48\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.409516Z",
     "start_time": "2025-10-05T13:48:01.398071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"5. DISTRIBUTION TESTS\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nShapiro-Wilk normality tests:\")\n",
    "\n",
    "def shapiro_test_by_group(df, value_col, group_col=None, min_n=3):\n",
    "    if group_col:\n",
    "        print(f\"Shapiro-Wilk test for '{value_col}' by '{group_col}':\\n\")\n",
    "        for group in sorted(df[group_col].unique()):\n",
    "            group_data = df[df[group_col] == group][value_col]\n",
    "            n = len(group_data)\n",
    "            if n >= min_n:\n",
    "                stat, p = shapiro(group_data)\n",
    "                normal_status = \"normal\" if p > 0.05 else \"non-normal\"\n",
    "                print(f\"  {group}: W = {stat:.4f}, p = {p:.4f} ({normal_status}, n={n})\")\n",
    "            else:\n",
    "                print(f\"  {group}: insufficient data for test (n={n})\")\n",
    "\n",
    "    # Overall test\n",
    "    overall_data = df[value_col]\n",
    "    stat_overall, p_overall = shapiro(overall_data)\n",
    "    overall_status = \"normal\" if p_overall > 0.05 else \"non-normal\"\n",
    "    print(f\"\\nOverall: W = {stat_overall:.4f}, p = {p_overall:.4f} ({overall_status}, n={len(overall_data)})\\n\")\n",
    "\n",
    "    if p_overall < 0.05:\n",
    "        print(\"Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\")\n",
    "    else:\n",
    "        print(\"Conclusion: Parametric tests may be appropriate, but verify assumptions\")\n",
    "\n",
    "print(\"Overall dataset:\")\n",
    "shapiro_test_by_group(df_batch, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "shapiro_test_by_group(df_reading, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "shapiro_test_by_group(df_analysis, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "shapiro_test_by_group(df_interpretation, value_col='score', group_col='model_name')"
   ],
   "id": "f29bceeb7a743132",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. DISTRIBUTION TESTS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Shapiro-Wilk normality tests:\n",
      "Overall dataset:\n",
      "Shapiro-Wilk test for 'score' by 'model_name':\n",
      "\n",
      "  Claude 3.5 Sonnet v2: W = 0.7025, p = 0.0000 (non-normal, n=144)\n",
      "  Claude 3.7 Sonnet: W = 0.6148, p = 0.0000 (non-normal, n=144)\n",
      "  DeepSeek-R1: W = 0.7589, p = 0.0000 (non-normal, n=144)\n",
      "  GPT o3: W = 0.7015, p = 0.0000 (non-normal, n=144)\n",
      "  GPT-4o: W = 0.7487, p = 0.0000 (non-normal, n=144)\n",
      "  Gemini 1.5 Pro: W = 0.7427, p = 0.0000 (non-normal, n=144)\n",
      "  Gemma 3: W = 0.7256, p = 0.0000 (non-normal, n=144)\n",
      "  Grok-3: W = 0.7086, p = 0.0000 (non-normal, n=144)\n",
      "  MiniMax-01: W = 0.7379, p = 0.0000 (non-normal, n=144)\n",
      "  Mistral Large: W = 0.7081, p = 0.0000 (non-normal, n=144)\n",
      "  Qwen2.5-Max: W = 0.7779, p = 0.0000 (non-normal, n=144)\n",
      "  Sonar: W = 0.7874, p = 0.0000 (non-normal, n=144)\n",
      "\n",
      "Overall: W = 0.7372, p = 0.0000 (non-normal, n=1728)\n",
      "\n",
      "Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "Shapiro-Wilk test for 'score' by 'model_name':\n",
      "\n",
      "  Claude 3.5 Sonnet v2: W = 0.6226, p = 0.0000 (non-normal, n=48)\n",
      "  Claude 3.7 Sonnet: W = 0.6263, p = 0.0000 (non-normal, n=48)\n",
      "  DeepSeek-R1: W = 0.6956, p = 0.0000 (non-normal, n=48)\n",
      "  GPT o3: W = 0.6644, p = 0.0000 (non-normal, n=48)\n",
      "  GPT-4o: W = 0.6634, p = 0.0000 (non-normal, n=48)\n",
      "  Gemini 1.5 Pro: W = 0.6571, p = 0.0000 (non-normal, n=48)\n",
      "  Gemma 3: W = 0.6686, p = 0.0000 (non-normal, n=48)\n",
      "  Grok-3: W = 0.6282, p = 0.0000 (non-normal, n=48)\n",
      "  MiniMax-01: W = 0.6856, p = 0.0000 (non-normal, n=48)\n",
      "  Mistral Large: W = 0.6387, p = 0.0000 (non-normal, n=48)\n",
      "  Qwen2.5-Max: W = 0.6798, p = 0.0000 (non-normal, n=48)\n",
      "  Sonar: W = 0.7113, p = 0.0000 (non-normal, n=48)\n",
      "\n",
      "Overall: W = 0.6786, p = 0.0000 (non-normal, n=576)\n",
      "\n",
      "Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "Shapiro-Wilk test for 'score' by 'model_name':\n",
      "\n",
      "  Claude 3.5 Sonnet v2: W = 0.6578, p = 0.0000 (non-normal, n=48)\n",
      "  Claude 3.7 Sonnet: W = 0.6108, p = 0.0000 (non-normal, n=48)\n",
      "  DeepSeek-R1: W = 0.7222, p = 0.0000 (non-normal, n=48)\n",
      "  GPT o3: W = 0.6984, p = 0.0000 (non-normal, n=48)\n",
      "  GPT-4o: W = 0.7656, p = 0.0000 (non-normal, n=48)\n",
      "  Gemini 1.5 Pro: W = 0.7282, p = 0.0000 (non-normal, n=48)\n",
      "  Gemma 3: W = 0.6967, p = 0.0000 (non-normal, n=48)\n",
      "  Grok-3: W = 0.6980, p = 0.0000 (non-normal, n=48)\n",
      "  MiniMax-01: W = 0.7078, p = 0.0000 (non-normal, n=48)\n",
      "  Mistral Large: W = 0.7169, p = 0.0000 (non-normal, n=48)\n",
      "  Qwen2.5-Max: W = 0.7433, p = 0.0000 (non-normal, n=48)\n",
      "  Sonar: W = 0.7528, p = 0.0000 (non-normal, n=48)\n",
      "\n",
      "Overall: W = 0.7255, p = 0.0000 (non-normal, n=576)\n",
      "\n",
      "Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "Shapiro-Wilk test for 'score' by 'model_name':\n",
      "\n",
      "  Claude 3.5 Sonnet v2: W = 0.7920, p = 0.0000 (non-normal, n=48)\n",
      "  Claude 3.7 Sonnet: W = 0.6629, p = 0.0000 (non-normal, n=48)\n",
      "  DeepSeek-R1: W = 0.7944, p = 0.0000 (non-normal, n=48)\n",
      "  GPT o3: W = 0.7098, p = 0.0000 (non-normal, n=48)\n",
      "  GPT-4o: W = 0.6932, p = 0.0000 (non-normal, n=48)\n",
      "  Gemini 1.5 Pro: W = 0.8249, p = 0.0000 (non-normal, n=48)\n",
      "  Gemma 3: W = 0.6956, p = 0.0000 (non-normal, n=48)\n",
      "  Grok-3: W = 0.7609, p = 0.0000 (non-normal, n=48)\n",
      "  MiniMax-01: W = 0.7414, p = 0.0000 (non-normal, n=48)\n",
      "  Mistral Large: W = 0.6804, p = 0.0000 (non-normal, n=48)\n",
      "  Qwen2.5-Max: W = 0.8512, p = 0.0000 (non-normal, n=48)\n",
      "  Sonar: W = 0.8569, p = 0.0000 (non-normal, n=48)\n",
      "\n",
      "Overall: W = 0.7656, p = 0.0000 (non-normal, n=576)\n",
      "\n",
      "Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.438825Z",
     "start_time": "2025-10-05T13:48:01.428460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"6. HOMOGENEITY OF VARIANCE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def levene_test(df, value_col, group_col):\n",
    "    groups = [df[df[group_col] == g][value_col].values for g in sorted(df[group_col].unique())]\n",
    "\n",
    "    stat, p = levene(*groups)\n",
    "\n",
    "    print(f\"Levene's test for '{value_col}' by '{group_col}':\")\n",
    "    print(f\"W = {stat:.4f}, p = {p:.4f}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        print(\"Conclusion: Variances are heterogeneous - use Welch's ANOVA or non-parametric tests\")\n",
    "    else:\n",
    "        print(\"Conclusion: Variances are homogeneous\")\n",
    "\n",
    "levene_test(df_batch, value_col='score', group_col='model_name')\n",
    "levene_test(df_reading, value_col='score', group_col='model_name')\n",
    "levene_test(df_analysis, value_col='score', group_col='model_name')\n",
    "levene_test(df_interpretation, value_col='score', group_col='model_name')\n"
   ],
   "id": "ba111cd6b380bb9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. HOMOGENEITY OF VARIANCE\n",
      "--------------------------------------------------------------------------------\n",
      "Levene's test for 'score' by 'model_name':\n",
      "W = 2.7026, p = 0.0019\n",
      "Conclusion: Variances are heterogeneous - use Welch's ANOVA or non-parametric tests\n",
      "Levene's test for 'score' by 'model_name':\n",
      "W = 0.8068, p = 0.6334\n",
      "Conclusion: Variances are homogeneous\n",
      "Levene's test for 'score' by 'model_name':\n",
      "W = 1.5696, p = 0.1037\n",
      "Conclusion: Variances are homogeneous\n",
      "Levene's test for 'score' by 'model_name':\n",
      "W = 2.4537, p = 0.0053\n",
      "Conclusion: Variances are heterogeneous - use Welch's ANOVA or non-parametric tests\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.460044Z",
     "start_time": "2025-10-05T13:48:01.454576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"7. MODEL CHARACTERISTICS DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nProvider country distribution:\")\n",
    "country_dist = df_batch.groupby(['model_name', 'provider_country']).size().unstack(fill_value=0)\n",
    "print(country_dist)\n",
    "\n",
    "print(\"\\nLicense distribution:\")\n",
    "license_dist = df_batch.groupby(['model_name', 'licence_type']).size().unstack(fill_value=0)\n",
    "print(license_dist)"
   ],
   "id": "b053fa7d7d3a04a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. MODEL CHARACTERISTICS DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Provider country distribution:\n",
      "provider_country      China  France  USA\n",
      "model_name                              \n",
      "Claude 3.5 Sonnet v2      0       0  144\n",
      "Claude 3.7 Sonnet         0       0  144\n",
      "DeepSeek-R1             144       0    0\n",
      "GPT o3                    0       0  144\n",
      "GPT-4o                    0       0  144\n",
      "Gemini 1.5 Pro            0       0  144\n",
      "Gemma 3                   0       0  144\n",
      "Grok-3                    0       0  144\n",
      "MiniMax-01              144       0    0\n",
      "Mistral Large             0     144    0\n",
      "Qwen2.5-Max             144       0    0\n",
      "Sonar                     0       0  144\n",
      "\n",
      "License distribution:\n",
      "licence_type          free  paid\n",
      "model_name                      \n",
      "Claude 3.5 Sonnet v2     0   144\n",
      "Claude 3.7 Sonnet        0   144\n",
      "DeepSeek-R1            144     0\n",
      "GPT o3                   0   144\n",
      "GPT-4o                   0   144\n",
      "Gemini 1.5 Pro           0   144\n",
      "Gemma 3                144     0\n",
      "Grok-3                   0   144\n",
      "MiniMax-01             144     0\n",
      "Mistral Large            0   144\n",
      "Qwen2.5-Max            144     0\n",
      "Sonar                    0   144\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.481418Z",
     "start_time": "2025-10-05T13:48:01.477966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"8. TASK CHARACTERISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nMap usage types:\")\n",
    "print(df_batch['map_usage_type'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nGraphical complexity levels:\")\n",
    "print(df_batch['graphical_complexity'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nNUTS levels:\")\n",
    "print(df_batch['nuts_level'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nMap sources:\")\n",
    "print(df_batch['map_source'].value_counts().sort_index())"
   ],
   "id": "526e6eef3f513f55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. TASK CHARACTERISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Map usage types:\n",
      "map_usage_type\n",
      "analysis          576\n",
      "interpretation    576\n",
      "reading           576\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Graphical complexity levels:\n",
      "graphical_complexity\n",
      "high    864\n",
      "low     864\n",
      "Name: count, dtype: int64\n",
      "\n",
      "NUTS levels:\n",
      "nuts_level\n",
      "country    864\n",
      "region     864\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Map sources:\n",
      "map_source\n",
      "atlas                 864\n",
      "statistical_office    864\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Main effects",
   "id": "77c6fb1afe48413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.515200Z",
     "start_time": "2025-10-05T13:48:01.500227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# M1: Model Ranking\n",
    "# H0: All models achieve the same mean scores\n",
    "# H1: There are differences in mean scores between AI models\n",
    "\n",
    "print(\"M1: MODEL RANKING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Kruskal-Wallis test (non-parametric, >2 groups)\n",
    "model_groups = [df_batch[df_batch['model_name'] == model]['score'].values\n",
    "                for model in sorted(df_batch['model_name'].unique())]\n",
    "h_stat, p_val = kruskal(*model_groups)\n",
    "\n",
    "# Effect size: Epsilon squared\n",
    "n = len(df_batch)\n",
    "k = len(model_groups)\n",
    "epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "print(f\"Kruskal-Wallis H = {h_stat:.3f}, p = {p_val:.6f}\")\n",
    "print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "# Post-hoc Dunn test with FDR correction\n",
    "if p_val < 0.05:\n",
    "    print(\"\\nPost-hoc pairwise comparisons (Dunn test with FDR correction):\")\n",
    "    posthoc = posthoc_dunn(df_batch, val_col='score', group_col='model_name', p_adjust='fdr_bh')\n",
    "\n",
    "    # Extract significant pairs\n",
    "    sig_pairs = []\n",
    "    models = posthoc.index.tolist()\n",
    "    for i, model1 in enumerate(models):\n",
    "        for j, model2 in enumerate(models):\n",
    "            if i < j and posthoc.loc[model1, model2] < 0.05:\n",
    "                sig_pairs.append({\n",
    "                    'Model 1': model1,\n",
    "                    'Model 2': model2,\n",
    "                    'p-value': posthoc.loc[model1, model2]\n",
    "                })\n",
    "\n",
    "    if sig_pairs:\n",
    "        sig_df = pd.DataFrame(sig_pairs).sort_values('p-value')\n",
    "        print(f\"\\n{len(sig_pairs)} significant pairwise differences found:\")\n",
    "        print(sig_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant pairwise differences after FDR correction\")\n",
    "\n",
    "model_means = df_batch.groupby('model_name')['score'].agg(['mean', 'median', 'std']).sort_values('mean',\n",
    "                                                                                                   ascending=False)\n",
    "print(\"\\nModel Rankings (by mean score):\")\n",
    "for rank, (model, row) in enumerate(model_means.iterrows(), 1):\n",
    "    print(f\"{rank}. {model}: M={row['mean']:.3f}, Mdn={row['median']:.3f}, SD={row['std']:.3f}\")"
   ],
   "id": "3cf7394c39552f26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1: MODEL RANKING\n",
      "--------------------------------------------------------------------------------\n",
      "Kruskal-Wallis H = 90.453, p = 0.000000\n",
      "Effect size (ε²) = 0.046\n",
      "Significant: YES\n",
      "\n",
      "Post-hoc pairwise comparisons (Dunn test with FDR correction):\n",
      "\n",
      "32 significant pairwise differences found:\n",
      "             Model 1        Model 2      p-value\n",
      "   Claude 3.7 Sonnet          Sonar 1.352936e-10\n",
      "   Claude 3.7 Sonnet    DeepSeek-R1 8.490153e-08\n",
      "   Claude 3.7 Sonnet     MiniMax-01 1.014199e-07\n",
      "   Claude 3.7 Sonnet    Qwen2.5-Max 7.254231e-07\n",
      "   Claude 3.7 Sonnet         GPT-4o 2.173157e-06\n",
      "   Claude 3.7 Sonnet        Gemma 3 2.236691e-06\n",
      "Claude 3.5 Sonnet v2          Sonar 2.274644e-06\n",
      "              Grok-3          Sonar 2.119598e-04\n",
      "              GPT o3          Sonar 2.119598e-04\n",
      "Claude 3.5 Sonnet v2    DeepSeek-R1 2.845958e-04\n",
      "Claude 3.5 Sonnet v2     MiniMax-01 3.898157e-04\n",
      "       Mistral Large          Sonar 1.055405e-03\n",
      "   Claude 3.7 Sonnet Gemini 1.5 Pro 1.055405e-03\n",
      "Claude 3.5 Sonnet v2    Qwen2.5-Max 1.457701e-03\n",
      "Claude 3.5 Sonnet v2         GPT-4o 3.322824e-03\n",
      "   Claude 3.7 Sonnet  Mistral Large 3.472242e-03\n",
      "Claude 3.5 Sonnet v2        Gemma 3 3.472242e-03\n",
      "      Gemini 1.5 Pro          Sonar 3.506418e-03\n",
      "         DeepSeek-R1         Grok-3 6.210198e-03\n",
      "         DeepSeek-R1         GPT o3 6.223033e-03\n",
      "              Grok-3     MiniMax-01 7.755006e-03\n",
      "              GPT o3     MiniMax-01 7.797224e-03\n",
      "   Claude 3.7 Sonnet         GPT o3 1.258069e-02\n",
      "   Claude 3.7 Sonnet         Grok-3 1.266640e-02\n",
      "         DeepSeek-R1  Mistral Large 2.117918e-02\n",
      "              Grok-3    Qwen2.5-Max 2.117918e-02\n",
      "              GPT o3    Qwen2.5-Max 2.117918e-02\n",
      "          MiniMax-01  Mistral Large 2.621448e-02\n",
      "              GPT-4o         Grok-3 3.710737e-02\n",
      "              GPT o3         GPT-4o 3.744305e-02\n",
      "             Gemma 3         Grok-3 3.860593e-02\n",
      "              GPT o3        Gemma 3 3.901736e-02\n",
      "\n",
      "Model Rankings (by mean score):\n",
      "1. Claude 3.7 Sonnet: M=3.936, Mdn=4.525, SD=1.685\n",
      "2. Claude 3.5 Sonnet v2: M=3.577, Mdn=4.425, SD=1.865\n",
      "3. GPT o3: M=3.513, Mdn=4.300, SD=1.838\n",
      "4. Grok-3: M=3.351, Mdn=4.300, SD=2.008\n",
      "5. Mistral Large: M=3.328, Mdn=4.275, SD=1.979\n",
      "6. Gemini 1.5 Pro: M=3.288, Mdn=4.100, SD=1.934\n",
      "7. GPT-4o: M=2.978, Mdn=4.000, SD=2.046\n",
      "8. Gemma 3: M=2.976, Mdn=4.050, SD=2.063\n",
      "9. Qwen2.5-Max: M=2.953, Mdn=3.900, SD=1.996\n",
      "10. MiniMax-01: M=2.876, Mdn=4.000, SD=2.056\n",
      "11. DeepSeek-R1: M=2.802, Mdn=3.900, SD=2.071\n",
      "12. Sonar: M=2.648, Mdn=3.675, SD=2.021\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.545872Z",
     "start_time": "2025-10-05T13:48:01.536197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# M2: Provider Country\n",
    "# H0: Models from different countries achieve the same mean scores\n",
    "# H1: Mean scores differ by country of origin\n",
    "\n",
    "print(\"M2: PROVIDER COUNTRY\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "country_counts = df_batch['provider_country'].value_counts()\n",
    "print(f\"Country distribution: {dict(country_counts)}\")\n",
    "\n",
    "# All countries have n≥144, proceed with test\n",
    "country_groups = [df_batch[df_batch['provider_country'] == country]['score'].values\n",
    "                  for country in sorted(df_batch['provider_country'].unique())]\n",
    "h_stat, p_val = kruskal(*country_groups)\n",
    "\n",
    "n = len(df_batch)\n",
    "k = len(country_groups)\n",
    "epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "print(f\"\\nKruskal-Wallis H = {h_stat:.3f}, p = {p_val:.6f}\")\n",
    "print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "country_means = df_batch.groupby('provider_country')['score'].agg(['mean', 'std', 'count']).sort_values('mean',\n",
    "                                                                                                        ascending=False)\n",
    "print(\"\\nCountry performance:\")\n",
    "print(country_means)\n",
    "\n",
    "if p_val < 0.05:\n",
    "    posthoc = posthoc_dunn(df_batch, val_col='score', group_col='provider_country', p_adjust='fdr_bh')\n",
    "    print(\"\\nPost-hoc comparisons:\")\n",
    "    print(posthoc)\n"
   ],
   "id": "4e448419cbe30fb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M2: PROVIDER COUNTRY\n",
      "--------------------------------------------------------------------------------\n",
      "Country distribution: {'USA': 1152, 'China': 432, 'France': 144}\n",
      "\n",
      "Kruskal-Wallis H = 21.939, p = 0.000017\n",
      "Effect size (ε²) = 0.012\n",
      "Significant: YES\n",
      "\n",
      "Country performance:\n",
      "                      mean       std  count\n",
      "provider_country                           \n",
      "France            3.328299  1.979374    144\n",
      "USA               3.283247  1.967697   1152\n",
      "China             2.876910  2.037589    432\n",
      "\n",
      "Post-hoc comparisons:\n",
      "           China    France       USA\n",
      "China   1.000000  0.004172  0.000017\n",
      "France  0.004172  1.000000  0.718178\n",
      "USA     0.000017  0.718178  1.000000\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.578158Z",
     "start_time": "2025-10-05T13:48:01.571866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# M3: License Type\n",
    "# H0: Paid and free models achieve the same mean scores\n",
    "# H1: Mean scores differ between paid and free models\n",
    "\n",
    "print(\"M3: LICENSE TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "license_counts = df_batch['licence_type'].value_counts()\n",
    "print(f\"License distribution: {dict(license_counts)}\")\n",
    "\n",
    "# Mann-Whitney U test (2 groups)\n",
    "paid = df_batch[df_batch['licence_type'] == 'paid']['score'].values\n",
    "free = df_batch[df_batch['licence_type'] == 'free']['score'].values\n",
    "\n",
    "u_stat, p_val = mannwhitneyu(paid, free, alternative='two-sided')\n",
    "\n",
    "# Effect size: rank biserial correlation\n",
    "r = 1 - (2 * u_stat) / (len(paid) * len(free))\n",
    "\n",
    "print(f\"\\nMann-Whitney U = {u_stat:.3f}, p = {p_val:.6f}\")\n",
    "print(f\"Effect size (rank-biserial r) = {r:.3f}\")\n",
    "print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "license_means = df_batch.groupby('licence_type')['score'].agg(['mean', 'median', 'std', 'count'])\n",
    "print(\"\\nLicense performance:\")\n",
    "print(license_means)"
   ],
   "id": "8d9a7e75bb39c6f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M3: LICENSE TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "License distribution: {'paid': 1152, 'free': 576}\n",
      "\n",
      "Mann-Whitney U = 382221.000, p = 0.000000\n",
      "Effect size (rank-biserial r) = -0.152\n",
      "Significant: YES\n",
      "\n",
      "License performance:\n",
      "                  mean  median       std  count\n",
      "licence_type                                   \n",
      "free          2.901780    4.00  2.042590    576\n",
      "paid          3.327235    4.25  1.953572   1152\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.615777Z",
     "start_time": "2025-10-05T13:48:01.606808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# M4: Map Usage Type\n",
    "# H0: Map usage types do not affect mean scores\n",
    "# H1: Mean scores differ between map usage types\n",
    "\n",
    "print(\"M4: MAP USAGE TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "category_counts = df_batch['map_usage_type'].value_counts()\n",
    "print(f\"Category distribution: {dict(category_counts)}\")\n",
    "\n",
    "category_groups = [df_batch[df_batch['map_usage_type'] == cat]['score'].values\n",
    "                   for cat in sorted(df_batch['map_usage_type'].unique())]\n",
    "h_stat, p_val = kruskal(*category_groups)\n",
    "\n",
    "n = len(df_batch)\n",
    "k = len(category_groups)\n",
    "epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "print(f\"\\nKruskal-Wallis H = {h_stat:.2f}, p = {p_val:.6f}\")\n",
    "print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "category_means = df_batch.groupby('map_usage_type')['score'].agg(['mean', 'median', 'std']).sort_values('mean',\n",
    "                                                                                                           ascending=False)\n",
    "print(\"\\nMap usage type performance:\")\n",
    "print(category_means)\n",
    "\n",
    "if p_val < 0.05:\n",
    "    posthoc = posthoc_dunn(df_batch, val_col='score', group_col='map_usage_type', p_adjust='fdr_bh')\n",
    "    print(\"\\nPost-hoc comparisons:\")\n",
    "    print(posthoc)"
   ],
   "id": "6ea4c31eaf195828",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M4: MAP USAGE TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "Category distribution: {'reading': 576, 'analysis': 576, 'interpretation': 576}\n",
      "\n",
      "Kruskal-Wallis H = 15.19, p = 0.000503\n",
      "Effect size (ε²) = 0.008\n",
      "Significant: YES\n",
      "\n",
      "Map usage type performance:\n",
      "                    mean  median       std\n",
      "map_usage_type                            \n",
      "interpretation  3.693316    4.05  1.385971\n",
      "analysis        3.033247    4.10  2.012549\n",
      "reading         2.829688    4.50  2.356468\n",
      "\n",
      "Post-hoc comparisons:\n",
      "                analysis  interpretation   reading\n",
      "analysis        1.000000        0.004564  0.000716\n",
      "interpretation  0.004564        1.000000  0.477183\n",
      "reading         0.000716        0.477183  1.000000\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.647368Z",
     "start_time": "2025-10-05T13:48:01.634049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# M5: Task Type\n",
    "# H0: There are no significant differences in model performance across different task types.\n",
    "# H1: At least one task type differs significantly in performance compared to the others.\n",
    "\n",
    "print(\"M5: TASK TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def report_significant_pairs(posthoc_df, alpha_levels=[0.05, 0.01, 0.001]):\n",
    "    sig_pairs = []\n",
    "\n",
    "    for i, row in enumerate(posthoc_df.index):\n",
    "        for j, col in enumerate(posthoc_df.columns):\n",
    "            if j <= i:  # skip duplicates and diagonal\n",
    "                continue\n",
    "            p = posthoc_df.loc[row, col]\n",
    "            if p < alpha_levels[0]:\n",
    "                if p < alpha_levels[2]:\n",
    "                    level = \"< 0.001\"\n",
    "                elif p < alpha_levels[1]:\n",
    "                    level = \"< 0.01\"\n",
    "                else:\n",
    "                    level = \"< 0.05\"\n",
    "                sig_pairs.append((row, col, p, level))\n",
    "\n",
    "    if not sig_pairs:\n",
    "        print(\"No statistically significant differences found.\")\n",
    "    else:\n",
    "        print(\"Significant post-hoc differences:\")\n",
    "        for a, b, p, lvl in sorted(sig_pairs, key=lambda x: x[2]):\n",
    "            print(f\"  {a} vs {b} — p = {p:.6f} ({lvl})\")\n",
    "\n",
    "mode_counts = df_batch['task_type'].value_counts()\n",
    "print(f\"Task type distribution:\\n{mode_counts}\\n\")\n",
    "\n",
    "# Check for small groups\n",
    "if mode_counts.min() >= 20:\n",
    "    mode_groups = [df_batch[df_batch['task_type'] == mode]['score'].values\n",
    "                   for mode in sorted(df_batch['task_type'].unique())]\n",
    "    h_stat, p_val = kruskal(*mode_groups)\n",
    "\n",
    "    n = len(df_batch)\n",
    "    k = len(mode_groups)\n",
    "    epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "    print(f\"Kruskal-Wallis H = {h_stat:.3f}, p = {p_val:.6f}\")\n",
    "    print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "    print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "    mode_means = df_batch.groupby('task_type')['score'].agg(['mean', 'median', 'std', 'count']).sort_values('mean',\n",
    "                                                                                                                ascending=False)\n",
    "    print(\"\\nTask type performance:\")\n",
    "    print(mode_means)\n",
    "\n",
    "    if p_val < 0.05:\n",
    "        posthoc = posthoc_dunn(df_batch, val_col='score', group_col='task_type', p_adjust='fdr_bh')\n",
    "        print(\"\\nPost-hoc comparisons (showing p < 0.05):\")\n",
    "        print(posthoc)\n",
    "        report_significant_pairs(posthoc)\n",
    "else:\n",
    "    print(\"WARNING: Some groups have n < 20. Consider grouping or skip test.\")"
   ],
   "id": "227432e178a4623c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5: TASK TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "Task type distribution:\n",
      "task_type\n",
      "identify          192\n",
      "locate            192\n",
      "retrieve value    192\n",
      "compare           192\n",
      "cluster           192\n",
      "associate         192\n",
      "interpret         192\n",
      "cause/effect      192\n",
      "predict           192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal-Wallis H = 100.070, p = 0.000000\n",
      "Effect size (ε²) = 0.054\n",
      "Significant: YES\n",
      "\n",
      "Task type performance:\n",
      "                    mean  median       std  count\n",
      "task_type                                        \n",
      "cause/effect    3.847656   4.050  1.088184    192\n",
      "predict         3.818750   4.250  1.402611    192\n",
      "identify        3.590104   4.900  2.144970    192\n",
      "interpret       3.413542   4.000  1.585231    192\n",
      "compare         3.313932   4.300  1.928545    192\n",
      "associate       3.244922   4.100  1.930893    192\n",
      "locate          2.658854   4.300  2.365729    192\n",
      "cluster         2.540885   3.825  2.092346    192\n",
      "retrieve value  2.240104   0.000  2.357833    192\n",
      "\n",
      "Post-hoc comparisons (showing p < 0.05):\n",
      "                   associate  cause/effect       cluster   compare  \\\n",
      "associate       1.000000e+00      0.625748  1.091421e-03  0.687850   \n",
      "cause/effect    6.257481e-01      1.000000  1.134510e-04  0.896800   \n",
      "cluster         1.091421e-03      0.000113  1.000000e+00  0.000186   \n",
      "compare         6.878505e-01      0.896800  1.864893e-04  1.000000   \n",
      "identify        6.337239e-07      0.000011  2.124835e-17  0.000006   \n",
      "interpret       6.539071e-01      0.310075  6.642416e-03  0.388053   \n",
      "locate          9.286506e-01      0.653907  8.387094e-04  0.736383   \n",
      "predict         8.196845e-02      0.251028  2.999391e-07  0.201189   \n",
      "retrieve value  5.845602e-02      0.012203  2.302253e-01  0.018648   \n",
      "\n",
      "                    identify     interpret        locate       predict  \\\n",
      "associate       6.337239e-07  6.539071e-01  9.286506e-01  8.196845e-02   \n",
      "cause/effect    1.127766e-05  3.100749e-01  6.539071e-01  2.510285e-01   \n",
      "cluster         2.124835e-17  6.642416e-03  8.387094e-04  2.999391e-07   \n",
      "compare         5.771698e-06  3.880531e-01  7.363831e-01  2.011890e-01   \n",
      "identify        1.000000e+00  4.324394e-08  8.627934e-07  1.926866e-03   \n",
      "interpret       4.324394e-08  1.000000e+00  6.257481e-01  2.277559e-02   \n",
      "locate          8.627934e-07  6.257481e-01  1.000000e+00  9.626615e-02   \n",
      "predict         1.926866e-03  2.277559e-02  9.626615e-02  1.000000e+00   \n",
      "retrieve value  1.255138e-12  1.761248e-01  4.903040e-02  1.378714e-04   \n",
      "\n",
      "                retrieve value  \n",
      "associate         5.845602e-02  \n",
      "cause/effect      1.220257e-02  \n",
      "cluster           2.302253e-01  \n",
      "compare           1.864833e-02  \n",
      "identify          1.255138e-12  \n",
      "interpret         1.761248e-01  \n",
      "locate            4.903040e-02  \n",
      "predict           1.378714e-04  \n",
      "retrieve value    1.000000e+00  \n",
      "Significant post-hoc differences:\n",
      "  cluster vs identify — p = 0.000000 (< 0.001)\n",
      "  identify vs retrieve value — p = 0.000000 (< 0.001)\n",
      "  identify vs interpret — p = 0.000000 (< 0.001)\n",
      "  cluster vs predict — p = 0.000000 (< 0.001)\n",
      "  associate vs identify — p = 0.000001 (< 0.001)\n",
      "  identify vs locate — p = 0.000001 (< 0.001)\n",
      "  compare vs identify — p = 0.000006 (< 0.001)\n",
      "  cause/effect vs identify — p = 0.000011 (< 0.001)\n",
      "  cause/effect vs cluster — p = 0.000113 (< 0.001)\n",
      "  predict vs retrieve value — p = 0.000138 (< 0.001)\n",
      "  cluster vs compare — p = 0.000186 (< 0.001)\n",
      "  cluster vs locate — p = 0.000839 (< 0.001)\n",
      "  associate vs cluster — p = 0.001091 (< 0.01)\n",
      "  identify vs predict — p = 0.001927 (< 0.01)\n",
      "  cluster vs interpret — p = 0.006642 (< 0.01)\n",
      "  cause/effect vs retrieve value — p = 0.012203 (< 0.05)\n",
      "  compare vs retrieve value — p = 0.018648 (< 0.05)\n",
      "  interpret vs predict — p = 0.022776 (< 0.05)\n",
      "  locate vs retrieve value — p = 0.049030 (< 0.05)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Map Characteristics",
   "id": "6c46cb9a19f7d963"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.669787Z",
     "start_time": "2025-10-05T13:48:01.666887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mann_whitney_analysis(df, group_col, value_col, group1=None, group2=None):\n",
    "    unique_groups = df[group_col].unique()\n",
    "\n",
    "    if group1 is None or group2 is None:\n",
    "        if len(unique_groups) != 2:\n",
    "            raise ValueError(f\"{group_col} must have exactly two unique groups if group1/group2 are not specified.\")\n",
    "        group1, group2 = unique_groups\n",
    "\n",
    "    group1_values = df[df[group_col] == group1][value_col].values\n",
    "    group2_values = df[df[group_col] == group2][value_col].values\n",
    "\n",
    "    # Mann-Whitney U test\n",
    "    u_stat, p_val = mannwhitneyu(group1_values, group2_values, alternative='two-sided')\n",
    "\n",
    "    # Rank-biserial effect size\n",
    "    r = 1 - (2 * u_stat) / (len(group1_values) * len(group2_values))\n",
    "\n",
    "    # Descriptive stats\n",
    "    group_stats = df.groupby(group_col)[value_col].agg(['mean', 'median', 'std', 'count'])\n",
    "\n",
    "    # Output\n",
    "    print(f\"\\n{group_col} distribution: {dict(df[group_col].value_counts())}\")\n",
    "    print(f\"\\nMann-Whitney U test between '{group1}' and '{group2}':\")\n",
    "    print(f\"U = {u_stat:.3f}, p = {p_val:.6f}\")\n",
    "    print(f\"Effect size (rank-biserial r) = {r:.3f}\")\n",
    "    print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    print(group_stats)"
   ],
   "id": "4cab846e124d5719",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.704005Z",
     "start_time": "2025-10-05T13:48:01.693081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C1: Map Graphical Complexity\n",
    "# H0: Map graphical complexity does not affect mean scores\n",
    "# H1: Mean scores differ between low-complex and high-complex maps\n",
    "\n",
    "print(\"C1: MAP GRAPHICAL COMPLEXITY\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "mann_whitney_analysis(df_batch, group_col='graphical_complexity', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "mann_whitney_analysis(df_reading, group_col='graphical_complexity', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "mann_whitney_analysis(df_analysis, group_col='graphical_complexity', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "mann_whitney_analysis(df_interpretation, group_col='graphical_complexity', value_col='score')"
   ],
   "id": "e71238945a741908",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1: MAP GRAPHICAL COMPLEXITY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "\n",
      "graphical_complexity distribution: {'low': 864, 'high': 864}\n",
      "\n",
      "Mann-Whitney U test between 'low' and 'high':\n",
      "U = 420971.000, p = 0.000003\n",
      "Effect size (rank-biserial r) = -0.128\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "graphical_complexity                                   \n",
      "high                  2.930787     4.0  2.086586    864\n",
      "low                   3.440046     4.3  1.861930    864\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "\n",
      "graphical_complexity distribution: {'low': 288, 'high': 288}\n",
      "\n",
      "Mann-Whitney U test between 'low' and 'high':\n",
      "U = 48043.500, p = 0.000514\n",
      "Effect size (rank-biserial r) = -0.158\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "graphical_complexity                                   \n",
      "high                  2.440625     3.9  2.405333    288\n",
      "low                   3.218750     4.5  2.244062    288\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "\n",
      "graphical_complexity distribution: {'low': 288, 'high': 288}\n",
      "\n",
      "Mann-Whitney U test between 'low' and 'high':\n",
      "U = 48051.500, p = 0.000812\n",
      "Effect size (rank-biserial r) = -0.159\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "graphical_complexity                                   \n",
      "high                  2.678472    3.85  2.133876    288\n",
      "low                   3.388021    4.10  1.819006    288\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "\n",
      "graphical_complexity distribution: {'low': 288, 'high': 288}\n",
      "\n",
      "Mann-Whitney U test between 'low' and 'high':\n",
      "U = 43094.500, p = 0.415771\n",
      "Effect size (rank-biserial r) = -0.039\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "graphical_complexity                                   \n",
      "high                  3.673264   4.050  1.376456    288\n",
      "low                   3.713368   4.225  1.397529    288\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.731116Z",
     "start_time": "2025-10-05T13:48:01.720657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C2 Spatial aggregation level\n",
    "# H0: Territorial level does not affect mean scores\n",
    "# H1: Mean scores differ between country and region level\n",
    "\n",
    "print(\"C2: SPATIAL AGGREGATION LEVEL\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "mann_whitney_analysis(df_batch, group_col='nuts_level', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "mann_whitney_analysis(df_reading, group_col='nuts_level', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "mann_whitney_analysis(df_analysis, group_col='nuts_level', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "mann_whitney_analysis(df_interpretation, group_col='nuts_level', value_col='score')"
   ],
   "id": "62c62a7c586d788c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2: SPATIAL AGGREGATION LEVEL\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "\n",
      "nuts_level distribution: {'country': 864, 'region': 864}\n",
      "\n",
      "Mann-Whitney U test between 'country' and 'region':\n",
      "U = 392809.500, p = 0.055964\n",
      "Effect size (rank-biserial r) = -0.052\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                mean  median       std  count\n",
      "nuts_level                                   \n",
      "country     3.276736    4.10  1.954428    864\n",
      "region      3.094097    4.05  2.028290    864\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "\n",
      "nuts_level distribution: {'country': 288, 'region': 288}\n",
      "\n",
      "Mann-Whitney U test between 'country' and 'region':\n",
      "U = 46759.000, p = 0.005201\n",
      "Effect size (rank-biserial r) = -0.127\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                mean  median       std  count\n",
      "nuts_level                                   \n",
      "country     3.045833     4.5  2.326289    288\n",
      "region      2.613542     4.3  2.370622    288\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "\n",
      "nuts_level distribution: {'country': 288, 'region': 288}\n",
      "\n",
      "Mann-Whitney U test between 'country' and 'region':\n",
      "U = 45577.500, p = 0.036664\n",
      "Effect size (rank-biserial r) = -0.099\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                mean  median       std  count\n",
      "nuts_level                                   \n",
      "country     3.254861    4.10  1.896558    288\n",
      "region      2.811632    4.05  2.102218    288\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "\n",
      "nuts_level distribution: {'country': 288, 'region': 288}\n",
      "\n",
      "Mann-Whitney U test between 'country' and 'region':\n",
      "U = 37466.000, p = 0.044472\n",
      "Effect size (rank-biserial r) = 0.097\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                mean  median       std  count\n",
      "nuts_level                                   \n",
      "country     3.529514    4.05  1.536013    288\n",
      "region      3.857118    4.20  1.198057    288\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.762377Z",
     "start_time": "2025-10-05T13:48:01.752087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C3: Map Source\n",
    "# H0: Map source does not affect mean scores\n",
    "# H1: Mean scores differ by map source\n",
    "\n",
    "print(\"C3: MAP SOURCE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "mann_whitney_analysis(df_batch, group_col='map_source', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "mann_whitney_analysis(df_reading, group_col='map_source', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "mann_whitney_analysis(df_analysis, group_col='map_source', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "mann_whitney_analysis(df_interpretation, group_col='map_source', value_col='score')"
   ],
   "id": "b16fa00373c570b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: MAP SOURCE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "\n",
      "map_source distribution: {'atlas': 864, 'statistical_office': 864}\n",
      "\n",
      "Mann-Whitney U test between 'atlas' and 'statistical_office':\n",
      "U = 365969.500, p = 0.477000\n",
      "Effect size (rank-biserial r) = 0.020\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                        mean  median       std  count\n",
      "map_source                                           \n",
      "atlas               3.105208     4.1  2.053629    864\n",
      "statistical_office  3.265625     4.1  1.928775    864\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "\n",
      "map_source distribution: {'atlas': 288, 'statistical_office': 288}\n",
      "\n",
      "Mann-Whitney U test between 'atlas' and 'statistical_office':\n",
      "U = 38704.500, p = 0.143587\n",
      "Effect size (rank-biserial r) = 0.067\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                        mean  median       std  count\n",
      "map_source                                           \n",
      "atlas               2.668056     4.4  2.386275    288\n",
      "statistical_office  2.991319     4.5  2.319158    288\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "\n",
      "map_source distribution: {'atlas': 288, 'statistical_office': 288}\n",
      "\n",
      "Mann-Whitney U test between 'atlas' and 'statistical_office':\n",
      "U = 43039.500, p = 0.425092\n",
      "Effect size (rank-biserial r) = -0.038\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                        mean  median       std  count\n",
      "map_source                                           \n",
      "atlas               3.037674    4.10  2.039373    288\n",
      "statistical_office  3.028819    4.05  1.988904    288\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "\n",
      "map_source distribution: {'atlas': 288, 'statistical_office': 288}\n",
      "\n",
      "Mann-Whitney U test between 'atlas' and 'statistical_office':\n",
      "U = 41781.500, p = 0.876798\n",
      "Effect size (rank-biserial r) = -0.007\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                        mean  median       std  count\n",
      "map_source                                           \n",
      "atlas               3.609896   4.075  1.541515    288\n",
      "statistical_office  3.776736   4.050  1.207597    288\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.784675Z",
     "start_time": "2025-10-05T13:48:01.780386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_categorical_effect(df, group_col, value_col='score', min_group_size=20, do_posthoc=True):\n",
    "    df_sub = df[df[group_col].notna() & (df[group_col] != '')].copy()\n",
    "    print(f\"Available observations: {len(df_sub)}\")\n",
    "\n",
    "    if len(df_sub) == 0:\n",
    "        print(\"No data available for analysis.\")\n",
    "        return\n",
    "\n",
    "    group_counts = df_sub[group_col].value_counts()\n",
    "    print(f\"{group_col} distribution:\\n{group_counts}\\n\")\n",
    "\n",
    "    if len(group_counts) < 2 or group_counts.min() < min_group_size:\n",
    "        print(f\"Insufficient data (need ≥{min_group_size} per group).\")\n",
    "        return\n",
    "\n",
    "    groups = [df_sub[df_sub[group_col] == g][value_col].values for g in sorted(df_sub[group_col].unique())]\n",
    "\n",
    "    if len(groups) == 2:\n",
    "        u_stat, p_val = mannwhitneyu(groups[0], groups[1], alternative='two-sided')\n",
    "        r = 1 - (2 * u_stat) / (len(groups[0]) * len(groups[1]))\n",
    "        print(f\"Mann–Whitney U = {u_stat:.3f}, p = {p_val:.6f}\")\n",
    "        print(f\"Effect size (rank-biserial r) = {r:.3f}\")\n",
    "        print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "    else:\n",
    "        h_stat, p_val = kruskal(*groups)\n",
    "        n, k = len(df_sub), len(groups)\n",
    "        epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "        print(f\"Kruskal–Wallis H = {h_stat:.3f}, p = {p_val:.6f}\")\n",
    "        print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "        print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "        if p_val < 0.05 and do_posthoc:\n",
    "            posthoc = posthoc_dunn(df_sub, val_col=value_col, group_col=group_col, p_adjust='fdr_bh')\n",
    "            print(\"\\nPost-hoc Dunn test (adjusted p-values < 0.05):\")\n",
    "            sig_pairs = []\n",
    "            for i, row in enumerate(posthoc.index):\n",
    "                for j, col in enumerate(posthoc.columns):\n",
    "                    if j <= i:\n",
    "                        continue\n",
    "                    p = posthoc.loc[row, col]\n",
    "                    if p < 0.05:\n",
    "                        sig_pairs.append((row, col, p))\n",
    "            if not sig_pairs:\n",
    "                print(\"No significant post-hoc differences.\")\n",
    "            else:\n",
    "                for a, b, p in sorted(sig_pairs, key=lambda x: x[2]):\n",
    "                    print(f\"  {a} vs {b} — p = {p:.6f}\")\n",
    "\n",
    "    desc = df_sub.groupby(group_col)[value_col].agg(['mean', 'median', 'std', 'count']).sort_values('mean', ascending=False)\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    print(desc)"
   ],
   "id": "dd76e59b7f9baa",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.822033Z",
     "start_time": "2025-10-05T13:48:01.805331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C4: VISUALIZATION TECHNIQUE\n",
    "# H0: There is no effect of the visualization technique on model performance.\n",
    "# H1: There is a significant effect of visualization technique.\n",
    "\n",
    "print(\"C4: VISUALIZATION TECHNIQUE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "analyze_categorical_effect(df_batch, 'viz_technique', min_group_size=10)\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "analyze_categorical_effect(df_reading, 'viz_technique', min_group_size=10)\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "analyze_categorical_effect(df_analysis, 'viz_technique', min_group_size=10)\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpreting subset:\")\n",
    "analyze_categorical_effect(df_interpretation, 'viz_technique', min_group_size=10)"
   ],
   "id": "cc85a053a1836c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4: VISUALIZATION TECHNIQUE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "Available observations: 864\n",
      "viz_technique distribution:\n",
      "viz_technique\n",
      "choropleth             324\n",
      "point-based symbols    324\n",
      "cartogram              216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal–Wallis H = 11.159, p = 0.003775\n",
      "Effect size (ε²) = 0.011\n",
      "Significant: YES\n",
      "\n",
      "Post-hoc Dunn test (adjusted p-values < 0.05):\n",
      "  cartogram vs choropleth — p = 0.002525\n",
      "\n",
      "Descriptive statistics:\n",
      "                         mean  median       std  count\n",
      "viz_technique                                         \n",
      "cartogram            3.789352    4.35  1.634491    216\n",
      "point-based symbols  3.439815    4.30  1.877706    324\n",
      "choropleth           3.207407    4.10  1.955173    324\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "Available observations: 288\n",
      "viz_technique distribution:\n",
      "viz_technique\n",
      "choropleth             108\n",
      "point-based symbols    108\n",
      "cartogram               72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal–Wallis H = 2.650, p = 0.265835\n",
      "Effect size (ε²) = 0.002\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                         mean  median       std  count\n",
      "viz_technique                                         \n",
      "cartogram            3.450000     4.6  2.172815     72\n",
      "point-based symbols  3.159259     4.5  2.218320    108\n",
      "choropleth           3.124074     4.6  2.324870    108\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "Available observations: 288\n",
      "viz_technique distribution:\n",
      "viz_technique\n",
      "choropleth             108\n",
      "point-based symbols    108\n",
      "cartogram               72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal–Wallis H = 19.059, p = 0.000073\n",
      "Effect size (ε²) = 0.060\n",
      "Significant: YES\n",
      "\n",
      "Post-hoc Dunn test (adjusted p-values < 0.05):\n",
      "  cartogram vs choropleth — p = 0.000146\n",
      "  cartogram vs point-based symbols — p = 0.000303\n",
      "\n",
      "Descriptive statistics:\n",
      "                         mean  median       std  count\n",
      "viz_technique                                         \n",
      "cartogram            4.223611     4.3  0.981626     72\n",
      "choropleth           3.140741     4.1  1.905478    108\n",
      "point-based symbols  3.078241     4.1  1.994072    108\n",
      "--------------------------------------------------------------------------------\n",
      "Interpreting subset:\n",
      "Available observations: 288\n",
      "viz_technique distribution:\n",
      "viz_technique\n",
      "choropleth             108\n",
      "point-based symbols    108\n",
      "cartogram               72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal–Wallis H = 15.568, p = 0.000416\n",
      "Effect size (ε²) = 0.048\n",
      "Significant: YES\n",
      "\n",
      "Post-hoc Dunn test (adjusted p-values < 0.05):\n",
      "  choropleth vs point-based symbols — p = 0.000240\n",
      "\n",
      "Descriptive statistics:\n",
      "                         mean  median       std  count\n",
      "viz_technique                                         \n",
      "point-based symbols  4.081944   4.300  1.057538    108\n",
      "cartogram            3.694444   4.225  1.445015     72\n",
      "choropleth           3.357407   3.775  1.571457    108\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.853218Z",
     "start_time": "2025-10-05T13:48:01.841762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C5: SYMBOL SCALING\n",
    "# H0: There is no effect of the symbol scaling on model performance.\n",
    "# H1: There is a significant effect of symbol scaling.\n",
    "\n",
    "print(\"C5: SYMBOL SCALING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "analyze_categorical_effect(df_batch, 'symbol_scaling')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "analyze_categorical_effect(df_reading, 'symbol_scaling')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "analyze_categorical_effect(df_analysis, 'symbol_scaling')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpreting subset:\")\n",
    "analyze_categorical_effect(df_interpretation, 'symbol_scaling')"
   ],
   "id": "d40c0fe51a014878",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C5: SYMBOL SCALING\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "Available observations: 1188\n",
      "symbol_scaling distribution:\n",
      "symbol_scaling\n",
      "proportional symbols    648\n",
      "graduated symbols       540\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 164155.500, p = 0.062328\n",
      "Effect size (rank-biserial r) = 0.062\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "symbol_scaling                                         \n",
      "proportional symbols  3.208873    4.10  1.965625    648\n",
      "graduated symbols     2.902500    4.05  2.123198    540\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "Available observations: 396\n",
      "symbol_scaling distribution:\n",
      "symbol_scaling\n",
      "proportional symbols    216\n",
      "graduated symbols       180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 17387.000, p = 0.054807\n",
      "Effect size (rank-biserial r) = 0.106\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "symbol_scaling                                         \n",
      "proportional symbols  2.857407     4.5  2.344323    216\n",
      "graduated symbols     2.371667     1.7  2.390397    180\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "Available observations: 396\n",
      "symbol_scaling distribution:\n",
      "symbol_scaling\n",
      "proportional symbols    216\n",
      "graduated symbols       180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 18590.000, p = 0.442566\n",
      "Effect size (rank-biserial r) = 0.044\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "symbol_scaling                                         \n",
      "proportional symbols  2.885185   3.975  2.064825    216\n",
      "graduated symbols     2.670278   3.900  2.145107    180\n",
      "--------------------------------------------------------------------------------\n",
      "Interpreting subset:\n",
      "Available observations: 396\n",
      "symbol_scaling distribution:\n",
      "symbol_scaling\n",
      "proportional symbols    216\n",
      "graduated symbols       180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 19521.500, p = 0.942935\n",
      "Effect size (rank-biserial r) = -0.004\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "symbol_scaling                                         \n",
      "proportional symbols  3.884028    4.05  1.086422    216\n",
      "graduated symbols     3.665556    4.05  1.528302    180\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.883238Z",
     "start_time": "2025-10-05T13:48:01.871801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C6: DIAGRAM STRUCTURE\n",
    "# H0: There is no effect of the diagram structure on model performance.\n",
    "# H1: There is a significant effect of diagram structure.\n",
    "\n",
    "print(\"C6: DIAGRAM STRUCTURE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "analyze_categorical_effect(df_batch, 'diagram_structure')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "analyze_categorical_effect(df_reading, 'diagram_structure')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "analyze_categorical_effect(df_analysis, 'diagram_structure')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpreting subset:\")\n",
    "analyze_categorical_effect(df_interpretation, 'diagram_structure')"
   ],
   "id": "7052ef6250674d3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C6: DIAGRAM STRUCTURE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "Available observations: 1188\n",
      "diagram_structure distribution:\n",
      "diagram_structure\n",
      "uniform       648\n",
      "structural    540\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 181197.000, p = 0.281950\n",
      "Effect size (rank-biserial r) = -0.036\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                       mean  median       std  count\n",
      "diagram_structure                                   \n",
      "structural         3.109630   4.075  2.059428    540\n",
      "uniform            3.036265   4.025  2.031297    648\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "Available observations: 396\n",
      "diagram_structure distribution:\n",
      "diagram_structure\n",
      "uniform       216\n",
      "structural    180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 18489.500, p = 0.374078\n",
      "Effect size (rank-biserial r) = 0.049\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                       mean  median       std  count\n",
      "diagram_structure                                   \n",
      "uniform            2.781944    4.45  2.348616    216\n",
      "structural         2.462222    3.90  2.400655    180\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "Available observations: 396\n",
      "diagram_structure distribution:\n",
      "diagram_structure\n",
      "uniform       216\n",
      "structural    180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 21482.500, p = 0.064925\n",
      "Effect size (rank-biserial r) = -0.105\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                       mean  median       std  count\n",
      "diagram_structure                                   \n",
      "structural         3.009167   4.050  2.048419    180\n",
      "uniform            2.602778   3.825  2.132310    216\n",
      "--------------------------------------------------------------------------------\n",
      "Interpreting subset:\n",
      "Available observations: 396\n",
      "diagram_structure distribution:\n",
      "diagram_structure\n",
      "uniform       216\n",
      "structural    180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 21711.000, p = 0.044803\n",
      "Effect size (rank-biserial r) = -0.117\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                       mean  median       std  count\n",
      "diagram_structure                                   \n",
      "structural         3.857500   4.125  1.348292    180\n",
      "uniform            3.724074   4.000  1.274791    216\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Interactions",
   "id": "165605e4da564b4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:01.922675Z",
     "start_time": "2025-10-05T13:48:01.916902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scheirer_ray_hare_test(df, value_col, factor1_col, factor2_col):\n",
    "    df = df.copy()\n",
    "    df['rank'] = rankdata(df[value_col])\n",
    "\n",
    "    n = len(df)\n",
    "    a = df[factor1_col].nunique()\n",
    "    b = df[factor2_col].nunique()\n",
    "\n",
    "    grand_mean_rank = df['rank'].mean()\n",
    "\n",
    "    ss_factor1 = 0\n",
    "    for level in df[factor1_col].unique():\n",
    "        subset = df[df[factor1_col] == level]\n",
    "        n_level = len(subset)\n",
    "        mean_rank = subset['rank'].mean()\n",
    "        ss_factor1 += n_level * (mean_rank - grand_mean_rank)**2\n",
    "\n",
    "    ss_factor2 = 0\n",
    "    for level in df[factor2_col].unique():\n",
    "        subset = df[df[factor2_col] == level]\n",
    "        n_level = len(subset)\n",
    "        mean_rank = subset['rank'].mean()\n",
    "        ss_factor2 += n_level * (mean_rank - grand_mean_rank)**2\n",
    "\n",
    "    ss_total = np.sum((df['rank'] - grand_mean_rank)**2)\n",
    "    ss_interaction = ss_total - ss_factor1 - ss_factor2\n",
    "    ms_total = ss_total / (n - 1)\n",
    "\n",
    "    H_factor1 = ss_factor1 / ms_total\n",
    "    H_factor2 = ss_factor2 / ms_total\n",
    "    H_interaction = ss_interaction / ms_total\n",
    "\n",
    "    df_factor1 = a - 1\n",
    "    df_factor2 = b - 1\n",
    "    df_interaction = (a - 1) * (b - 1)\n",
    "\n",
    "    p_factor1 = 1 - chi2.cdf(H_factor1, df_factor1)\n",
    "    p_factor2 = 1 - chi2.cdf(H_factor2, df_factor2)\n",
    "    p_interaction = 1 - chi2.cdf(H_interaction, df_interaction)\n",
    "\n",
    "    return {\n",
    "        'model_effect': {'H': H_factor1, 'df': df_factor1, 'p': p_factor1},\n",
    "        f'{factor2_col}_effect': {'H': H_factor2, 'df': df_factor2, 'p': p_factor2},\n",
    "        'interaction': {'H': H_interaction, 'df': df_interaction, 'p': p_interaction}\n",
    "    }\n",
    "\n",
    "\n",
    "def permutation_interaction_test(df, value_col, factor1_col, factor2_col, n_permutations=10000):\n",
    "    observed_stat = 0\n",
    "    for level in df[factor2_col].unique():\n",
    "        subset = df[df[factor2_col] == level]\n",
    "        groups = [subset[subset[factor1_col] == m][value_col].values\n",
    "                  for m in subset[factor1_col].unique()]\n",
    "        h, _ = kruskal(*groups)\n",
    "        observed_stat += h\n",
    "\n",
    "    permuted_stats = []\n",
    "    for _ in range(n_permutations):\n",
    "        df_perm = df.copy()\n",
    "        df_perm[value_col] = np.random.permutation(df_perm[value_col].values)\n",
    "\n",
    "        perm_stat = 0\n",
    "        for level in df_perm[factor2_col].unique():\n",
    "            subset = df_perm[df_perm[factor2_col] == level]\n",
    "            groups = [subset[subset[factor1_col] == m][value_col].values\n",
    "                      for m in subset[factor1_col].unique()]\n",
    "            h, _ = kruskal(*groups)\n",
    "            perm_stat += h\n",
    "        permuted_stats.append(perm_stat)\n",
    "\n",
    "    p_value = np.mean(np.array(permuted_stats) >= observed_stat)\n",
    "\n",
    "    return {'statistic': observed_stat, 'p_value': p_value}\n",
    "\n",
    "\n",
    "def test_ranking_consistency(df, value_col, factor1_col, factor2_col):\n",
    "    pivot = df.pivot_table(values=value_col, index=factor1_col,\n",
    "                           columns=factor2_col, aggfunc='mean')\n",
    "\n",
    "    rankings = pivot.rank(ascending=False)\n",
    "    categories = rankings.columns.tolist()\n",
    "    results = []\n",
    "\n",
    "    for i, cat1 in enumerate(categories):\n",
    "        for cat2 in categories[i+1:]:\n",
    "            tau, p = kendalltau(rankings[cat1], rankings[cat2])\n",
    "            results.append({\n",
    "                'category1': cat1,\n",
    "                'category2': cat2,\n",
    "                'kendall_tau': tau,\n",
    "                'p_value': p,\n",
    "                'agreement': 'high' if tau > 0.7 else 'moderate' if tau > 0.4 else 'low'\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results), rankings"
   ],
   "id": "c790bfe951a15def",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:53.736786Z",
     "start_time": "2025-10-05T13:48:01.927770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I1: Model x Map Usage Type intersection\n",
    "# H0: No interaction effect between Model and Map Usage Type.\n",
    "# H1: An interaction effect exists between Model and Map Usage Type.\n",
    "\n",
    "print(\"I1: MODEL × MAP USAGE TYPE INTERACTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"Scheirer-Ray-Hare test:\")\n",
    "results = scheirer_ray_hare_test(df_batch, 'score', 'model_name', 'map_usage_type')\n",
    "print(f\"Model effect: H = {results['model_effect']['H']:.3f}, p = {results['model_effect']['p']:.6f}\")\n",
    "print(f\"Usage type effect: H = {results['map_usage_type_effect']['H']:.3f}, p = {results['map_usage_type_effect']['p']:.6f}\")\n",
    "print(f\"Interaction: H = {results['interaction']['H']:.3f}, p = {results['interaction']['p']:.6f}\")\n",
    "\n",
    "print(\"Permutation test\")\n",
    "result = permutation_interaction_test(df_batch, 'score', 'model_name', 'map_usage_type')\n",
    "print(f\"Interaction test: stat = {result['statistic']:.3f}, p = {result['p_value']:.6f}\")\n",
    "\n",
    "print(\"Ranking consistency test\")\n",
    "comparison_results, rankings = test_ranking_consistency(\n",
    "    df_batch, 'score', 'model_name', 'map_usage_type'\n",
    ")\n",
    "print(\"\\nRanking consistency:\")\n",
    "print(comparison_results)\n",
    "print(\"\\nRankings per category:\")\n",
    "print(rankings)\n",
    "\n",
    "print(\"Simple effects analysis:\")\n",
    "interaction_results_c1 = []\n",
    "for category in sorted(df_batch['map_usage_type'].unique()):\n",
    "    subset = df_batch[df_batch['map_usage_type'] == category]\n",
    "    model_groups_cat = [subset[subset['model_name'] == model]['score'].values\n",
    "                        for model in sorted(subset['model_name'].unique())]\n",
    "    h, p = kruskal(*model_groups_cat)\n",
    "    interaction_results_c1.append({\n",
    "        'category': category,\n",
    "        'H': h,\n",
    "        'p': p,\n",
    "        'significant': p < 0.05\n",
    "    })\n",
    "    print(f\"\\n{category}: H = {h:.3f}, p = {p:.6f} {'*' if p < 0.05 else ''}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        cat_means = subset.groupby('model_name')['score'].mean().sort_values(ascending=False)\n",
    "        print(f\"  Top 3 models: {', '.join(cat_means.head(3).index.tolist())}\")\n",
    "\n",
    "# FDR correction across categories\n",
    "p_values_c1 = [r['p'] for r in interaction_results_c1]\n",
    "rejected, p_corrected, _, _ = multipletests(p_values_c1, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "print(\"\\n\\nFDR-corrected results:\")\n",
    "for i, result in enumerate(interaction_results_c1):\n",
    "    result['p_corrected'] = p_corrected[i]\n",
    "    result['significant_corrected'] = rejected[i]\n",
    "    print(f\"{result['category']}: p_corrected = {p_corrected[i]:.6f} {'*' if rejected[i] else ''}\")\n",
    "\n",
    "# Interaction heatmap data\n",
    "interaction_matrix_c1 = df_batch.pivot_table(\n",
    "    values='score',\n",
    "    index='model_name',\n",
    "    columns='map_usage_type',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(\"\\n\\nMean scores (Model × Map Usage Type):\")\n",
    "print(interaction_matrix_c1.round(3))"
   ],
   "id": "8b4f9a254c2cacb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1: MODEL × MAP USAGE TYPE INTERACTION\n",
      "--------------------------------------------------------------------------------\n",
      "Scheirer-Ray-Hare test:\n",
      "Model effect: H = 90.453, p = 0.000000\n",
      "Usage type effect: H = 15.191, p = 0.000503\n",
      "Interaction: H = 1621.356, p = 0.000000\n",
      "Permutation test\n",
      "Interaction test: stat = 127.843, p = 0.000000\n",
      "Ranking consistency test\n",
      "\n",
      "Ranking consistency:\n",
      "        category1       category2  kendall_tau   p_value agreement\n",
      "0        analysis  interpretation     0.242424  0.310810       low\n",
      "1        analysis         reading     0.484848  0.031050  moderate\n",
      "2  interpretation         reading     0.090909  0.737306       low\n",
      "\n",
      "Rankings per category:\n",
      "map_usage_type        analysis  interpretation  reading\n",
      "model_name                                             \n",
      "Claude 3.5 Sonnet v2       2.0             7.0      3.0\n",
      "Claude 3.7 Sonnet          1.0             1.0      1.0\n",
      "DeepSeek-R1               11.0            11.0      8.0\n",
      "GPT o3                     3.0             4.0      5.0\n",
      "GPT-4o                     7.0             3.0     11.0\n",
      "Gemini 1.5 Pro             6.0             8.0      6.0\n",
      "Gemma 3                    5.0             6.0     12.0\n",
      "Grok-3                     4.0            10.0      2.0\n",
      "MiniMax-01                12.0             2.0     10.0\n",
      "Mistral Large              8.0             5.0      4.0\n",
      "Qwen2.5-Max                9.0             9.0      7.0\n",
      "Sonar                     10.0            12.0      9.0\n",
      "Simple effects analysis:\n",
      "\n",
      "analysis: H = 46.375, p = 0.000003 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Claude 3.5 Sonnet v2, GPT o3\n",
      "\n",
      "interpretation: H = 44.476, p = 0.000006 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, MiniMax-01, GPT-4o\n",
      "\n",
      "reading: H = 36.992, p = 0.000116 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Grok-3, Claude 3.5 Sonnet v2\n",
      "\n",
      "\n",
      "FDR-corrected results:\n",
      "analysis: p_corrected = 0.000008 *\n",
      "interpretation: p_corrected = 0.000009 *\n",
      "reading: p_corrected = 0.000116 *\n",
      "\n",
      "\n",
      "Mean scores (Model × Map Usage Type):\n",
      "map_usage_type        analysis  interpretation  reading\n",
      "model_name                                             \n",
      "Claude 3.5 Sonnet v2     3.635           3.733    3.363\n",
      "Claude 3.7 Sonnet        3.893           4.409    3.504\n",
      "DeepSeek-R1              2.504           3.368    2.533\n",
      "GPT o3                   3.509           3.858    3.171\n",
      "GPT-4o                   2.941           3.902    2.092\n",
      "Gemini 1.5 Pro           3.070           3.689    3.104\n",
      "Gemma 3                  3.121           3.754    2.054\n",
      "Grok-3                   3.227           3.402    3.423\n",
      "MiniMax-01               2.444           3.955    2.227\n",
      "Mistral Large            2.903           3.841    3.242\n",
      "Qwen2.5-Max              2.616           3.461    2.783\n",
      "Sonar                    2.535           2.947    2.460\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:53.865140Z",
     "start_time": "2025-10-05T13:48:53.807655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I2: Graphical complexity x Map Usage Type\n",
    "# H0: There are no significant effects of map graphical complexity or map usage type on model performance, and no interaction between these factors.\n",
    "# H1: There is a significant interaction between graphical complexity and map usage type.\n",
    "\n",
    "print(\"I2: GRAPHICAL COMPLEXITY × MAP USAGE TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ===== 1. MAIN EFFECTS =====\n",
    "\n",
    "df_c5 = df_batch[['score', 'graphical_complexity', 'map_usage_type']].copy()\n",
    "\n",
    "df_c5['rank'] = df_c5['score'].rank()\n",
    "\n",
    "model = ols('rank ~ C(graphical_complexity) + C(map_usage_type) + C(graphical_complexity):C(map_usage_type)',\n",
    "            data=df_c5).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "N = len(df_c5)\n",
    "anova_table['H'] = anova_table['F'] * (anova_table['df'] + 1)\n",
    "anova_table['p_srh'] = chi2.sf(anova_table['H'], anova_table['df'])\n",
    "\n",
    "print(\"Scheirer-Ray-Hare Test Results:\")\n",
    "print(f\"Complexity effect: H = {anova_table.loc['C(graphical_complexity)', 'H']:.3f}, \" +\n",
    "      f\"p = {anova_table.loc['C(graphical_complexity)', 'p_srh']:.6f}\")\n",
    "print(f\"Usage type effect: H = {anova_table.loc['C(map_usage_type)', 'H']:.3f}, \" +\n",
    "      f\"p = {anova_table.loc['C(map_usage_type)', 'p_srh']:.6f}\")\n",
    "print(f\"Interaction: H = {anova_table.loc['C(graphical_complexity):C(map_usage_type)', 'H']:.3f}, \" +\n",
    "      f\"p = {anova_table.loc['C(graphical_complexity):C(map_usage_type)', 'p_srh']:.6f}\")\n",
    "\n",
    "interaction_p = anova_table.loc['C(graphical_complexity):C(map_usage_type)', 'p_srh']\n",
    "print(f\"\\nInteraction significant: {'YES' if interaction_p < 0.05 else 'NO'}\")\n",
    "\n",
    "# ===== 2. SIMPLE EFFECTS =====\n",
    "if interaction_p < 0.05:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Simple effects analysis (post-hoc):\")\n",
    "    interaction_results_c5 = []\n",
    "\n",
    "    for category in sorted(df_batch['map_usage_type'].unique()):\n",
    "        subset = df_batch[df_batch['map_usage_type'] == category]\n",
    "        comp_groups = [subset[subset['graphical_complexity'] == comp]['score'].values\n",
    "                       for comp in sorted(subset['graphical_complexity'].unique())]\n",
    "        u, p = mannwhitneyu(comp_groups[0], comp_groups[1], alternative='two-sided')\n",
    "\n",
    "        # Effect size\n",
    "        n1, n2 = len(comp_groups[0]), len(comp_groups[1])\n",
    "        r = 1 - (2*u) / (n1 * n2)  # rank-biserial\n",
    "\n",
    "        interaction_results_c5.append({\n",
    "            'category': category,\n",
    "            'U': u,\n",
    "            'p': p,\n",
    "            'r': r,\n",
    "            'significant': p < 0.05\n",
    "        })\n",
    "        print(f\"\\n{category}: U = {u:.3f}, p = {p:.6f}, r = {r:.3f} {'*' if p < 0.05 else ''}\")\n",
    "\n",
    "    # FDR correction\n",
    "    p_values_c5 = [r['p'] for r in interaction_results_c5]\n",
    "    rejected_c5, p_corrected_c5, _, _ = multipletests(p_values_c5, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    print(\"\\n\\nFDR-corrected results:\")\n",
    "    for i, result in enumerate(interaction_results_c5):\n",
    "        result['p_corrected'] = p_corrected_c5[i]\n",
    "        result['significant_corrected'] = rejected_c5[i]\n",
    "        print(f\"{result['category']}: p_corrected = {p_corrected_c5[i]:.6f} {'*' if rejected_c5[i] else ''}\")\n",
    "else:\n",
    "    print(\"\\nInteraction not significant - simple effects analysis not warranted\")\n",
    "    print(\"Main effect of complexity applies uniformly across usage types\")\n",
    "\n",
    "# ===== 3. DESCRIPTIVE STATISTICS =====\n",
    "print(\"\\n\\nMean scores (Complexity × Category):\")\n",
    "interaction_matrix_c5 = df_batch.pivot_table(\n",
    "    values='score',\n",
    "    index='graphical_complexity',\n",
    "    columns='map_usage_type',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(interaction_matrix_c5.round(3))\n",
    "\n",
    "print(\"\\n\\nEffect of low complexity (difference from high):\")\n",
    "for col in interaction_matrix_c5.columns:\n",
    "    diff = interaction_matrix_c5.loc['low', col] - interaction_matrix_c5.loc['high', col]\n",
    "    print(f\"{col}: +{diff:.3f}\")"
   ],
   "id": "8bfa23e6e5b97a39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I2: GRAPHICAL COMPLEXITY × MAP USAGE TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "Scheirer-Ray-Hare Test Results:\n",
      "Complexity effect: H = 44.492, p = 0.000000\n",
      "Usage type effect: H = 23.313, p = 0.000009\n",
      "Interaction: H = 10.667, p = 0.004827\n",
      "\n",
      "Interaction significant: YES\n",
      "\n",
      "================================================================================\n",
      "Simple effects analysis (post-hoc):\n",
      "\n",
      "analysis: U = 34892.500, p = 0.000812, r = 0.159 *\n",
      "\n",
      "interpretation: U = 39849.500, p = 0.415771, r = 0.039 \n",
      "\n",
      "reading: U = 34900.500, p = 0.000514, r = 0.158 *\n",
      "\n",
      "\n",
      "FDR-corrected results:\n",
      "analysis: p_corrected = 0.001218 *\n",
      "interpretation: p_corrected = 0.415771 \n",
      "reading: p_corrected = 0.001218 *\n",
      "\n",
      "\n",
      "Mean scores (Complexity × Category):\n",
      "map_usage_type        analysis  interpretation  reading\n",
      "graphical_complexity                                   \n",
      "high                     2.678           3.673    2.441\n",
      "low                      3.388           3.713    3.219\n",
      "\n",
      "\n",
      "Effect of low complexity (difference from high):\n",
      "analysis: +0.710\n",
      "interpretation: +0.040\n",
      "reading: +0.778\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:53.951072Z",
     "start_time": "2025-10-05T13:48:53.914769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I3: Model x Graphical complexity\n",
    "# H0: There is no significant effect of the model, no effect of graphical complexity, and no interaction between model and graphical complexity.\n",
    "# H1: There is a significant interaction between model and graphical complexity.\n",
    "\n",
    "print(\"I3: MODEL × GRAPHICAL COMPLEXITY INTERACTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results = scheirer_ray_hare_test(df_batch, 'score', 'model_name', 'graphical_complexity')\n",
    "print(f\"Model effect: H = {results['model_effect']['H']:.3f}, p = {results['model_effect']['p']:.6f}\")\n",
    "print(f\"Graphical complexity effect: H = {results['graphical_complexity_effect']['H']:.3f}, p = {results['graphical_complexity_effect']['p']:.6f}\")\n",
    "print(f\"Interaction: H = {results['interaction']['H']:.3f}, p = {results['interaction']['p']:.6f}\")\n",
    "\n",
    "print(\"Simple effects analysis:\")\n",
    "interaction_results_c2 = []\n",
    "for complexity in sorted(df_batch['graphical_complexity'].unique()):\n",
    "    subset = df_batch[df_batch['graphical_complexity'] == complexity]\n",
    "    model_groups_comp = [subset[subset['model_name'] == model]['score'].values\n",
    "                         for model in sorted(subset['model_name'].unique())]\n",
    "    h, p = kruskal(*model_groups_comp)\n",
    "    interaction_results_c2.append({\n",
    "        'graphical_complexity': complexity,\n",
    "        'H': h,\n",
    "        'p': p,\n",
    "        'significant': p < 0.05\n",
    "    })\n",
    "    print(f\"\\n{complexity}: H = {h:.3f}, p = {p:.6f} {'*' if p < 0.05 else ''}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        comp_means = subset.groupby('model_name')['score'].mean().sort_values(ascending=False)\n",
    "        print(f\"  Top 3 models: {', '.join(comp_means.head(3).index.tolist())}\")\n",
    "\n",
    "p_values_c2 = [r['p'] for r in interaction_results_c2]\n",
    "rejected_c2, p_corrected_c2, _, _ = multipletests(p_values_c2, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "print(\"\\n\\nFDR-corrected results:\")\n",
    "for i, result in enumerate(interaction_results_c2):\n",
    "    result['p_corrected'] = p_corrected_c2[i]\n",
    "    result['significant_corrected'] = rejected_c2[i]\n",
    "    print(f\"{result['graphical_complexity']}: p_corrected = {p_corrected_c2[i]:.6f} {'*' if rejected_c2[i] else ''}\")\n",
    "\n",
    "interaction_matrix_c2 = df_batch.pivot_table(\n",
    "    values='score',\n",
    "    index='model_name',\n",
    "    columns='graphical_complexity',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(\"\\n\\nMean scores (Model × Graphical Complexity):\")\n",
    "print(interaction_matrix_c2.round(3))"
   ],
   "id": "4430666568dda9ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I3: MODEL × GRAPHICAL COMPLEXITY INTERACTION\n",
      "--------------------------------------------------------------------------------\n",
      "Model effect: H = 90.453, p = 0.000000\n",
      "Graphical complexity effect: H = 21.744, p = 0.000003\n",
      "Interaction: H = 1614.803, p = 0.000000\n",
      "Simple effects analysis:\n",
      "\n",
      "high: H = 34.727, p = 0.000275 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Claude 3.5 Sonnet v2, GPT o3\n",
      "\n",
      "low: H = 72.624, p = 0.000000 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Mistral Large, GPT o3\n",
      "\n",
      "\n",
      "FDR-corrected results:\n",
      "high: p_corrected = 0.000275 *\n",
      "low: p_corrected = 0.000000 *\n",
      "\n",
      "\n",
      "Mean scores (Model × Graphical Complexity):\n",
      "graphical_complexity   high    low\n",
      "model_name                        \n",
      "Claude 3.5 Sonnet v2  3.425  3.729\n",
      "Claude 3.7 Sonnet     3.580  4.291\n",
      "DeepSeek-R1           2.419  3.184\n",
      "GPT o3                3.241  3.785\n",
      "GPT-4o                2.815  3.142\n",
      "Gemini 1.5 Pro        3.134  3.442\n",
      "Gemma 3               2.910  3.042\n",
      "Grok-3                2.961  3.740\n",
      "MiniMax-01            2.473  3.278\n",
      "Mistral Large         2.866  3.791\n",
      "Qwen2.5-Max           2.700  3.207\n",
      "Sonar                 2.645  2.650\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:54.124771Z",
     "start_time": "2025-10-05T13:48:53.999352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I4: Model x Spatial aggregation level\n",
    "# H0: There is no significant effect of the model, no effect of NUTS level, and no interaction between model and NUTS level.\n",
    "# H1: There is a significant interaction between model and NUTS level.\n",
    "\n",
    "print(\"I4: MODEL × SPATIAL AGGREGATION LEVEL INTERACTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results = scheirer_ray_hare_test(df_batch, 'score', 'model_name', 'nuts_level')\n",
    "print(f\"Model effect: H = {results['model_effect']['H']:.3f}, p = {results['model_effect']['p']:.6f}\")\n",
    "print(f\"NUTS level effect: H = {results['nuts_level_effect']['H']:.3f}, p = {results['nuts_level_effect']['p']:.6f}\")\n",
    "print(f\"Interaction: H = {results['interaction']['H']:.3f}, p = {results['interaction']['p']:.6f}\")\n",
    "\n",
    "print(\"Simple effects analysis:\")\n",
    "interaction_results_c3 = []\n",
    "for nuts in sorted(df_batch['nuts_level'].unique()):\n",
    "    subset = df_batch[df_batch['nuts_level'] == nuts]\n",
    "    model_groups_nuts = [subset[subset['model_name'] == model]['score'].values\n",
    "                         for model in sorted(subset['model_name'].unique())]\n",
    "    h, p = kruskal(*model_groups_nuts)\n",
    "    interaction_results_c3.append({\n",
    "        'nuts_level': nuts,\n",
    "        'H': h,\n",
    "        'p': p,\n",
    "        'significant': p < 0.05\n",
    "    })\n",
    "    print(f\"\\n{nuts}: H = {h:.3f}, p = {p:.6f} {'*' if p < 0.05 else ''}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        nuts_means = subset.groupby('model_name')['score'].mean().sort_values(ascending=False)\n",
    "        print(f\"  Top 3 models: {', '.join(nuts_means.head(3).index.tolist())}\")\n",
    "\n",
    "# FDR correction across NUTS levels\n",
    "p_values_c3 = [r['p'] for r in interaction_results_c3]\n",
    "rejected_c3, p_corrected_c3, _, _ = multipletests(p_values_c3, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "print(\"\\n\\nFDR-corrected results:\")\n",
    "for i, result in enumerate(interaction_results_c3):\n",
    "    result['p_corrected'] = p_corrected_c3[i]\n",
    "    result['significant_corrected'] = rejected_c3[i]\n",
    "    print(f\"{result['nuts_level']}: p_corrected = {p_corrected_c3[i]:.6f} {'*' if rejected_c3[i] else ''}\")\n",
    "\n",
    "interaction_matrix_c3 = df_batch.pivot_table(\n",
    "    values='score',\n",
    "    index='model_name',\n",
    "    columns='nuts_level',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(\"\\n\\nMean scores (Model × NUTS):\")\n",
    "print(interaction_matrix_c3.round(3))"
   ],
   "id": "5b432515673b8647",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I4: MODEL × SPATIAL AGGREGATION LEVEL INTERACTION\n",
      "--------------------------------------------------------------------------------\n",
      "Model effect: H = 90.453, p = 0.000000\n",
      "NUTS level effect: H = 3.653, p = 0.055958\n",
      "Interaction: H = 1632.894, p = 0.000000\n",
      "Simple effects analysis:\n",
      "\n",
      "country: H = 53.150, p = 0.000000 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Claude 3.5 Sonnet v2, GPT o3\n",
      "\n",
      "region: H = 42.932, p = 0.000011 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, GPT o3, Claude 3.5 Sonnet v2\n",
      "\n",
      "\n",
      "FDR-corrected results:\n",
      "country: p_corrected = 0.000000 *\n",
      "region: p_corrected = 0.000011 *\n",
      "\n",
      "\n",
      "Mean scores (Model × NUTS):\n",
      "nuts_level            country  region\n",
      "model_name                           \n",
      "Claude 3.5 Sonnet v2    3.690   3.464\n",
      "Claude 3.7 Sonnet       4.097   3.774\n",
      "DeepSeek-R1             2.838   2.765\n",
      "GPT o3                  3.535   3.491\n",
      "GPT-4o                  3.057   2.899\n",
      "Gemini 1.5 Pro          3.533   3.042\n",
      "Gemma 3                 2.994   2.959\n",
      "Grok-3                  3.264   3.438\n",
      "MiniMax-01              2.894   2.857\n",
      "Mistral Large           3.416   3.240\n",
      "Qwen2.5-Max             3.221   2.686\n",
      "Sonar                   2.781   2.514\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Profiles",
   "id": "4769dc6faafb4162"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T14:50:12.207707Z",
     "start_time": "2025-10-05T14:50:12.078396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# P1: Model Difficulty Profiles\n",
    "# H0: All models have uniform difficulty profiles (perform equally across condition combinations)\n",
    "# H1: Models have different difficulty profiles (differ based on complexity, source, and task combinations)\n",
    "\n",
    "print(\"P1: DIFFICULTY PROFILES OF MODELS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_d3 = df_batch.copy()\n",
    "\n",
    "# Create combined difficulty variable\n",
    "df_d3['difficulty_combo'] = (df_d3['graphical_complexity'] + '_' +\n",
    "                             df_d3['nuts_level'] + '_' +\n",
    "                             df_d3['map_source'] + '_' +\n",
    "                             df_d3['map_usage_type'])\n",
    "\n",
    "print(\"Difficulty combinations:\")\n",
    "combo_counts = df_d3['difficulty_combo'].value_counts()\n",
    "print(f\"Total combinations: {len(combo_counts)}\")\n",
    "print(f\"\\nDistribution of observations across combinations:\")\n",
    "print(combo_counts.describe())\n",
    "\n",
    "# Filter to keep only combinations with sufficient observations\n",
    "# With 12 models, n≥10 means at least some models are represented\n",
    "valid_combos = combo_counts[combo_counts >= 10].index\n",
    "df_d3 = df_d3[df_d3['difficulty_combo'].isin(valid_combos)]\n",
    "\n",
    "print(f\"\\nAfter filtering (n≥10): {len(valid_combos)} combinations, {len(df_d3)} observations\")\n",
    "print(f\"Valid combinations:\\n{sorted(valid_combos)}\")\n",
    "\n",
    "print(\"\\nNumber of observations for each valid combination:\")\n",
    "for combo, count in combo_counts.items():\n",
    "    if combo in valid_combos:\n",
    "        print(f\"  {combo}: {count}\")\n",
    "\n",
    "profile_analysis = df_d3.groupby(['model_name', 'difficulty_combo'])['score'].agg([\n",
    "    'mean', 'std', 'count'\n",
    "]).unstack(fill_value=np.nan)\n",
    "\n",
    "print(\"\\n\\nProfile Analysis - Mean Scores per Model × Difficulty Combination:\")\n",
    "print(profile_analysis['mean'].round(3))\n",
    "\n",
    "# === SHOW MODELS WITH PERFECT SCORE (5.00) FOR EACH DIFFICULTY COMBO ===\n",
    "print(\"\\n\\nModels with perfect mean score (5.00) by difficulty combination:\")\n",
    "perfect_score_models = {}\n",
    "\n",
    "for combo in sorted(profile_analysis['mean'].columns):\n",
    "    combo_means = profile_analysis['mean'][combo]\n",
    "    models_with_5 = combo_means[combo_means == 5.00].index.tolist()\n",
    "    if models_with_5:\n",
    "        perfect_score_models[combo] = models_with_5\n",
    "        print(f\"\\n{combo}:\")\n",
    "        for model in models_with_5:\n",
    "            print(f\"  - {model}\")\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "if not perfect_score_models:\n",
    "    print(\"\\nNo models achieved a perfect mean score (5.00) for any combination.\")\n",
    "\n",
    "\n",
    "# === SAVE WIDE TABLE (mean scores per model × difficulty combination) ===\n",
    "\n",
    "mean_scores = profile_analysis['mean']\n",
    "mean_scores = mean_scores.reindex(sorted(mean_scores.columns), axis=1)\n",
    "mean_scores.reset_index(inplace=True)\n",
    "\n",
    "output_file = \"../../results/model_difficulty_profiles_means.csv\"\n",
    "mean_scores.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nSaved mean difficulty profiles (wide format) to '{output_file}'\")\n",
    "print(f\"Shape: {mean_scores.shape}\")\n",
    "print(f\"Preview:\\n{mean_scores.head()}\")\n",
    "\n",
    "\n",
    "# Calculate rankings for each difficulty combination\n",
    "rankings = {}\n",
    "for combo in valid_combos:\n",
    "    combo_scores = df_d3[df_d3['difficulty_combo'] == combo].groupby('model_name')['score'].mean()\n",
    "    rankings[combo] = combo_scores.sort_values(ascending=False)\n",
    "\n",
    "# Find best model for each combination\n",
    "best_models_per_combo = {}\n",
    "for combo, ranking in rankings.items():\n",
    "    if len(ranking) > 0:\n",
    "        best_models_per_combo[combo] = {\n",
    "            'best_model': ranking.index[0],\n",
    "            'best_score': ranking.iloc[0],\n",
    "            'second_model': ranking.index[1] if len(ranking) > 1 else None,\n",
    "            'second_score': ranking.iloc[1] if len(ranking) > 1 else None\n",
    "        }\n",
    "\n",
    "print(\"\\n\\nBest models per difficulty combination:\")\n",
    "for combo, best in sorted(best_models_per_combo.items()):\n",
    "    print(f\"\\n{combo}:\")\n",
    "    print(f\"  1st: {best['best_model']} (M={best['best_score']:.3f})\")\n",
    "    if best['second_model']:\n",
    "        print(f\"  2nd: {best['second_model']} (M={best['second_score']:.3f})\")\n",
    "\n",
    "# Count how often each model is best\n",
    "model_wins = {}\n",
    "for combo, best in best_models_per_combo.items():\n",
    "    model = best['best_model']\n",
    "    model_wins[model] = model_wins.get(model, 0) + 1\n",
    "\n",
    "print(\"\\n\\nModel specialization (times ranked 1st):\")\n",
    "for model, wins in sorted(model_wins.items(), key=lambda x: x[1], reverse=True):\n",
    "    pct = (wins / len(best_models_per_combo)) * 100\n",
    "    print(f\"  {model}: {wins}/{len(best_models_per_combo)} ({pct:.1f}%)\")\n",
    "\n",
    "# Cluster analysis of models based on difficulty profiles\n",
    "try:\n",
    "    # Prepare data for clustering\n",
    "    model_profiles = profile_analysis['mean'].fillna(profile_analysis['mean'].mean(axis=0))\n",
    "\n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    profiles_scaled = scaler.fit_transform(model_profiles)\n",
    "\n",
    "    # Determine optimal number of clusters (2-5)\n",
    "    silhouette_scores = {}\n",
    "    for n_clusters in range(2, min(6, len(model_profiles))):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(profiles_scaled)\n",
    "        silhouette_scores[n_clusters] = silhouette_score(profiles_scaled, cluster_labels)\n",
    "\n",
    "    optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
    "    print(f\"\\n\\nCluster Analysis:\")\n",
    "    print(f\"Silhouette scores for different k: {silhouette_scores}\")\n",
    "    print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "\n",
    "    # K-means clustering with optimal k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(profiles_scaled)\n",
    "\n",
    "    # Assign clusters to models\n",
    "    model_clusters = dict(zip(model_profiles.index, clusters))\n",
    "\n",
    "    print(f\"\\nModel cluster assignments (k={optimal_k}):\")\n",
    "    for cluster_id in range(optimal_k):\n",
    "        cluster_models = [m for m, c in model_clusters.items() if c == cluster_id]\n",
    "        print(f\"  Cluster {cluster_id}: {', '.join(cluster_models)}\")\n",
    "\n",
    "    # Characterize clusters by their performance patterns\n",
    "    cluster_characteristics = {}\n",
    "    for cluster_id in range(optimal_k):\n",
    "        cluster_models = [m for m, c in model_clusters.items() if c == cluster_id]\n",
    "        cluster_data = df_d3[df_d3['model_name'].isin(cluster_models)]\n",
    "\n",
    "        cluster_characteristics[cluster_id] = {\n",
    "            'mean_score': cluster_data['score'].mean(),\n",
    "            'std_score': cluster_data['score'].std(),\n",
    "            'best_on_low': cluster_data[cluster_data['graphical_complexity'] == 'low']['score'].mean(),\n",
    "            'best_on_high': cluster_data[cluster_data['graphical_complexity'] == 'high']['score'].mean(),\n",
    "            'models': cluster_models\n",
    "        }\n",
    "\n",
    "    print(\"\\nCluster characteristics:\")\n",
    "    for cluster_id, chars in cluster_characteristics.items():\n",
    "        print(f\"\\n  Cluster {cluster_id}:\")\n",
    "        print(f\"    Overall: M={chars['mean_score']:.3f}, SD={chars['std_score']:.3f}\")\n",
    "        print(f\"    Low graphically complex maps: M={chars['best_on_low']:.3f}\")\n",
    "        print(f\"    High graphically complex maps: M={chars['best_on_high']:.3f}\")\n",
    "\n",
    "    cluster_analysis = {\n",
    "        'model_clusters': model_clusters,\n",
    "        'optimal_k': optimal_k,\n",
    "        'silhouette_scores': silhouette_scores,\n",
    "        'cluster_characteristics': cluster_characteristics\n",
    "    }\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\n\\nSklearn not available - skipping cluster analysis\")\n",
    "    cluster_analysis = None\n",
    "\n",
    "# Statistical tests for each difficulty combination\n",
    "print(\"\\n\\nStatistical tests per difficulty combination:\")\n",
    "anova_results = {}\n",
    "p_values_d3 = []\n",
    "combo_names_d3 = []\n",
    "\n",
    "for combo in valid_combos:\n",
    "    combo_data = df_d3[df_d3['difficulty_combo'] == combo]\n",
    "    unique_models = combo_data['model_name'].unique()\n",
    "\n",
    "    if len(unique_models) > 2:\n",
    "        # Kruskal-Wallis for >2 groups\n",
    "        model_groups = [combo_data[combo_data['model_name'] == model]['score'].values\n",
    "                        for model in unique_models]\n",
    "        h_stat, p_val = kruskal(*model_groups)\n",
    "\n",
    "        n = len(combo_data)\n",
    "        k = len(unique_models)\n",
    "        epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "        anova_results[combo] = {\n",
    "            'test': 'Kruskal-Wallis',\n",
    "            'statistic': h_stat,\n",
    "            'p_value': p_val,\n",
    "            'effect_size': epsilon_sq,\n",
    "            'significant': p_val < 0.05,\n",
    "            'n_models': len(unique_models),\n",
    "            'n_obs': n\n",
    "        }\n",
    "        p_values_d3.append(p_val)\n",
    "        combo_names_d3.append(combo)\n",
    "\n",
    "print(\"\\nCombinations significant before FDR (trends):\")\n",
    "for combo, result in anova_results.items():\n",
    "    if result['significant'] and not result.get('significant_corrected', False):\n",
    "        print(f\"  {combo}: H={result['statistic']:.2f}, p={result['p_value']:.4f}, ε²={result['effect_size']:.3f}\")\n",
    "\n",
    "# FDR correction across all combinations\n",
    "if len(p_values_d3) > 0:\n",
    "    rejected, p_corrected, _, _ = multipletests(p_values_d3, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    print(f\"\\nTotal combinations tested: {len(p_values_d3)}\")\n",
    "    print(f\"Significant before correction: {sum([r['significant'] for r in anova_results.values()])}\")\n",
    "    print(f\"Significant after FDR correction: {sum(rejected)}\")\n",
    "\n",
    "    # Update results with corrected p-values\n",
    "    for i, combo in enumerate(combo_names_d3):\n",
    "        anova_results[combo]['p_corrected'] = p_corrected[i]\n",
    "        anova_results[combo]['significant_corrected'] = rejected[i]\n",
    "\n",
    "    # Show significant results after correction\n",
    "    print(\"\\nSignificant differences after FDR correction:\")\n",
    "    sig_count = 0\n",
    "    for combo, result in anova_results.items():\n",
    "        if result.get('significant_corrected', False):\n",
    "            sig_count += 1\n",
    "            print(f\"\\n  {combo}:\")\n",
    "            print(\n",
    "                f\"    H={result['statistic']:.3f}, p_corr={result['p_corrected']:.6f}, ε²={result['effect_size']:.3f}\")\n",
    "            # Show top models\n",
    "            best = best_models_per_combo[combo]\n",
    "            print(f\"    Best: {best['best_model']} (M={best['best_score']:.3f})\")\n",
    "\n",
    "    if sig_count == 0:\n",
    "        print(\"  None - no significant differences after correction\")"
   ],
   "id": "4343d43c248b2144",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1: DIFFICULTY PROFILES OF MODELS\n",
      "--------------------------------------------------------------------------------\n",
      "Difficulty combinations:\n",
      "Total combinations: 21\n",
      "\n",
      "Distribution of observations across combinations:\n",
      "count     21.000000\n",
      "mean      82.285714\n",
      "std       38.001504\n",
      "min       36.000000\n",
      "25%       36.000000\n",
      "50%       72.000000\n",
      "75%      108.000000\n",
      "max      144.000000\n",
      "Name: count, dtype: float64\n",
      "\n",
      "After filtering (n≥10): 21 combinations, 1728 observations\n",
      "Valid combinations:\n",
      "['high_country_atlas_analysis', 'high_country_atlas_interpretation', 'high_country_atlas_reading', 'high_country_statistical_office_analysis', 'high_country_statistical_office_interpretation', 'high_country_statistical_office_reading', 'high_region_atlas_analysis', 'high_region_atlas_interpretation', 'high_region_atlas_reading', 'low_country_atlas_analysis', 'low_country_atlas_interpretation', 'low_country_atlas_reading', 'low_country_statistical_office_analysis', 'low_country_statistical_office_interpretation', 'low_country_statistical_office_reading', 'low_region_atlas_analysis', 'low_region_atlas_interpretation', 'low_region_atlas_reading', 'low_region_statistical_office_analysis', 'low_region_statistical_office_interpretation', 'low_region_statistical_office_reading']\n",
      "\n",
      "Number of observations for each valid combination:\n",
      "  low_region_statistical_office_analysis: 144\n",
      "  low_region_statistical_office_reading: 144\n",
      "  low_region_statistical_office_interpretation: 144\n",
      "  high_region_atlas_analysis: 108\n",
      "  high_region_atlas_reading: 108\n",
      "  high_country_statistical_office_interpretation: 108\n",
      "  high_country_statistical_office_analysis: 108\n",
      "  high_country_statistical_office_reading: 108\n",
      "  high_region_atlas_interpretation: 108\n",
      "  low_country_atlas_analysis: 72\n",
      "  high_country_atlas_reading: 72\n",
      "  high_country_atlas_analysis: 72\n",
      "  high_country_atlas_interpretation: 72\n",
      "  low_country_atlas_interpretation: 72\n",
      "  low_country_atlas_reading: 72\n",
      "  low_region_atlas_interpretation: 36\n",
      "  low_region_atlas_analysis: 36\n",
      "  low_region_atlas_reading: 36\n",
      "  low_country_statistical_office_interpretation: 36\n",
      "  low_country_statistical_office_analysis: 36\n",
      "  low_country_statistical_office_reading: 36\n",
      "\n",
      "\n",
      "Profile Analysis - Mean Scores per Model × Difficulty Combination:\n",
      "difficulty_combo      high_country_atlas_analysis  \\\n",
      "model_name                                          \n",
      "Claude 3.5 Sonnet v2                        3.833   \n",
      "Claude 3.7 Sonnet                           4.617   \n",
      "DeepSeek-R1                                 2.150   \n",
      "GPT o3                                      3.717   \n",
      "GPT-4o                                      3.750   \n",
      "Gemini 1.5 Pro                              4.500   \n",
      "Gemma 3                                     3.517   \n",
      "Grok-3                                      2.892   \n",
      "MiniMax-01                                  1.383   \n",
      "Mistral Large                               2.317   \n",
      "Qwen2.5-Max                                 2.850   \n",
      "Sonar                                       2.050   \n",
      "\n",
      "difficulty_combo      high_country_atlas_interpretation  \\\n",
      "model_name                                                \n",
      "Claude 3.5 Sonnet v2                              2.758   \n",
      "Claude 3.7 Sonnet                                 4.392   \n",
      "DeepSeek-R1                                       2.808   \n",
      "GPT o3                                            3.083   \n",
      "GPT-4o                                            3.667   \n",
      "Gemini 1.5 Pro                                    3.475   \n",
      "Gemma 3                                           3.750   \n",
      "Grok-3                                            3.408   \n",
      "MiniMax-01                                        3.817   \n",
      "Mistral Large                                     3.692   \n",
      "Qwen2.5-Max                                       3.033   \n",
      "Sonar                                             2.842   \n",
      "\n",
      "difficulty_combo      high_country_atlas_reading  \\\n",
      "model_name                                         \n",
      "Claude 3.5 Sonnet v2                       4.050   \n",
      "Claude 3.7 Sonnet                          3.250   \n",
      "DeepSeek-R1                                2.950   \n",
      "GPT o3                                     3.183   \n",
      "GPT-4o                                     2.350   \n",
      "Gemini 1.5 Pro                             3.100   \n",
      "Gemma 3                                    2.383   \n",
      "Grok-3                                     3.250   \n",
      "MiniMax-01                                 1.633   \n",
      "Mistral Large                              3.850   \n",
      "Qwen2.5-Max                                2.150   \n",
      "Sonar                                      2.383   \n",
      "\n",
      "difficulty_combo      high_country_statistical_office_analysis  \\\n",
      "model_name                                                       \n",
      "Claude 3.5 Sonnet v2                                     3.494   \n",
      "Claude 3.7 Sonnet                                        3.894   \n",
      "DeepSeek-R1                                              2.350   \n",
      "GPT o3                                                   2.658   \n",
      "GPT-4o                                                   2.308   \n",
      "Gemini 1.5 Pro                                           2.931   \n",
      "Gemma 3                                                  2.742   \n",
      "Grok-3                                                   2.936   \n",
      "MiniMax-01                                               2.900   \n",
      "Mistral Large                                            2.981   \n",
      "Qwen2.5-Max                                              3.250   \n",
      "Sonar                                                    2.517   \n",
      "\n",
      "difficulty_combo      high_country_statistical_office_interpretation  \\\n",
      "model_name                                                             \n",
      "Claude 3.5 Sonnet v2                                           3.989   \n",
      "Claude 3.7 Sonnet                                              4.217   \n",
      "DeepSeek-R1                                                    3.856   \n",
      "GPT o3                                                         4.367   \n",
      "GPT-4o                                                         4.367   \n",
      "Gemini 1.5 Pro                                                 3.967   \n",
      "Gemma 3                                                        3.761   \n",
      "Grok-3                                                         3.267   \n",
      "MiniMax-01                                                     3.867   \n",
      "Mistral Large                                                  3.922   \n",
      "Qwen2.5-Max                                                    3.800   \n",
      "Sonar                                                          3.428   \n",
      "\n",
      "difficulty_combo      high_country_statistical_office_reading  \\\n",
      "model_name                                                      \n",
      "Claude 3.5 Sonnet v2                                    3.222   \n",
      "Claude 3.7 Sonnet                                       3.256   \n",
      "DeepSeek-R1                                             1.544   \n",
      "GPT o3                                                  2.700   \n",
      "GPT-4o                                                  2.211   \n",
      "Gemini 1.5 Pro                                          2.778   \n",
      "Gemma 3                                                 2.589   \n",
      "Grok-3                                                  3.233   \n",
      "MiniMax-01                                              2.000   \n",
      "Mistral Large                                           2.778   \n",
      "Qwen2.5-Max                                             2.711   \n",
      "Sonar                                                   3.156   \n",
      "\n",
      "difficulty_combo      high_region_atlas_analysis  \\\n",
      "model_name                                         \n",
      "Claude 3.5 Sonnet v2                       3.350   \n",
      "Claude 3.7 Sonnet                          2.536   \n",
      "DeepSeek-R1                                1.850   \n",
      "GPT o3                                     2.997   \n",
      "GPT-4o                                     2.242   \n",
      "Gemini 1.5 Pro                             1.844   \n",
      "Gemma 3                                    2.364   \n",
      "Grok-3                                     2.431   \n",
      "MiniMax-01                                 0.953   \n",
      "Mistral Large                              1.417   \n",
      "Qwen2.5-Max                                1.400   \n",
      "Sonar                                      2.317   \n",
      "\n",
      "difficulty_combo      high_region_atlas_interpretation  \\\n",
      "model_name                                               \n",
      "Claude 3.5 Sonnet v2                             4.083   \n",
      "Claude 3.7 Sonnet                                4.456   \n",
      "DeepSeek-R1                                      2.828   \n",
      "GPT o3                                           3.217   \n",
      "GPT-4o                                           3.789   \n",
      "Gemini 1.5 Pro                                   4.144   \n",
      "Gemma 3                                          3.783   \n",
      "Grok-3                                           2.911   \n",
      "MiniMax-01                                       4.422   \n",
      "Mistral Large                                    3.589   \n",
      "Qwen2.5-Max                                      3.017   \n",
      "Sonar                                            3.350   \n",
      "\n",
      "difficulty_combo      high_region_atlas_reading  low_country_atlas_analysis  \\\n",
      "model_name                                                                    \n",
      "Claude 3.5 Sonnet v2                      2.167                       3.800   \n",
      "Claude 3.7 Sonnet                         2.111                       3.867   \n",
      "DeepSeek-R1                               1.656                       2.983   \n",
      "GPT o3                                    3.333                       4.267   \n",
      "GPT-4o                                    1.089                       3.650   \n",
      "Gemini 1.5 Pro                            2.022                       4.308   \n",
      "Gemma 3                                   1.611                       3.442   \n",
      "Grok-3                                    2.544                       3.767   \n",
      "MiniMax-01                                1.089                       2.758   \n",
      "Mistral Large                             1.667                       3.525   \n",
      "Qwen2.5-Max                               2.067                       3.375   \n",
      "Sonar                                     1.544                       2.742   \n",
      "\n",
      "difficulty_combo      ...  low_country_atlas_reading  \\\n",
      "model_name            ...                              \n",
      "Claude 3.5 Sonnet v2  ...                      4.167   \n",
      "Claude 3.7 Sonnet     ...                      4.983   \n",
      "DeepSeek-R1           ...                      3.933   \n",
      "GPT o3                ...                      4.500   \n",
      "GPT-4o                ...                      2.300   \n",
      "Gemini 1.5 Pro        ...                      4.967   \n",
      "Gemma 3               ...                      1.583   \n",
      "Grok-3                ...                      3.233   \n",
      "MiniMax-01            ...                      3.333   \n",
      "Mistral Large         ...                      4.167   \n",
      "Qwen2.5-Max           ...                      3.233   \n",
      "Sonar                 ...                      2.933   \n",
      "\n",
      "difficulty_combo      low_country_statistical_office_analysis  \\\n",
      "model_name                                                      \n",
      "Claude 3.5 Sonnet v2                                    4.467   \n",
      "Claude 3.7 Sonnet                                       4.467   \n",
      "DeepSeek-R1                                             3.033   \n",
      "GPT o3                                                  4.267   \n",
      "GPT-4o                                                  4.033   \n",
      "Gemini 1.5 Pro                                          2.800   \n",
      "Gemma 3                                                 4.567   \n",
      "Grok-3                                                  3.100   \n",
      "MiniMax-01                                              4.067   \n",
      "Mistral Large                                           4.300   \n",
      "Qwen2.5-Max                                             4.367   \n",
      "Sonar                                                   4.000   \n",
      "\n",
      "difficulty_combo      low_country_statistical_office_interpretation  \\\n",
      "model_name                                                            \n",
      "Claude 3.5 Sonnet v2                                          2.750   \n",
      "Claude 3.7 Sonnet                                             3.233   \n",
      "DeepSeek-R1                                                   2.033   \n",
      "GPT o3                                                        3.683   \n",
      "GPT-4o                                                        2.350   \n",
      "Gemini 1.5 Pro                                                3.700   \n",
      "Gemma 3                                                       2.650   \n",
      "Grok-3                                                        4.083   \n",
      "MiniMax-01                                                    2.233   \n",
      "Mistral Large                                                 1.667   \n",
      "Qwen2.5-Max                                                   1.850   \n",
      "Sonar                                                         1.983   \n",
      "\n",
      "difficulty_combo      low_country_statistical_office_reading  \\\n",
      "model_name                                                     \n",
      "Claude 3.5 Sonnet v2                                   5.000   \n",
      "Claude 3.7 Sonnet                                      5.000   \n",
      "DeepSeek-R1                                            3.333   \n",
      "GPT o3                                                 1.667   \n",
      "GPT-4o                                                 1.667   \n",
      "Gemini 1.5 Pro                                         3.200   \n",
      "Gemma 3                                                1.667   \n",
      "Grok-3                                                 5.000   \n",
      "MiniMax-01                                             2.667   \n",
      "Mistral Large                                          3.200   \n",
      "Qwen2.5-Max                                            5.000   \n",
      "Sonar                                                  2.733   \n",
      "\n",
      "difficulty_combo      low_region_atlas_analysis  \\\n",
      "model_name                                        \n",
      "Claude 3.5 Sonnet v2                      4.567   \n",
      "Claude 3.7 Sonnet                         4.933   \n",
      "DeepSeek-R1                               4.333   \n",
      "GPT o3                                    4.333   \n",
      "GPT-4o                                    4.867   \n",
      "Gemini 1.5 Pro                            4.700   \n",
      "Gemma 3                                   4.867   \n",
      "Grok-3                                    4.533   \n",
      "MiniMax-01                                4.233   \n",
      "Mistral Large                             4.400   \n",
      "Qwen2.5-Max                               4.367   \n",
      "Sonar                                     4.267   \n",
      "\n",
      "difficulty_combo      low_region_atlas_interpretation  \\\n",
      "model_name                                              \n",
      "Claude 3.5 Sonnet v2                            4.517   \n",
      "Claude 3.7 Sonnet                               4.500   \n",
      "DeepSeek-R1                                     4.200   \n",
      "GPT o3                                          4.183   \n",
      "GPT-4o                                          4.000   \n",
      "Gemini 1.5 Pro                                  3.950   \n",
      "Gemma 3                                         3.967   \n",
      "Grok-3                                          3.567   \n",
      "MiniMax-01                                      4.417   \n",
      "Mistral Large                                   4.383   \n",
      "Qwen2.5-Max                                     3.967   \n",
      "Sonar                                           3.933   \n",
      "\n",
      "difficulty_combo      low_region_atlas_reading  \\\n",
      "model_name                                       \n",
      "Claude 3.5 Sonnet v2                     3.333   \n",
      "Claude 3.7 Sonnet                        3.167   \n",
      "DeepSeek-R1                              1.367   \n",
      "GPT o3                                   1.667   \n",
      "GPT-4o                                   3.167   \n",
      "Gemini 1.5 Pro                           3.200   \n",
      "Gemma 3                                  1.667   \n",
      "Grok-3                                   3.100   \n",
      "MiniMax-01                               3.000   \n",
      "Mistral Large                            3.200   \n",
      "Qwen2.5-Max                              3.333   \n",
      "Sonar                                    1.500   \n",
      "\n",
      "difficulty_combo      low_region_statistical_office_analysis  \\\n",
      "model_name                                                     \n",
      "Claude 3.5 Sonnet v2                                   3.333   \n",
      "Claude 3.7 Sonnet                                      4.158   \n",
      "DeepSeek-R1                                            2.458   \n",
      "GPT o3                                                 3.654   \n",
      "GPT-4o                                                 2.425   \n",
      "Gemini 1.5 Pro                                         2.421   \n",
      "Gemma 3                                                2.817   \n",
      "Grok-3                                                 3.646   \n",
      "MiniMax-01                                             2.742   \n",
      "Mistral Large                                          3.217   \n",
      "Qwen2.5-Max                                            1.679   \n",
      "Sonar                                                  2.054   \n",
      "\n",
      "difficulty_combo      low_region_statistical_office_interpretation  \\\n",
      "model_name                                                           \n",
      "Claude 3.5 Sonnet v2                                         3.929   \n",
      "Claude 3.7 Sonnet                                            4.675   \n",
      "DeepSeek-R1                                                  3.792   \n",
      "GPT o3                                                       4.100   \n",
      "GPT-4o                                                       4.262   \n",
      "Gemini 1.5 Pro                                               3.679   \n",
      "Gemma 3                                                      4.242   \n",
      "Grok-3                                                       4.175   \n",
      "MiniMax-01                                                   3.950   \n",
      "Mistral Large                                                4.200   \n",
      "Qwen2.5-Max                                                  3.883   \n",
      "Sonar                                                        2.596   \n",
      "\n",
      "difficulty_combo      low_region_statistical_office_reading  \n",
      "model_name                                                   \n",
      "Claude 3.5 Sonnet v2                                  3.217  \n",
      "Claude 3.7 Sonnet                                     3.833  \n",
      "DeepSeek-R1                                           3.117  \n",
      "GPT o3                                                3.483  \n",
      "GPT-4o                                                2.358  \n",
      "Gemini 1.5 Pro                                        3.183  \n",
      "Gemma 3                                               2.250  \n",
      "Grok-3                                                4.092  \n",
      "MiniMax-01                                            2.692  \n",
      "Mistral Large                                         4.025  \n",
      "Qwen2.5-Max                                           2.775  \n",
      "Sonar                                                 2.600  \n",
      "\n",
      "[12 rows x 21 columns]\n",
      "\n",
      "\n",
      "Models with perfect mean score (5.00) by difficulty combination:\n",
      "\n",
      "low_country_statistical_office_reading:\n",
      "  - Claude 3.5 Sonnet v2\n",
      "  - Claude 3.7 Sonnet\n",
      "  - Grok-3\n",
      "  - Qwen2.5-Max\n",
      "\n",
      "Saved mean difficulty profiles (wide format) to '../../results/model_difficulty_profiles_means.csv'\n",
      "Shape: (12, 22)\n",
      "Preview:\n",
      "difficulty_combo            model_name  high_country_atlas_analysis  \\\n",
      "0                 Claude 3.5 Sonnet v2                     3.833333   \n",
      "1                    Claude 3.7 Sonnet                     4.616667   \n",
      "2                          DeepSeek-R1                     2.150000   \n",
      "3                               GPT o3                     3.716667   \n",
      "4                               GPT-4o                     3.750000   \n",
      "\n",
      "difficulty_combo  high_country_atlas_interpretation  \\\n",
      "0                                          2.758333   \n",
      "1                                          4.391667   \n",
      "2                                          2.808333   \n",
      "3                                          3.083333   \n",
      "4                                          3.666667   \n",
      "\n",
      "difficulty_combo  high_country_atlas_reading  \\\n",
      "0                                   4.050000   \n",
      "1                                   3.250000   \n",
      "2                                   2.950000   \n",
      "3                                   3.183333   \n",
      "4                                   2.350000   \n",
      "\n",
      "difficulty_combo  high_country_statistical_office_analysis  \\\n",
      "0                                                 3.494444   \n",
      "1                                                 3.894444   \n",
      "2                                                 2.350000   \n",
      "3                                                 2.658333   \n",
      "4                                                 2.308333   \n",
      "\n",
      "difficulty_combo  high_country_statistical_office_interpretation  \\\n",
      "0                                                       3.988889   \n",
      "1                                                       4.216667   \n",
      "2                                                       3.855556   \n",
      "3                                                       4.366667   \n",
      "4                                                       4.366667   \n",
      "\n",
      "difficulty_combo  high_country_statistical_office_reading  \\\n",
      "0                                                3.222222   \n",
      "1                                                3.255556   \n",
      "2                                                1.544444   \n",
      "3                                                2.700000   \n",
      "4                                                2.211111   \n",
      "\n",
      "difficulty_combo  high_region_atlas_analysis  \\\n",
      "0                                   3.350000   \n",
      "1                                   2.536111   \n",
      "2                                   1.850000   \n",
      "3                                   2.997222   \n",
      "4                                   2.241667   \n",
      "\n",
      "difficulty_combo  high_region_atlas_interpretation  high_region_atlas_reading  \\\n",
      "0                                         4.083333                   2.166667   \n",
      "1                                         4.455556                   2.111111   \n",
      "2                                         2.827778                   1.655556   \n",
      "3                                         3.216667                   3.333333   \n",
      "4                                         3.788889                   1.088889   \n",
      "\n",
      "difficulty_combo  ...  low_country_atlas_reading  \\\n",
      "0                 ...                   4.166667   \n",
      "1                 ...                   4.983333   \n",
      "2                 ...                   3.933333   \n",
      "3                 ...                   4.500000   \n",
      "4                 ...                   2.300000   \n",
      "\n",
      "difficulty_combo  low_country_statistical_office_analysis  \\\n",
      "0                                                4.466667   \n",
      "1                                                4.466667   \n",
      "2                                                3.033333   \n",
      "3                                                4.266667   \n",
      "4                                                4.033333   \n",
      "\n",
      "difficulty_combo  low_country_statistical_office_interpretation  \\\n",
      "0                                                      2.750000   \n",
      "1                                                      3.233333   \n",
      "2                                                      2.033333   \n",
      "3                                                      3.683333   \n",
      "4                                                      2.350000   \n",
      "\n",
      "difficulty_combo  low_country_statistical_office_reading  \\\n",
      "0                                               5.000000   \n",
      "1                                               5.000000   \n",
      "2                                               3.333333   \n",
      "3                                               1.666667   \n",
      "4                                               1.666667   \n",
      "\n",
      "difficulty_combo  low_region_atlas_analysis  low_region_atlas_interpretation  \\\n",
      "0                                  4.566667                         4.516667   \n",
      "1                                  4.933333                         4.500000   \n",
      "2                                  4.333333                         4.200000   \n",
      "3                                  4.333333                         4.183333   \n",
      "4                                  4.866667                         4.000000   \n",
      "\n",
      "difficulty_combo  low_region_atlas_reading  \\\n",
      "0                                 3.333333   \n",
      "1                                 3.166667   \n",
      "2                                 1.366667   \n",
      "3                                 1.666667   \n",
      "4                                 3.166667   \n",
      "\n",
      "difficulty_combo  low_region_statistical_office_analysis  \\\n",
      "0                                               3.333333   \n",
      "1                                               4.158333   \n",
      "2                                               2.458333   \n",
      "3                                               3.654167   \n",
      "4                                               2.425000   \n",
      "\n",
      "difficulty_combo  low_region_statistical_office_interpretation  \\\n",
      "0                                                     3.929167   \n",
      "1                                                     4.675000   \n",
      "2                                                     3.791667   \n",
      "3                                                     4.100000   \n",
      "4                                                     4.262500   \n",
      "\n",
      "difficulty_combo  low_region_statistical_office_reading  \n",
      "0                                              3.216667  \n",
      "1                                              3.833333  \n",
      "2                                              3.116667  \n",
      "3                                              3.483333  \n",
      "4                                              2.358333  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "\n",
      "Best models per difficulty combination:\n",
      "\n",
      "high_country_atlas_analysis:\n",
      "  1st: Claude 3.7 Sonnet (M=4.617)\n",
      "  2nd: Gemini 1.5 Pro (M=4.500)\n",
      "\n",
      "high_country_atlas_interpretation:\n",
      "  1st: Claude 3.7 Sonnet (M=4.392)\n",
      "  2nd: MiniMax-01 (M=3.817)\n",
      "\n",
      "high_country_atlas_reading:\n",
      "  1st: Claude 3.5 Sonnet v2 (M=4.050)\n",
      "  2nd: Mistral Large (M=3.850)\n",
      "\n",
      "high_country_statistical_office_analysis:\n",
      "  1st: Claude 3.7 Sonnet (M=3.894)\n",
      "  2nd: Claude 3.5 Sonnet v2 (M=3.494)\n",
      "\n",
      "high_country_statistical_office_interpretation:\n",
      "  1st: GPT o3 (M=4.367)\n",
      "  2nd: GPT-4o (M=4.367)\n",
      "\n",
      "high_country_statistical_office_reading:\n",
      "  1st: Claude 3.7 Sonnet (M=3.256)\n",
      "  2nd: Grok-3 (M=3.233)\n",
      "\n",
      "high_region_atlas_analysis:\n",
      "  1st: Claude 3.5 Sonnet v2 (M=3.350)\n",
      "  2nd: GPT o3 (M=2.997)\n",
      "\n",
      "high_region_atlas_interpretation:\n",
      "  1st: Claude 3.7 Sonnet (M=4.456)\n",
      "  2nd: MiniMax-01 (M=4.422)\n",
      "\n",
      "high_region_atlas_reading:\n",
      "  1st: GPT o3 (M=3.333)\n",
      "  2nd: Grok-3 (M=2.544)\n",
      "\n",
      "low_country_atlas_analysis:\n",
      "  1st: Gemini 1.5 Pro (M=4.308)\n",
      "  2nd: GPT o3 (M=4.267)\n",
      "\n",
      "low_country_atlas_interpretation:\n",
      "  1st: Claude 3.7 Sonnet (M=4.658)\n",
      "  2nd: Mistral Large (M=4.342)\n",
      "\n",
      "low_country_atlas_reading:\n",
      "  1st: Claude 3.7 Sonnet (M=4.983)\n",
      "  2nd: Gemini 1.5 Pro (M=4.967)\n",
      "\n",
      "low_country_statistical_office_analysis:\n",
      "  1st: Gemma 3 (M=4.567)\n",
      "  2nd: Claude 3.5 Sonnet v2 (M=4.467)\n",
      "\n",
      "low_country_statistical_office_interpretation:\n",
      "  1st: Grok-3 (M=4.083)\n",
      "  2nd: Gemini 1.5 Pro (M=3.700)\n",
      "\n",
      "low_country_statistical_office_reading:\n",
      "  1st: Claude 3.5 Sonnet v2 (M=5.000)\n",
      "  2nd: Claude 3.7 Sonnet (M=5.000)\n",
      "\n",
      "low_region_atlas_analysis:\n",
      "  1st: Claude 3.7 Sonnet (M=4.933)\n",
      "  2nd: GPT-4o (M=4.867)\n",
      "\n",
      "low_region_atlas_interpretation:\n",
      "  1st: Claude 3.5 Sonnet v2 (M=4.517)\n",
      "  2nd: Claude 3.7 Sonnet (M=4.500)\n",
      "\n",
      "low_region_atlas_reading:\n",
      "  1st: Claude 3.5 Sonnet v2 (M=3.333)\n",
      "  2nd: Qwen2.5-Max (M=3.333)\n",
      "\n",
      "low_region_statistical_office_analysis:\n",
      "  1st: Claude 3.7 Sonnet (M=4.158)\n",
      "  2nd: GPT o3 (M=3.654)\n",
      "\n",
      "low_region_statistical_office_interpretation:\n",
      "  1st: Claude 3.7 Sonnet (M=4.675)\n",
      "  2nd: GPT-4o (M=4.263)\n",
      "\n",
      "low_region_statistical_office_reading:\n",
      "  1st: Grok-3 (M=4.092)\n",
      "  2nd: Mistral Large (M=4.025)\n",
      "\n",
      "\n",
      "Model specialization (times ranked 1st):\n",
      "  Claude 3.7 Sonnet: 10/21 (47.6%)\n",
      "  Claude 3.5 Sonnet v2: 5/21 (23.8%)\n",
      "  Grok-3: 2/21 (9.5%)\n",
      "  GPT o3: 2/21 (9.5%)\n",
      "  Gemini 1.5 Pro: 1/21 (4.8%)\n",
      "  Gemma 3: 1/21 (4.8%)\n",
      "\n",
      "\n",
      "Cluster Analysis:\n",
      "Silhouette scores for different k: {2: 0.1617581229454909, 3: 0.1462751206484514, 4: 0.14309861286186268, 5: 0.1609622264512788}\n",
      "Optimal number of clusters: 2\n",
      "\n",
      "Model cluster assignments (k=2):\n",
      "  Cluster 0: DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar\n",
      "  Cluster 1: Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large\n",
      "\n",
      "Cluster characteristics:\n",
      "\n",
      "  Cluster 0:\n",
      "    Overall: M=2.872, SD=2.040\n",
      "    Low graphically complex maps: M=3.084\n",
      "    High graphically complex maps: M=2.660\n",
      "\n",
      "  Cluster 1:\n",
      "    Overall: M=3.499, SD=1.895\n",
      "    Low graphically complex maps: M=3.796\n",
      "    High graphically complex maps: M=3.201\n",
      "\n",
      "\n",
      "Statistical tests per difficulty combination:\n",
      "\n",
      "Combinations significant before FDR (trends):\n",
      "  low_region_statistical_office_analysis: H=24.23, p=0.0118, ε²=0.100\n",
      "  low_region_statistical_office_interpretation: H=24.72, p=0.0100, ε²=0.104\n",
      "  low_country_atlas_reading: H=20.85, p=0.0350, ε²=0.164\n",
      "\n",
      "Total combinations tested: 21\n",
      "Significant before correction: 3\n",
      "Significant after FDR correction: 0\n",
      "\n",
      "Significant differences after FDR correction:\n",
      "  None - no significant differences after correction\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:54.625442Z",
     "start_time": "2025-10-05T13:48:54.622349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check missing combinations\n",
    "df_batch[\n",
    "    (df_batch['graphical_complexity'] == 'high') &\n",
    "    (df_batch['nuts_level'] == 'region') &\n",
    "    (df_batch['map_source'] == 'statistical_office')\n",
    "].shape[0]"
   ],
   "id": "f6d802ac69d6d09e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:54.708438Z",
     "start_time": "2025-10-05T13:48:54.667948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify \"easiest tasks\" claim\n",
    "print(\"\\n1. EASIEST TASKS VERIFICATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Calculate mean scores for each combination across all models\n",
    "combo_means = df_d3.groupby('difficulty_combo')['score'].agg(['mean', 'std', 'count'])\n",
    "combo_means_sorted = combo_means.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"\\nMean scores by difficulty combination (top 10):\")\n",
    "print(combo_means_sorted.head(10).round(3))\n",
    "\n",
    "print(\"\\nCombinations with mean scores > 4.00:\")\n",
    "high_performing = combo_means_sorted[combo_means_sorted['mean'] > 4.00]\n",
    "print(high_performing.round(3))\n",
    "\n",
    "# Check specific low_country reading tasks\n",
    "print(\"\\nDetailed look at 'reading simple country-level maps':\")\n",
    "reading_country = [c for c in valid_combos if 'country' in c and 'reading' in c and 'low' in c]\n",
    "for combo in reading_country:\n",
    "    combo_data = df_d3[df_d3['difficulty_combo'] == combo]\n",
    "    model_scores = combo_data.groupby('model_name')['score'].mean().sort_values(ascending=False)\n",
    "    models_above_4 = (model_scores > 4.0).sum()\n",
    "    total_models = len(model_scores)\n",
    "\n",
    "    print(f\"\\n  {combo}:\")\n",
    "    print(f\"    Overall mean: {combo_data['score'].mean():.3f}\")\n",
    "    print(f\"    Models with scores > 4.00: {models_above_4}/{total_models} ({100*models_above_4/total_models:.1f}%)\")\n",
    "    print(f\"    Score range: {model_scores.min():.3f} - {model_scores.max():.3f}\")\n",
    "\n",
    "# Most challenging task verification\n",
    "print(\"\\n\\n2. MOST CHALLENGING TASK VERIFICATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nCombinations with lowest mean scores (bottom 10):\")\n",
    "print(combo_means_sorted.tail(10).round(3))\n",
    "\n",
    "# Specific check for high_region_atlas_analysis\n",
    "high_region_analysis = df_d3[df_d3['difficulty_combo'] == 'high_region_atlas_analysis']\n",
    "print(f\"\\nhigh_region_atlas_analysis detailed statistics:\")\n",
    "print(f\"  Overall mean: {high_region_analysis['score'].mean():.3f}\")\n",
    "print(f\"  SD: {high_region_analysis['score'].std():.3f}\")\n",
    "print(f\"  N: {len(high_region_analysis)}\")\n",
    "print(f\"  Range: {high_region_analysis['score'].min():.3f} - {high_region_analysis['score'].max():.3f}\")\n",
    "\n",
    "# GPT o3 tie verification\n",
    "print(\"\\n\\n3. GPT O3 PERFORMANCE VERIFICATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "combo = 'high_country_statistical_office_interpretation'\n",
    "combo_data = df_d3[df_d3['difficulty_combo'] == combo]\n",
    "model_scores = combo_data.groupby('model_name')['score'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nScores for {combo}:\")\n",
    "print(model_scores.round(3))\n",
    "\n",
    "top_score = model_scores.iloc[0]\n",
    "top_models = model_scores[model_scores == top_score]\n",
    "print(f\"\\nTop performers (M={top_score:.3f}):\")\n",
    "for model in top_models.index:\n",
    "    print(f\"  - {model}\")\n",
    "\n",
    "if len(top_models) > 1:\n",
    "    print(f\"\\nTIED: {len(top_models)} models share the top score\")\n",
    "else:\n",
    "    print(f\"\\nSingle leader: {top_models.index[0]}\")\n",
    "\n",
    "# Regional vs Country comparison\n",
    "print(\"\\n\\n4. REGIONAL VS COUNTRY PERFORMANCE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Parse nuts_level from difficulty_combo\n",
    "df_d3['nuts_parsed'] = df_d3['difficulty_combo'].str.split('_').str[1]\n",
    "\n",
    "regional_mean = df_d3[df_d3['nuts_parsed'] == 'region']['score'].mean()\n",
    "country_mean = df_d3[df_d3['nuts_parsed'] == 'country']['score'].mean()\n",
    "\n",
    "print(f\"\\nOverall performance by spatial aggregation:\")\n",
    "print(f\"  Regional maps: M={regional_mean:.3f}, SD={df_d3[df_d3['nuts_parsed'] == 'region']['score'].std():.3f}\")\n",
    "print(f\"  Country maps: M={country_mean:.3f}, SD={df_d3[df_d3['nuts_parsed'] == 'country']['score'].std():.3f}\")\n",
    "print(f\"  Difference: {country_mean - regional_mean:.3f} (country performs better: {country_mean > regional_mean})\")\n",
    "\n",
    "# Break down by other conditions\n",
    "print(\"\\nRegional vs Country by graphical complexity:\")\n",
    "for complexity in df_d3['graphical_complexity'].unique():\n",
    "    subset = df_d3[df_d3['graphical_complexity'] == complexity]\n",
    "    reg_mean = subset[subset['nuts_parsed'] == 'region']['score'].mean()\n",
    "    coun_mean = subset[subset['nuts_parsed'] == 'country']['score'].mean()\n",
    "    print(f\"  {complexity}: Regional={reg_mean:.3f}, Country={coun_mean:.3f}, Diff={coun_mean-reg_mean:.3f}\")\n",
    "\n",
    "print(\"\\nRegional vs Country by map source:\")\n",
    "for source in df_d3['map_source'].unique():\n",
    "    subset = df_d3[df_d3['map_source'] == source]\n",
    "    reg_mean = subset[subset['nuts_parsed'] == 'region']['score'].mean()\n",
    "    coun_mean = subset[subset['nuts_parsed'] == 'country']['score'].mean()\n",
    "    print(f\"  {source}: Regional={reg_mean:.3f}, Country={coun_mean:.3f}, Diff={coun_mean-reg_mean:.3f}\")\n",
    "\n",
    "print(\"\\nRegional vs Country by task type:\")\n",
    "for task in df_d3['map_usage_type'].unique():\n",
    "    subset = df_d3[df_d3['map_usage_type'] == task]\n",
    "    reg_mean = subset[subset['nuts_parsed'] == 'region']['score'].mean()\n",
    "    coun_mean = subset[subset['nuts_parsed'] == 'country']['score'].mean()\n",
    "    print(f\"  {task}: Regional={reg_mean:.3f}, Country={coun_mean:.3f}, Diff={coun_mean-reg_mean:.3f}\")\n",
    "\n",
    "# Range analysis across all combinations\n",
    "print(\"\\n\\n5. RANGE ANALYSIS ACROSS COMBINATIONS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Calculate range for each combination\n",
    "combo_ranges = {}\n",
    "for combo in valid_combos:\n",
    "    combo_data = df_d3[df_d3['difficulty_combo'] == combo]\n",
    "    model_scores = combo_data.groupby('model_name')['score'].mean()\n",
    "    combo_ranges[combo] = {\n",
    "        'range': model_scores.max() - model_scores.min(),\n",
    "        'min': model_scores.min(),\n",
    "        'max': model_scores.max(),\n",
    "        'std': model_scores.std()\n",
    "    }\n",
    "\n",
    "# Sort by range\n",
    "ranges_df = pd.DataFrame(combo_ranges).T.sort_values('range', ascending=False)\n",
    "\n",
    "print(\"\\nCombinations with widest performance spreads (top 10):\")\n",
    "print(ranges_df.head(10).round(3))\n",
    "\n",
    "print(\"\\nCombinations with narrowest performance spreads (bottom 10):\")\n",
    "print(ranges_df.tail(10).round(3))\n",
    "\n",
    "# Check specific claim about country statistical_office reading\n",
    "country_inst_reading = [c for c in valid_combos if 'country' in c and 'statistical_office' in c and 'reading' in c]\n",
    "print(\"\\nCountry-level statistical_office reading tasks:\")\n",
    "for combo in country_inst_reading:\n",
    "    if combo in combo_ranges:\n",
    "        print(f\"  {combo}:\")\n",
    "        print(f\"    Range: {combo_ranges[combo]['range']:.3f} (min={combo_ranges[combo]['min']:.3f}, max={combo_ranges[combo]['max']:.3f})\")\n",
    "\n",
    "# Complex interpretation compression\n",
    "print(\"\\n\\n6. DISTRIBUTION COMPRESSION BY TASK TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Parse task type and complexity from difficulty_combo\n",
    "df_d3['complexity_parsed'] = df_d3['difficulty_combo'].str.split('_').str[0]\n",
    "df_d3['task_parsed'] = df_d3['difficulty_combo'].str.split('_').str[-1]\n",
    "\n",
    "# Calculate variance/range by task type and complexity\n",
    "print(\"\\nVariance and range by task type and graphical complexity:\")\n",
    "for task in df_d3['task_parsed'].unique():\n",
    "    print(f\"\\n{task.upper()}:\")\n",
    "    for complexity in df_d3['complexity_parsed'].unique():\n",
    "        subset = df_d3[(df_d3['task_parsed'] == task) & (df_d3['complexity_parsed'] == complexity)]\n",
    "        if len(subset) > 0:\n",
    "            # Get model-level means for this subset\n",
    "            model_means = subset.groupby('model_name')['score'].mean()\n",
    "            print(f\"  {complexity}: Range={model_means.max()-model_means.min():.3f}, SD={model_means.std():.3f}, Mean={model_means.mean():.3f}\")\n",
    "\n",
    "# Overall by task type\n",
    "print(\"\\nOverall distribution characteristics by task type:\")\n",
    "task_stats = []\n",
    "for task in df_d3['task_parsed'].unique():\n",
    "    subset = df_d3[df_d3['task_parsed'] == task]\n",
    "    model_means = subset.groupby('model_name')['score'].mean()\n",
    "    task_stats.append({\n",
    "        'task': task,\n",
    "        'mean': model_means.mean(),\n",
    "        'std': model_means.std(),\n",
    "        'range': model_means.max() - model_means.min(),\n",
    "        'cv': model_means.std() / model_means.mean() if model_means.mean() > 0 else np.nan\n",
    "    })\n",
    "\n",
    "task_stats_df = pd.DataFrame(task_stats).sort_values('range', ascending=False)\n",
    "print(task_stats_df.round(3))\n",
    "\n",
    "# Cluster performance on simple vs complex\n",
    "print(\"\\n\\n7. CLUSTER PERFORMANCE ON GRAPHICAL COMPLEXITY\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if cluster_analysis is not None:\n",
    "    print(\"\\nRecalculating cluster performance by graphical complexity:\")\n",
    "\n",
    "    for cluster_id in range(cluster_analysis['optimal_k']):\n",
    "        cluster_models = [m for m, c in cluster_analysis['model_clusters'].items() if c == cluster_id]\n",
    "        cluster_data = df_d3[df_d3['model_name'].isin(cluster_models)]\n",
    "\n",
    "        print(f\"\\nCluster {cluster_id} ({len(cluster_models)} models):\")\n",
    "        print(f\"  Models: {', '.join(cluster_models)}\")\n",
    "\n",
    "        # Check if we have the graphical_complexity column\n",
    "        if 'graphical_complexity' in cluster_data.columns:\n",
    "            for complexity in cluster_data['graphical_complexity'].unique():\n",
    "                complexity_subset = cluster_data[cluster_data['graphical_complexity'] == complexity]\n",
    "                if len(complexity_subset) > 0:\n",
    "                    print(f\"  {complexity}: M={complexity_subset['score'].mean():.3f}, SD={complexity_subset['score'].std():.3f}, N={len(complexity_subset)}\")\n",
    "        else:\n",
    "            # Parse from difficulty_combo if needed\n",
    "            for complexity in ['low', 'high']:\n",
    "                complexity_subset = cluster_data[cluster_data['difficulty_combo'].str.startswith(complexity)]\n",
    "                if len(complexity_subset) > 0:\n",
    "                    print(f\"  {complexity}: M={complexity_subset['score'].mean():.3f}, SD={complexity_subset['score'].std():.3f}, N={len(complexity_subset)}\")"
   ],
   "id": "2f312455e7ef417f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. EASIEST TASKS VERIFICATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Mean scores by difficulty combination (top 10):\n",
      "                                                 mean    std  count\n",
      "difficulty_combo                                                   \n",
      "low_region_atlas_analysis                       4.533  0.414     36\n",
      "low_region_atlas_interpretation                 4.132  0.485     36\n",
      "low_region_statistical_office_interpretation    3.957  1.100    144\n",
      "low_country_statistical_office_analysis         3.956  1.291     36\n",
      "high_country_statistical_office_interpretation  3.900  0.867    108\n",
      "high_region_atlas_interpretation                3.632  1.437    108\n",
      "low_country_atlas_reading                       3.611  2.117     72\n",
      "low_country_atlas_analysis                      3.540  1.644     72\n",
      "low_country_atlas_interpretation                3.531  1.712     72\n",
      "high_country_atlas_interpretation               3.394  1.804     72\n",
      "\n",
      "Combinations with mean scores > 4.00:\n",
      "                                  mean    std  count\n",
      "difficulty_combo                                    \n",
      "low_region_atlas_analysis        4.533  0.414     36\n",
      "low_region_atlas_interpretation  4.132  0.485     36\n",
      "\n",
      "Detailed look at 'reading simple country-level maps':\n",
      "\n",
      "  low_country_atlas_reading:\n",
      "    Overall mean: 3.611\n",
      "    Models with scores > 4.00: 5/12 (41.7%)\n",
      "    Score range: 1.583 - 4.983\n",
      "\n",
      "  low_country_statistical_office_reading:\n",
      "    Overall mean: 3.344\n",
      "    Models with scores > 4.00: 4/12 (33.3%)\n",
      "    Score range: 1.667 - 5.000\n",
      "\n",
      "\n",
      "2. MOST CHALLENGING TASK VERIFICATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Combinations with lowest mean scores (bottom 10):\n",
      "                                                mean    std  count\n",
      "difficulty_combo                                                  \n",
      "low_region_statistical_office_reading          3.135  2.242    144\n",
      "high_country_atlas_analysis                    3.131  2.054     72\n",
      "high_country_statistical_office_analysis       2.913  2.040    108\n",
      "low_region_statistical_office_analysis         2.884  2.042    144\n",
      "high_country_atlas_reading                     2.878  2.330     72\n",
      "low_country_statistical_office_interpretation  2.685  1.818     36\n",
      "high_country_statistical_office_reading        2.681  2.419    108\n",
      "low_region_atlas_reading                       2.642  2.406     36\n",
      "high_region_atlas_analysis                     2.142  2.184    108\n",
      "high_region_atlas_reading                      1.908  2.365    108\n",
      "\n",
      "high_region_atlas_analysis detailed statistics:\n",
      "  Overall mean: 2.142\n",
      "  SD: 2.184\n",
      "  N: 108\n",
      "  Range: 0.000 - 5.000\n",
      "\n",
      "\n",
      "3. GPT O3 PERFORMANCE VERIFICATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Scores for high_country_statistical_office_interpretation:\n",
      "model_name\n",
      "GPT o3                  4.367\n",
      "GPT-4o                  4.367\n",
      "Claude 3.7 Sonnet       4.217\n",
      "Claude 3.5 Sonnet v2    3.989\n",
      "Gemini 1.5 Pro          3.967\n",
      "Mistral Large           3.922\n",
      "MiniMax-01              3.867\n",
      "DeepSeek-R1             3.856\n",
      "Qwen2.5-Max             3.800\n",
      "Gemma 3                 3.761\n",
      "Sonar                   3.428\n",
      "Grok-3                  3.267\n",
      "Name: score, dtype: float64\n",
      "\n",
      "Top performers (M=4.367):\n",
      "  - GPT o3\n",
      "  - GPT-4o\n",
      "\n",
      "TIED: 2 models share the top score\n",
      "\n",
      "\n",
      "4. REGIONAL VS COUNTRY PERFORMANCE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall performance by spatial aggregation:\n",
      "  Regional maps: M=3.094, SD=2.028\n",
      "  Country maps: M=3.277, SD=1.954\n",
      "  Difference: 0.183 (country performs better: True)\n",
      "\n",
      "Regional vs Country by graphical complexity:\n",
      "  low: Regional=3.414, Country=3.483, Diff=0.069\n",
      "  high: Regional=2.561, Country=3.153, Diff=0.592\n",
      "\n",
      "Regional vs Country by map source:\n",
      "  atlas: Regional=2.863, Country=3.348, Diff=0.485\n",
      "  statistical_office: Regional=3.325, Country=3.206, Diff=-0.119\n",
      "\n",
      "Regional vs Country by task type:\n",
      "  reading: Regional=2.614, Country=3.046, Diff=0.432\n",
      "  analysis: Regional=2.812, Country=3.255, Diff=0.443\n",
      "  interpretation: Regional=3.857, Country=3.530, Diff=-0.328\n",
      "\n",
      "\n",
      "5. RANGE ANALYSIS ACROSS COMBINATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Combinations with widest performance spreads (top 10):\n",
      "                                               range    min    max    std\n",
      "low_country_atlas_reading                      3.400  1.583  4.983  1.039\n",
      "low_country_statistical_office_reading         3.333  1.667  5.000  1.358\n",
      "high_country_atlas_analysis                    3.233  1.383  4.617  1.020\n",
      "low_region_statistical_office_analysis         2.479  1.679  4.158  0.731\n",
      "high_country_atlas_reading                     2.417  1.633  4.050  0.713\n",
      "low_country_statistical_office_interpretation  2.417  1.667  4.083  0.812\n",
      "high_region_atlas_analysis                     2.397  0.953  3.350  0.686\n",
      "low_country_atlas_interpretation               2.292  2.367  4.658  0.763\n",
      "high_region_atlas_reading                      2.244  1.089  3.333  0.623\n",
      "low_region_statistical_office_interpretation   2.079  2.596  4.675  0.503\n",
      "\n",
      "Combinations with narrowest performance spreads (bottom 10):\n",
      "                                                range    min    max    std\n",
      "low_region_statistical_office_reading           1.842  2.250  4.092  0.627\n",
      "low_country_statistical_office_analysis         1.767  2.800  4.567  0.619\n",
      "high_country_statistical_office_reading         1.711  1.544  3.256  0.536\n",
      "high_country_atlas_interpretation               1.633  2.758  4.392  0.500\n",
      "high_region_atlas_interpretation                1.628  2.828  4.456  0.573\n",
      "high_country_statistical_office_analysis        1.586  2.308  3.894  0.463\n",
      "low_country_atlas_analysis                      1.567  2.742  4.308  0.518\n",
      "high_country_statistical_office_interpretation  1.100  3.267  4.367  0.331\n",
      "low_region_atlas_interpretation                 0.950  3.567  4.517  0.286\n",
      "low_region_atlas_analysis                       0.700  4.233  4.933  0.252\n",
      "\n",
      "Country-level statistical_office reading tasks:\n",
      "  high_country_statistical_office_reading:\n",
      "    Range: 1.711 (min=1.544, max=3.256)\n",
      "  low_country_statistical_office_reading:\n",
      "    Range: 3.333 (min=1.667, max=5.000)\n",
      "\n",
      "\n",
      "6. DISTRIBUTION COMPRESSION BY TASK TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Variance and range by task type and graphical complexity:\n",
      "\n",
      "READING:\n",
      "  low: Range=2.246, SD=0.680, Mean=3.219\n",
      "  high: Range=1.492, SD=0.497, Mean=2.441\n",
      "\n",
      "ANALYSIS:\n",
      "  low: Range=1.475, SD=0.474, Mean=3.388\n",
      "  high: Range=1.775, SD=0.539, Mean=2.678\n",
      "\n",
      "INTERPRETATION:\n",
      "  low: Range=1.827, SD=0.434, Mean=3.713\n",
      "  high: Range=1.181, SD=0.376, Mean=3.673\n",
      "\n",
      "Overall distribution characteristics by task type:\n",
      "             task   mean    std  range     cv\n",
      "2  interpretation  3.693  0.367  1.462  0.099\n",
      "0         reading  2.830  0.538  1.450  0.190\n",
      "1        analysis  3.033  0.472  1.449  0.156\n",
      "\n",
      "\n",
      "7. CLUSTER PERFORMANCE ON GRAPHICAL COMPLEXITY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Recalculating cluster performance by graphical complexity:\n",
      "\n",
      "Cluster 0 (6 models):\n",
      "  Models: DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar\n",
      "  low: M=3.084, SD=1.964, N=432\n",
      "  high: M=2.660, SD=2.094, N=432\n",
      "\n",
      "Cluster 1 (6 models):\n",
      "  Models: Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large\n",
      "  low: M=3.796, SD=1.682, N=432\n",
      "  high: M=3.201, SD=2.046, N=432\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:48:54.773338Z",
     "start_time": "2025-10-05T13:48:54.771491Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5f35fc0bd8bc5e47",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
