{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23957d30276d0b08",
   "metadata": {},
   "source": [
    "# Batch-only Analysis\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "2. M1-M5 tests: Main Effects (model, country, license, map usage type, task type)\n",
    "3. C1-C6 tests: Map Characteristics (graphical complexity, spatial aggregation level, map source, viz technique, symbol scaling, diagram structure)\n",
    "4. I1-I4 tests: Interactions (model×map usage type, graphical complexity×map usage type, model×graphical complexity, model×spatial aggregation level)\n",
    "5. P1 test: Clusters"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.033330Z",
     "start_time": "2025-11-30T20:28:05.665958Z"
    }
   },
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import shapiro, kruskal, mannwhitneyu, levene, t, sem, rankdata, chi2, kendalltau\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_batch = pd.read_csv('../../data/cleaned_data/data_batch_only.csv', index_col='answer_id')\n",
    "\n",
    "df_batch.sample(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     model_name provider_country licence_type        map_code  \\\n",
       "answer_id                                                                       \n",
       "1549                      Sonar              USA         paid  MULTI-G-INST-3   \n",
       "107                      GPT-4o              USA         paid  MULTI-G-INST-2   \n",
       "946        Claude 3.5 Sonnet v2              USA         paid   MULTI-G-ATL-2   \n",
       "426                      GPT o3              USA         paid   MULTI-D-ATL-3   \n",
       "1126          Claude 3.7 Sonnet              USA         paid   MULTI-D-ATL-1   \n",
       "\n",
       "          graphical_complexity viz_technique        symbol_scaling  \\\n",
       "answer_id                                                            \n",
       "1549                      high           NaN  proportional symbols   \n",
       "107                       high           NaN  proportional symbols   \n",
       "946                       high           NaN     graduated symbols   \n",
       "426                       high           NaN     graduated symbols   \n",
       "1126                      high           NaN     graduated symbols   \n",
       "\n",
       "          diagram_structure          map_source  question_id nuts_level  \\\n",
       "answer_id                                                                 \n",
       "1549                uniform  statistical_office          109    country   \n",
       "107              structural  statistical_office          107    country   \n",
       "946              structural               atlas           82    country   \n",
       "426                 uniform               atlas          138     region   \n",
       "1126                uniform               atlas          118     region   \n",
       "\n",
       "           map_usage_type       task_type test_mode  score  \n",
       "answer_id                                                   \n",
       "1549              reading        identify     batch   0.00  \n",
       "107        interpretation    cause/effect     batch   4.75  \n",
       "946               reading        identify     batch   4.90  \n",
       "426               reading  retrieve value     batch   5.00  \n",
       "1126              reading        identify     batch   4.50  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>provider_country</th>\n",
       "      <th>licence_type</th>\n",
       "      <th>map_code</th>\n",
       "      <th>graphical_complexity</th>\n",
       "      <th>viz_technique</th>\n",
       "      <th>symbol_scaling</th>\n",
       "      <th>diagram_structure</th>\n",
       "      <th>map_source</th>\n",
       "      <th>question_id</th>\n",
       "      <th>nuts_level</th>\n",
       "      <th>map_usage_type</th>\n",
       "      <th>task_type</th>\n",
       "      <th>test_mode</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>MULTI-G-INST-3</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proportional symbols</td>\n",
       "      <td>uniform</td>\n",
       "      <td>statistical_office</td>\n",
       "      <td>109</td>\n",
       "      <td>country</td>\n",
       "      <td>reading</td>\n",
       "      <td>identify</td>\n",
       "      <td>batch</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>MULTI-G-INST-2</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proportional symbols</td>\n",
       "      <td>structural</td>\n",
       "      <td>statistical_office</td>\n",
       "      <td>107</td>\n",
       "      <td>country</td>\n",
       "      <td>interpretation</td>\n",
       "      <td>cause/effect</td>\n",
       "      <td>batch</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Claude 3.5 Sonnet v2</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>MULTI-G-ATL-2</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated symbols</td>\n",
       "      <td>structural</td>\n",
       "      <td>atlas</td>\n",
       "      <td>82</td>\n",
       "      <td>country</td>\n",
       "      <td>reading</td>\n",
       "      <td>identify</td>\n",
       "      <td>batch</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>GPT o3</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>MULTI-D-ATL-3</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated symbols</td>\n",
       "      <td>uniform</td>\n",
       "      <td>atlas</td>\n",
       "      <td>138</td>\n",
       "      <td>region</td>\n",
       "      <td>reading</td>\n",
       "      <td>retrieve value</td>\n",
       "      <td>batch</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>Claude 3.7 Sonnet</td>\n",
       "      <td>USA</td>\n",
       "      <td>paid</td>\n",
       "      <td>MULTI-D-ATL-1</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated symbols</td>\n",
       "      <td>uniform</td>\n",
       "      <td>atlas</td>\n",
       "      <td>118</td>\n",
       "      <td>region</td>\n",
       "      <td>reading</td>\n",
       "      <td>identify</td>\n",
       "      <td>batch</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c602d04327beb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.198822Z",
     "start_time": "2025-11-30T20:28:06.193292Z"
    }
   },
   "source": [
    "df_batch.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1728 entries, 1 to 2304\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   model_name            1728 non-null   object \n",
      " 1   provider_country      1728 non-null   object \n",
      " 2   licence_type          1728 non-null   object \n",
      " 3   map_code              1728 non-null   object \n",
      " 4   graphical_complexity  1728 non-null   object \n",
      " 5   viz_technique         864 non-null    object \n",
      " 6   symbol_scaling        1188 non-null   object \n",
      " 7   diagram_structure     1188 non-null   object \n",
      " 8   map_source            1728 non-null   object \n",
      " 9   question_id           1728 non-null   int64  \n",
      " 10  nuts_level            1728 non-null   object \n",
      " 11  map_usage_type        1728 non-null   object \n",
      " 12  task_type             1728 non-null   object \n",
      " 13  test_mode             1728 non-null   object \n",
      " 14  score                 1728 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 216.0+ KB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "74ed0fa7c5055014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.223111Z",
     "start_time": "2025-11-30T20:28:06.220361Z"
    }
   },
   "source": [
    "df_reading = df_batch[df_batch['map_usage_type'] == 'reading']\n",
    "df_analysis = df_batch[df_batch['map_usage_type'] == 'analysis']\n",
    "df_interpretation = df_batch[df_batch['map_usage_type'] == 'interpretation']"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "5af6b68eab04b3bf",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "9bdcf53f99e4b7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.266883Z",
     "start_time": "2025-11-30T20:28:06.263866Z"
    }
   },
   "source": [
    "print(\"1. BASIC INFORMATION\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total observations: {len(df_batch)}\")\n",
    "print(f\"Unique questions: {df_batch['question_id'].nunique()}\")\n",
    "print(f\"Unique models: {df_batch['model_name'].nunique()}\")\n",
    "print(f\"Models analyzed: {', '.join(sorted(df_batch['model_name'].unique()))}\")\n",
    "\n",
    "# Check if test_mode is all 'batch'\n",
    "test_modes = df_batch['test_mode'].unique()\n",
    "print(f\"\\nTest mode(s): {', '.join(test_modes)}\")\n",
    "if len(test_modes) > 1 or test_modes[0] != 'batch':\n",
    "    print(\"WARNING: Dataset contains non-batch observations!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. BASIC INFORMATION\n",
      "--------------------------------------------------------------------------------\n",
      "Total observations: 1728\n",
      "Unique questions: 144\n",
      "Unique models: 12\n",
      "Models analyzed: Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, DeepSeek-R1, GPT o3, GPT-4o, Gemini 1.5 Pro, Gemma 3, Grok-3, MiniMax-01, Mistral Large, Qwen2.5-Max, Sonar\n",
      "\n",
      "Test mode(s): batch\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "5596a470e40cdd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.300795Z",
     "start_time": "2025-11-30T20:28:06.298009Z"
    }
   },
   "source": [
    "print(\"2. MODEL DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "model_counts = df_batch['model_name'].value_counts().sort_index()\n",
    "print(\"\\nObservations per model:\")\n",
    "for model, count in model_counts.items():\n",
    "    print(f\"  {model}: {count}\")\n",
    "\n",
    "# Check balance\n",
    "balance_ratio = model_counts.max() / model_counts.min()\n",
    "print(f\"\\nBalance ratio (max/min): {balance_ratio:.2f}\")\n",
    "if balance_ratio > 2:\n",
    "    print(\"WARNING: Imbalanced design - some models have >2x observations of others\")\n",
    "else:\n",
    "    print(\"Design reasonably balanced across models\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. MODEL DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Observations per model:\n",
      "  Claude 3.5 Sonnet v2: 144\n",
      "  Claude 3.7 Sonnet: 144\n",
      "  DeepSeek-R1: 144\n",
      "  GPT o3: 144\n",
      "  GPT-4o: 144\n",
      "  Gemini 1.5 Pro: 144\n",
      "  Gemma 3: 144\n",
      "  Grok-3: 144\n",
      "  MiniMax-01: 144\n",
      "  Mistral Large: 144\n",
      "  Qwen2.5-Max: 144\n",
      "  Sonar: 144\n",
      "\n",
      "Balance ratio (max/min): 1.00\n",
      "Design reasonably balanced across models\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "453324c340dbe922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.329865Z",
     "start_time": "2025-11-30T20:28:06.324005Z"
    }
   },
   "source": [
    "print(\"3. ZERO VALUES ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "zeros_total = (df_batch['score'] == 0).sum()\n",
    "zeros_pct = (zeros_total / len(df_batch)) * 100\n",
    "print(f\"Zero values: {zeros_total} ({zeros_pct:.2f}%)\")\n",
    "\n",
    "# Zeros per model\n",
    "print(\"Zero values by model:\")\n",
    "for model in sorted(df_batch['model_name'].unique()):\n",
    "    model_data = df_batch[df_batch['model_name'] == model]\n",
    "    zeros = (model_data['score'] == 0).sum()\n",
    "    zeros_pct_model = (zeros / len(model_data)) * 100\n",
    "    print(f\"  {model}: {zeros} ({zeros_pct_model:.1f}%)\")\n",
    "\n",
    "print(\"\\nNote: Zeros represent failed responses, not missing data.\")\n",
    "print(\"All analyses include zeros as legitimate failure outcomes.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. ZERO VALUES ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Zero values: 458 (26.50%)\n",
      "Zero values by model:\n",
      "  Claude 3.5 Sonnet v2: 28 (19.4%)\n",
      "  Claude 3.7 Sonnet: 21 (14.6%)\n",
      "  DeepSeek-R1: 48 (33.3%)\n",
      "  GPT o3: 29 (20.1%)\n",
      "  GPT-4o: 44 (30.6%)\n",
      "  Gemini 1.5 Pro: 34 (23.6%)\n",
      "  Gemma 3: 45 (31.2%)\n",
      "  Grok-3: 36 (25.0%)\n",
      "  MiniMax-01: 47 (32.6%)\n",
      "  Mistral Large: 36 (25.0%)\n",
      "  Qwen2.5-Max: 41 (28.5%)\n",
      "  Sonar: 49 (34.0%)\n",
      "\n",
      "Note: Zeros represent failed responses, not missing data.\n",
      "All analyses include zeros as legitimate failure outcomes.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "655b75f3c3645ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.387408Z",
     "start_time": "2025-11-30T20:28:06.348682Z"
    }
   },
   "source": [
    "print(\"4. DESCRIPTIVE STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def descriptive_statistics(df, value_col, group_col=None, ci=0.95):\n",
    "    def calc_stats(series, ci_level):\n",
    "        n = len(series)\n",
    "        mean_val = series.mean()\n",
    "        sem_val = sem(series)\n",
    "        ci_low, ci_high = t.interval(ci_level, n-1, loc=mean_val, scale=sem_val)\n",
    "        stats_dict = {\n",
    "            \"M\": mean_val,\n",
    "            \"95% CI\": (ci_low, ci_high),\n",
    "            \"Mdn\": series.median(),\n",
    "            \"SD\": series.std(),\n",
    "            \"Range\": (series.min(), series.max()),\n",
    "            \"Q1\": series.quantile(0.25),\n",
    "            \"Q3\": series.quantile(0.75),\n",
    "            \"N\": n\n",
    "        }\n",
    "        return stats_dict\n",
    "\n",
    "    if group_col is None:\n",
    "        stats_overall = calc_stats(df[value_col], ci)\n",
    "        print(\"\\nOverall statistics:\")\n",
    "        print(f\"  M = {stats_overall['M']:.3f}, 95% CI = ({stats_overall['95% CI'][0]:.2f}, {stats_overall['95% CI'][1]:.2f}), \"\n",
    "              f\"Mdn = {stats_overall['Mdn']:.3f}, SD = {stats_overall['SD']:.3f}\")\n",
    "        print(f\"  Range: [{stats_overall['Range'][0]:.1f}, {stats_overall['Range'][1]:.1f}]\")\n",
    "        print(f\"  Q1 = {stats_overall['Q1']:.2f}, Q3 = {stats_overall['Q3']:.2f}\")\n",
    "    else:\n",
    "        print(f\"\\nStatistics by '{group_col}':\")\n",
    "        for group in sorted(df[group_col].unique()):\n",
    "            group_data = df[df[group_col] == group][value_col]\n",
    "            stats_group = calc_stats(group_data, ci)\n",
    "            print(f\"{group}:\")\n",
    "            print(f\"  M = {stats_group['M']:.2f}, 95% CI = ({stats_group['95% CI'][0]:.2f}, {stats_group['95% CI'][1]:.2f}), \"\n",
    "                  f\"Mdn = {stats_group['Mdn']:.2f}, SD = {stats_group['SD']:.2f}, \"\n",
    "                  f\"Range = [{stats_group['Range'][0]:.1f}, {stats_group['Range'][1]:.1f}], \"\n",
    "                  f\"Q1 = {stats_group['Q1']:.2f}, Q3 = {stats_group['Q3']:.2f}, N = {stats_group['N']}\")\n",
    "\n",
    "\n",
    "print(\"Overall dataset:\")\n",
    "descriptive_statistics(df_batch, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "descriptive_statistics(df_reading, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "descriptive_statistics(df_analysis, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "descriptive_statistics(df_interpretation, value_col='score', group_col='model_name')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. DESCRIPTIVE STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Overall dataset:\n",
      "\n",
      "Statistics by 'model_name':\n",
      "Claude 3.5 Sonnet v2:\n",
      "  M = 3.58, 95% CI = (3.27, 3.88), Mdn = 4.43, SD = 1.86, Range = [0.0, 5.0], Q1 = 3.43, Q3 = 5.00, N = 144\n",
      "Claude 3.7 Sonnet:\n",
      "  M = 3.94, 95% CI = (3.66, 4.21), Mdn = 4.53, SD = 1.68, Range = [0.0, 5.0], Q1 = 4.05, Q3 = 5.00, N = 144\n",
      "DeepSeek-R1:\n",
      "  M = 2.80, 95% CI = (2.46, 3.14), Mdn = 3.90, SD = 2.07, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 144\n",
      "GPT o3:\n",
      "  M = 3.51, 95% CI = (3.21, 3.82), Mdn = 4.30, SD = 1.84, Range = [0.0, 5.0], Q1 = 3.40, Q3 = 4.80, N = 144\n",
      "GPT-4o:\n",
      "  M = 2.98, 95% CI = (2.64, 3.32), Mdn = 4.00, SD = 2.05, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.56, N = 144\n",
      "Gemini 1.5 Pro:\n",
      "  M = 3.29, 95% CI = (2.97, 3.61), Mdn = 4.10, SD = 1.93, Range = [0.0, 5.0], Q1 = 2.41, Q3 = 4.80, N = 144\n",
      "Gemma 3:\n",
      "  M = 2.98, 95% CI = (2.64, 3.32), Mdn = 4.05, SD = 2.06, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 144\n",
      "Grok-3:\n",
      "  M = 3.35, 95% CI = (3.02, 3.68), Mdn = 4.30, SD = 2.01, Range = [0.0, 5.0], Q1 = 1.54, Q3 = 5.00, N = 144\n",
      "MiniMax-01:\n",
      "  M = 2.88, 95% CI = (2.54, 3.21), Mdn = 4.00, SD = 2.06, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 144\n",
      "Mistral Large:\n",
      "  M = 3.33, 95% CI = (3.00, 3.65), Mdn = 4.28, SD = 1.98, Range = [0.0, 5.0], Q1 = 2.06, Q3 = 4.80, N = 144\n",
      "Qwen2.5-Max:\n",
      "  M = 2.95, 95% CI = (2.62, 3.28), Mdn = 3.90, SD = 2.00, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.51, N = 144\n",
      "Sonar:\n",
      "  M = 2.65, 95% CI = (2.31, 2.98), Mdn = 3.67, SD = 2.02, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.33, N = 144\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "\n",
      "Statistics by 'model_name':\n",
      "Claude 3.5 Sonnet v2:\n",
      "  M = 3.36, 95% CI = (2.69, 4.03), Mdn = 5.00, SD = 2.30, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "Claude 3.7 Sonnet:\n",
      "  M = 3.50, 95% CI = (2.87, 4.14), Mdn = 4.70, SD = 2.17, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "DeepSeek-R1:\n",
      "  M = 2.53, 95% CI = (1.84, 3.22), Mdn = 3.95, SD = 2.38, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.93, N = 48\n",
      "GPT o3:\n",
      "  M = 3.17, 95% CI = (2.51, 3.83), Mdn = 4.50, SD = 2.28, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "GPT-4o:\n",
      "  M = 2.09, 95% CI = (1.39, 2.79), Mdn = 0.00, SD = 2.41, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.93, N = 48\n",
      "Gemini 1.5 Pro:\n",
      "  M = 3.10, 95% CI = (2.43, 3.78), Mdn = 4.60, SD = 2.33, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "Gemma 3:\n",
      "  M = 2.05, 95% CI = (1.37, 2.74), Mdn = 0.00, SD = 2.36, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 48\n",
      "Grok-3:\n",
      "  M = 3.42, 95% CI = (2.78, 4.07), Mdn = 4.70, SD = 2.23, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "MiniMax-01:\n",
      "  M = 2.23, 95% CI = (1.54, 2.91), Mdn = 0.00, SD = 2.36, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.60, N = 48\n",
      "Mistral Large:\n",
      "  M = 3.24, 95% CI = (2.57, 3.92), Mdn = 4.70, SD = 2.32, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "Qwen2.5-Max:\n",
      "  M = 2.78, 95% CI = (2.09, 3.48), Mdn = 4.50, SD = 2.40, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 5.00, N = 48\n",
      "Sonar:\n",
      "  M = 2.46, 95% CI = (1.79, 3.13), Mdn = 3.90, SD = 2.31, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.58, N = 48\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "\n",
      "Statistics by 'model_name':\n",
      "Claude 3.5 Sonnet v2:\n",
      "  M = 3.64, 95% CI = (3.11, 4.16), Mdn = 4.30, SD = 1.81, Range = [0.0, 5.0], Q1 = 3.90, Q3 = 4.85, N = 48\n",
      "Claude 3.7 Sonnet:\n",
      "  M = 3.89, 95% CI = (3.41, 4.38), Mdn = 4.50, SD = 1.67, Range = [0.0, 5.0], Q1 = 4.10, Q3 = 4.90, N = 48\n",
      "DeepSeek-R1:\n",
      "  M = 2.50, 95% CI = (1.88, 3.13), Mdn = 3.85, SD = 2.16, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.30, N = 48\n",
      "GPT o3:\n",
      "  M = 3.51, 95% CI = (3.00, 4.02), Mdn = 4.10, SD = 1.76, Range = [0.0, 5.0], Q1 = 3.60, Q3 = 4.62, N = 48\n",
      "GPT-4o:\n",
      "  M = 2.94, 95% CI = (2.37, 3.51), Mdn = 3.74, SD = 1.97, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.35, N = 48\n",
      "Gemini 1.5 Pro:\n",
      "  M = 3.07, 95% CI = (2.48, 3.66), Mdn = 4.10, SD = 2.04, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 48\n",
      "Gemma 3:\n",
      "  M = 3.12, 95% CI = (2.55, 3.69), Mdn = 4.10, SD = 1.95, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.30, N = 48\n",
      "Grok-3:\n",
      "  M = 3.23, 95% CI = (2.64, 3.81), Mdn = 4.20, SD = 2.02, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 48\n",
      "MiniMax-01:\n",
      "  M = 2.44, 95% CI = (1.83, 3.05), Mdn = 3.88, SD = 2.10, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.30, N = 48\n",
      "Mistral Large:\n",
      "  M = 2.90, 95% CI = (2.29, 3.51), Mdn = 4.10, SD = 2.11, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.50, N = 48\n",
      "Qwen2.5-Max:\n",
      "  M = 2.62, 95% CI = (2.01, 3.22), Mdn = 3.83, SD = 2.08, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.30, N = 48\n",
      "Sonar:\n",
      "  M = 2.54, 95% CI = (1.95, 3.12), Mdn = 3.70, SD = 2.02, Range = [0.0, 5.0], Q1 = 0.00, Q3 = 4.06, N = 48\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "\n",
      "Statistics by 'model_name':\n",
      "Claude 3.5 Sonnet v2:\n",
      "  M = 3.73, 95% CI = (3.33, 4.14), Mdn = 4.17, SD = 1.40, Range = [0.0, 5.0], Q1 = 3.43, Q3 = 4.75, N = 48\n",
      "Claude 3.7 Sonnet:\n",
      "  M = 4.41, 95% CI = (4.17, 4.65), Mdn = 4.70, SD = 0.84, Range = [0.0, 5.0], Q1 = 4.04, Q3 = 5.00, N = 48\n",
      "DeepSeek-R1:\n",
      "  M = 3.37, 95% CI = (2.93, 3.80), Mdn = 3.98, SD = 1.50, Range = [0.0, 5.0], Q1 = 2.70, Q3 = 4.26, N = 48\n",
      "GPT o3:\n",
      "  M = 3.86, 95% CI = (3.48, 4.24), Mdn = 4.25, SD = 1.32, Range = [0.0, 5.0], Q1 = 3.68, Q3 = 4.71, N = 48\n",
      "GPT-4o:\n",
      "  M = 3.90, 95% CI = (3.56, 4.24), Mdn = 4.25, SD = 1.17, Range = [0.0, 5.0], Q1 = 3.88, Q3 = 4.50, N = 48\n",
      "Gemini 1.5 Pro:\n",
      "  M = 3.69, 95% CI = (3.33, 4.05), Mdn = 4.03, SD = 1.25, Range = [0.0, 5.0], Q1 = 3.23, Q3 = 4.51, N = 48\n",
      "Gemma 3:\n",
      "  M = 3.75, 95% CI = (3.34, 4.17), Mdn = 4.12, SD = 1.43, Range = [0.0, 5.0], Q1 = 3.84, Q3 = 4.59, N = 48\n",
      "Grok-3:\n",
      "  M = 3.40, 95% CI = (2.88, 3.92), Mdn = 4.05, SD = 1.79, Range = [0.0, 5.0], Q1 = 2.98, Q3 = 4.75, N = 48\n",
      "MiniMax-01:\n",
      "  M = 3.96, 95% CI = (3.66, 4.25), Mdn = 4.25, SD = 1.03, Range = [0.0, 5.0], Q1 = 3.79, Q3 = 4.51, N = 48\n",
      "Mistral Large:\n",
      "  M = 3.84, 95% CI = (3.47, 4.21), Mdn = 4.05, SD = 1.28, Range = [0.0, 5.0], Q1 = 3.75, Q3 = 4.55, N = 48\n",
      "Qwen2.5-Max:\n",
      "  M = 3.46, 95% CI = (3.09, 3.83), Mdn = 3.98, SD = 1.28, Range = [0.0, 5.0], Q1 = 2.73, Q3 = 4.30, N = 48\n",
      "Sonar:\n",
      "  M = 2.95, 95% CI = (2.46, 3.44), Mdn = 3.48, SD = 1.69, Range = [0.0, 5.0], Q1 = 2.38, Q3 = 4.25, N = 48\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "f29bceeb7a743132",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.413744Z",
     "start_time": "2025-11-30T20:28:06.402061Z"
    }
   },
   "source": [
    "print(\"5. DISTRIBUTION TESTS\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nShapiro-Wilk normality tests:\")\n",
    "\n",
    "def shapiro_test_by_group(df, value_col, group_col=None, min_n=3):\n",
    "    if group_col:\n",
    "        print(f\"Shapiro-Wilk test for '{value_col}' by '{group_col}':\\n\")\n",
    "        for group in sorted(df[group_col].unique()):\n",
    "            group_data = df[df[group_col] == group][value_col]\n",
    "            n = len(group_data)\n",
    "            if n >= min_n:\n",
    "                stat, p = shapiro(group_data)\n",
    "                normal_status = \"normal\" if p > 0.05 else \"non-normal\"\n",
    "                print(f\"  {group}: W = {stat:.4f}, p = {p:.4f} ({normal_status}, n={n})\")\n",
    "            else:\n",
    "                print(f\"  {group}: insufficient data for test (n={n})\")\n",
    "\n",
    "    # Overall test\n",
    "    overall_data = df[value_col]\n",
    "    stat_overall, p_overall = shapiro(overall_data)\n",
    "    overall_status = \"normal\" if p_overall > 0.05 else \"non-normal\"\n",
    "    print(f\"\\nOverall: W = {stat_overall:.4f}, p = {p_overall:.4f} ({overall_status}, n={len(overall_data)})\\n\")\n",
    "\n",
    "    if p_overall < 0.05:\n",
    "        print(\"Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\")\n",
    "    else:\n",
    "        print(\"Conclusion: Parametric tests may be appropriate, but verify assumptions\")\n",
    "\n",
    "print(\"Overall dataset:\")\n",
    "shapiro_test_by_group(df_batch, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "shapiro_test_by_group(df_reading, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "shapiro_test_by_group(df_analysis, value_col='score', group_col='model_name')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "shapiro_test_by_group(df_interpretation, value_col='score', group_col='model_name')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. DISTRIBUTION TESTS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Shapiro-Wilk normality tests:\n",
      "Overall dataset:\n",
      "Shapiro-Wilk test for 'score' by 'model_name':\n",
      "\n",
      "  Claude 3.5 Sonnet v2: W = 0.7025, p = 0.0000 (non-normal, n=144)\n",
      "  Claude 3.7 Sonnet: W = 0.6148, p = 0.0000 (non-normal, n=144)\n",
      "  DeepSeek-R1: W = 0.7589, p = 0.0000 (non-normal, n=144)\n",
      "  GPT o3: W = 0.7015, p = 0.0000 (non-normal, n=144)\n",
      "  GPT-4o: W = 0.7487, p = 0.0000 (non-normal, n=144)\n",
      "  Gemini 1.5 Pro: W = 0.7427, p = 0.0000 (non-normal, n=144)\n",
      "  Gemma 3: W = 0.7256, p = 0.0000 (non-normal, n=144)\n",
      "  Grok-3: W = 0.7086, p = 0.0000 (non-normal, n=144)\n",
      "  MiniMax-01: W = 0.7379, p = 0.0000 (non-normal, n=144)\n",
      "  Mistral Large: W = 0.7081, p = 0.0000 (non-normal, n=144)\n",
      "  Qwen2.5-Max: W = 0.7779, p = 0.0000 (non-normal, n=144)\n",
      "  Sonar: W = 0.7874, p = 0.0000 (non-normal, n=144)\n",
      "\n",
      "Overall: W = 0.7372, p = 0.0000 (non-normal, n=1728)\n",
      "\n",
      "Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "Shapiro-Wilk test for 'score' by 'model_name':\n",
      "\n",
      "  Claude 3.5 Sonnet v2: W = 0.6226, p = 0.0000 (non-normal, n=48)\n",
      "  Claude 3.7 Sonnet: W = 0.6263, p = 0.0000 (non-normal, n=48)\n",
      "  DeepSeek-R1: W = 0.6956, p = 0.0000 (non-normal, n=48)\n",
      "  GPT o3: W = 0.6644, p = 0.0000 (non-normal, n=48)\n",
      "  GPT-4o: W = 0.6634, p = 0.0000 (non-normal, n=48)\n",
      "  Gemini 1.5 Pro: W = 0.6571, p = 0.0000 (non-normal, n=48)\n",
      "  Gemma 3: W = 0.6686, p = 0.0000 (non-normal, n=48)\n",
      "  Grok-3: W = 0.6282, p = 0.0000 (non-normal, n=48)\n",
      "  MiniMax-01: W = 0.6856, p = 0.0000 (non-normal, n=48)\n",
      "  Mistral Large: W = 0.6387, p = 0.0000 (non-normal, n=48)\n",
      "  Qwen2.5-Max: W = 0.6798, p = 0.0000 (non-normal, n=48)\n",
      "  Sonar: W = 0.7113, p = 0.0000 (non-normal, n=48)\n",
      "\n",
      "Overall: W = 0.6786, p = 0.0000 (non-normal, n=576)\n",
      "\n",
      "Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "Shapiro-Wilk test for 'score' by 'model_name':\n",
      "\n",
      "  Claude 3.5 Sonnet v2: W = 0.6578, p = 0.0000 (non-normal, n=48)\n",
      "  Claude 3.7 Sonnet: W = 0.6108, p = 0.0000 (non-normal, n=48)\n",
      "  DeepSeek-R1: W = 0.7222, p = 0.0000 (non-normal, n=48)\n",
      "  GPT o3: W = 0.6984, p = 0.0000 (non-normal, n=48)\n",
      "  GPT-4o: W = 0.7656, p = 0.0000 (non-normal, n=48)\n",
      "  Gemini 1.5 Pro: W = 0.7282, p = 0.0000 (non-normal, n=48)\n",
      "  Gemma 3: W = 0.6967, p = 0.0000 (non-normal, n=48)\n",
      "  Grok-3: W = 0.6980, p = 0.0000 (non-normal, n=48)\n",
      "  MiniMax-01: W = 0.7078, p = 0.0000 (non-normal, n=48)\n",
      "  Mistral Large: W = 0.7169, p = 0.0000 (non-normal, n=48)\n",
      "  Qwen2.5-Max: W = 0.7433, p = 0.0000 (non-normal, n=48)\n",
      "  Sonar: W = 0.7528, p = 0.0000 (non-normal, n=48)\n",
      "\n",
      "Overall: W = 0.7255, p = 0.0000 (non-normal, n=576)\n",
      "\n",
      "Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "Shapiro-Wilk test for 'score' by 'model_name':\n",
      "\n",
      "  Claude 3.5 Sonnet v2: W = 0.7920, p = 0.0000 (non-normal, n=48)\n",
      "  Claude 3.7 Sonnet: W = 0.6629, p = 0.0000 (non-normal, n=48)\n",
      "  DeepSeek-R1: W = 0.7944, p = 0.0000 (non-normal, n=48)\n",
      "  GPT o3: W = 0.7098, p = 0.0000 (non-normal, n=48)\n",
      "  GPT-4o: W = 0.6932, p = 0.0000 (non-normal, n=48)\n",
      "  Gemini 1.5 Pro: W = 0.8249, p = 0.0000 (non-normal, n=48)\n",
      "  Gemma 3: W = 0.6956, p = 0.0000 (non-normal, n=48)\n",
      "  Grok-3: W = 0.7609, p = 0.0000 (non-normal, n=48)\n",
      "  MiniMax-01: W = 0.7414, p = 0.0000 (non-normal, n=48)\n",
      "  Mistral Large: W = 0.6804, p = 0.0000 (non-normal, n=48)\n",
      "  Qwen2.5-Max: W = 0.8512, p = 0.0000 (non-normal, n=48)\n",
      "  Sonar: W = 0.8569, p = 0.0000 (non-normal, n=48)\n",
      "\n",
      "Overall: W = 0.7656, p = 0.0000 (non-normal, n=576)\n",
      "\n",
      "Conclusion: Non-parametric tests required (Kruskal-Wallis, Mann-Whitney)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ba111cd6b380bb9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.436353Z",
     "start_time": "2025-11-30T20:28:06.425911Z"
    }
   },
   "source": [
    "print(\"6. HOMOGENEITY OF VARIANCE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def levene_test(df, value_col, group_col):\n",
    "    groups = [df[df[group_col] == g][value_col].values for g in sorted(df[group_col].unique())]\n",
    "\n",
    "    stat, p = levene(*groups)\n",
    "\n",
    "    print(f\"Levene's test for '{value_col}' by '{group_col}':\")\n",
    "    print(f\"W = {stat:.4f}, p = {p:.4f}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        print(\"Conclusion: Variances are heterogeneous - use Welch's ANOVA or non-parametric tests\")\n",
    "    else:\n",
    "        print(\"Conclusion: Variances are homogeneous\")\n",
    "\n",
    "levene_test(df_batch, value_col='score', group_col='model_name')\n",
    "levene_test(df_reading, value_col='score', group_col='model_name')\n",
    "levene_test(df_analysis, value_col='score', group_col='model_name')\n",
    "levene_test(df_interpretation, value_col='score', group_col='model_name')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. HOMOGENEITY OF VARIANCE\n",
      "--------------------------------------------------------------------------------\n",
      "Levene's test for 'score' by 'model_name':\n",
      "W = 2.7026, p = 0.0019\n",
      "Conclusion: Variances are heterogeneous - use Welch's ANOVA or non-parametric tests\n",
      "Levene's test for 'score' by 'model_name':\n",
      "W = 0.8068, p = 0.6334\n",
      "Conclusion: Variances are homogeneous\n",
      "Levene's test for 'score' by 'model_name':\n",
      "W = 1.5696, p = 0.1037\n",
      "Conclusion: Variances are homogeneous\n",
      "Levene's test for 'score' by 'model_name':\n",
      "W = 2.4537, p = 0.0053\n",
      "Conclusion: Variances are heterogeneous - use Welch's ANOVA or non-parametric tests\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "b053fa7d7d3a04a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.462626Z",
     "start_time": "2025-11-30T20:28:06.457349Z"
    }
   },
   "source": [
    "print(\"7. MODEL CHARACTERISTICS DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nProvider country distribution:\")\n",
    "country_dist = df_batch.groupby(['model_name', 'provider_country']).size().unstack(fill_value=0)\n",
    "print(country_dist)\n",
    "\n",
    "print(\"\\nLicense distribution:\")\n",
    "license_dist = df_batch.groupby(['model_name', 'licence_type']).size().unstack(fill_value=0)\n",
    "print(license_dist)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. MODEL CHARACTERISTICS DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Provider country distribution:\n",
      "provider_country      China  France  USA\n",
      "model_name                              \n",
      "Claude 3.5 Sonnet v2      0       0  144\n",
      "Claude 3.7 Sonnet         0       0  144\n",
      "DeepSeek-R1             144       0    0\n",
      "GPT o3                    0       0  144\n",
      "GPT-4o                    0       0  144\n",
      "Gemini 1.5 Pro            0       0  144\n",
      "Gemma 3                   0       0  144\n",
      "Grok-3                    0       0  144\n",
      "MiniMax-01              144       0    0\n",
      "Mistral Large             0     144    0\n",
      "Qwen2.5-Max             144       0    0\n",
      "Sonar                     0       0  144\n",
      "\n",
      "License distribution:\n",
      "licence_type          free  paid\n",
      "model_name                      \n",
      "Claude 3.5 Sonnet v2     0   144\n",
      "Claude 3.7 Sonnet        0   144\n",
      "DeepSeek-R1            144     0\n",
      "GPT o3                   0   144\n",
      "GPT-4o                   0   144\n",
      "Gemini 1.5 Pro           0   144\n",
      "Gemma 3                144     0\n",
      "Grok-3                   0   144\n",
      "MiniMax-01             144     0\n",
      "Mistral Large            0   144\n",
      "Qwen2.5-Max            144     0\n",
      "Sonar                    0   144\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "526e6eef3f513f55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.485328Z",
     "start_time": "2025-11-30T20:28:06.481521Z"
    }
   },
   "source": [
    "print(\"8. TASK CHARACTERISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nMap usage types:\")\n",
    "print(df_batch['map_usage_type'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nGraphical complexity levels:\")\n",
    "print(df_batch['graphical_complexity'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nNUTS levels:\")\n",
    "print(df_batch['nuts_level'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nMap sources:\")\n",
    "print(df_batch['map_source'].value_counts().sort_index())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. TASK CHARACTERISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Map usage types:\n",
      "map_usage_type\n",
      "analysis          576\n",
      "interpretation    576\n",
      "reading           576\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Graphical complexity levels:\n",
      "graphical_complexity\n",
      "high    864\n",
      "low     864\n",
      "Name: count, dtype: int64\n",
      "\n",
      "NUTS levels:\n",
      "nuts_level\n",
      "country    864\n",
      "region     864\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Map sources:\n",
      "map_source\n",
      "atlas                 864\n",
      "statistical_office    864\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "77c6fb1afe48413",
   "metadata": {},
   "source": [
    "## 2. Main effects"
   ]
  },
  {
   "cell_type": "code",
   "id": "3cf7394c39552f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.523277Z",
     "start_time": "2025-11-30T20:28:06.507436Z"
    }
   },
   "source": [
    "# M1: Model Ranking\n",
    "# H0: All models achieve the same mean scores\n",
    "# H1: There are differences in mean scores between AI models\n",
    "\n",
    "print(\"M1: MODEL RANKING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Kruskal-Wallis test (non-parametric, >2 groups)\n",
    "model_groups = [df_batch[df_batch['model_name'] == model]['score'].values\n",
    "                for model in sorted(df_batch['model_name'].unique())]\n",
    "h_stat, p_val = kruskal(*model_groups)\n",
    "\n",
    "# Effect size: Epsilon squared\n",
    "n = len(df_batch)\n",
    "k = len(model_groups)\n",
    "epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "print(f\"Kruskal-Wallis H = {h_stat:.3f}, p = {p_val:.6f}\")\n",
    "print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "def format_p_value(p):\n",
    "    if p < 0.001:\n",
    "        return \"< 0.001\"\n",
    "    elif p < 0.01:\n",
    "        return \"< 0.01\"\n",
    "    elif p < 0.05:\n",
    "        return \"< 0.05\"\n",
    "    else:\n",
    "        return f\"{p:.4f}\"\n",
    "\n",
    "# Post-hoc Dunn test with FDR correction\n",
    "if p_val < 0.05:\n",
    "    print(\"\\nPost-hoc pairwise comparisons (Dunn test with FDR correction):\")\n",
    "    posthoc = posthoc_dunn(df_batch, val_col='score', group_col='model_name', p_adjust='fdr_bh')\n",
    "\n",
    "    # Extract significant pairs\n",
    "    sig_pairs = []\n",
    "    models = posthoc.index.tolist()\n",
    "    for i, model1 in enumerate(models):\n",
    "        for j, model2 in enumerate(models):\n",
    "            if i < j and posthoc.loc[model1, model2] < 0.05:\n",
    "                sig_pairs.append({\n",
    "                    'Model 1': model1,\n",
    "                    'Model 2': model2,\n",
    "                    'p-value': posthoc.loc[model1, model2]\n",
    "                })\n",
    "\n",
    "    if sig_pairs:\n",
    "        sig_df = pd.DataFrame(sig_pairs).sort_values('p-value')\n",
    "        sig_df['p-value_formatted'] = sig_df['p-value'].apply(format_p_value)\n",
    "\n",
    "        print(f\"\\n{len(sig_pairs)} significant pairwise differences found:\")\n",
    "        print(sig_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant pairwise differences after FDR correction\")\n",
    "\n",
    "model_means = df_batch.groupby('model_name')['score'].agg(['mean', 'median', 'std']).sort_values('mean',\n",
    "                                                                                                   ascending=False)\n",
    "print(\"\\nModel Rankings (by mean score):\")\n",
    "for rank, (model, row) in enumerate(model_means.iterrows(), 1):\n",
    "    print(f\"{rank}. {model}: M={row['mean']:.3f}, Mdn={row['median']:.3f}, SD={row['std']:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1: MODEL RANKING\n",
      "--------------------------------------------------------------------------------\n",
      "Kruskal-Wallis H = 90.453, p = 0.000000\n",
      "Effect size (ε²) = 0.046\n",
      "Significant: YES\n",
      "\n",
      "Post-hoc pairwise comparisons (Dunn test with FDR correction):\n",
      "\n",
      "32 significant pairwise differences found:\n",
      "             Model 1        Model 2      p-value p-value_formatted\n",
      "   Claude 3.7 Sonnet          Sonar 1.352936e-10           < 0.001\n",
      "   Claude 3.7 Sonnet    DeepSeek-R1 8.490153e-08           < 0.001\n",
      "   Claude 3.7 Sonnet     MiniMax-01 1.014199e-07           < 0.001\n",
      "   Claude 3.7 Sonnet    Qwen2.5-Max 7.254231e-07           < 0.001\n",
      "   Claude 3.7 Sonnet         GPT-4o 2.173157e-06           < 0.001\n",
      "   Claude 3.7 Sonnet        Gemma 3 2.236691e-06           < 0.001\n",
      "Claude 3.5 Sonnet v2          Sonar 2.274644e-06           < 0.001\n",
      "              Grok-3          Sonar 2.119598e-04           < 0.001\n",
      "              GPT o3          Sonar 2.119598e-04           < 0.001\n",
      "Claude 3.5 Sonnet v2    DeepSeek-R1 2.845958e-04           < 0.001\n",
      "Claude 3.5 Sonnet v2     MiniMax-01 3.898157e-04           < 0.001\n",
      "       Mistral Large          Sonar 1.055405e-03            < 0.01\n",
      "   Claude 3.7 Sonnet Gemini 1.5 Pro 1.055405e-03            < 0.01\n",
      "Claude 3.5 Sonnet v2    Qwen2.5-Max 1.457701e-03            < 0.01\n",
      "Claude 3.5 Sonnet v2         GPT-4o 3.322824e-03            < 0.01\n",
      "   Claude 3.7 Sonnet  Mistral Large 3.472242e-03            < 0.01\n",
      "Claude 3.5 Sonnet v2        Gemma 3 3.472242e-03            < 0.01\n",
      "      Gemini 1.5 Pro          Sonar 3.506418e-03            < 0.01\n",
      "         DeepSeek-R1         Grok-3 6.210198e-03            < 0.01\n",
      "         DeepSeek-R1         GPT o3 6.223033e-03            < 0.01\n",
      "              Grok-3     MiniMax-01 7.755006e-03            < 0.01\n",
      "              GPT o3     MiniMax-01 7.797224e-03            < 0.01\n",
      "   Claude 3.7 Sonnet         GPT o3 1.258069e-02            < 0.05\n",
      "   Claude 3.7 Sonnet         Grok-3 1.266640e-02            < 0.05\n",
      "         DeepSeek-R1  Mistral Large 2.117918e-02            < 0.05\n",
      "              Grok-3    Qwen2.5-Max 2.117918e-02            < 0.05\n",
      "              GPT o3    Qwen2.5-Max 2.117918e-02            < 0.05\n",
      "          MiniMax-01  Mistral Large 2.621448e-02            < 0.05\n",
      "              GPT-4o         Grok-3 3.710737e-02            < 0.05\n",
      "              GPT o3         GPT-4o 3.744305e-02            < 0.05\n",
      "             Gemma 3         Grok-3 3.860593e-02            < 0.05\n",
      "              GPT o3        Gemma 3 3.901736e-02            < 0.05\n",
      "\n",
      "Model Rankings (by mean score):\n",
      "1. Claude 3.7 Sonnet: M=3.936, Mdn=4.525, SD=1.685\n",
      "2. Claude 3.5 Sonnet v2: M=3.577, Mdn=4.425, SD=1.865\n",
      "3. GPT o3: M=3.513, Mdn=4.300, SD=1.838\n",
      "4. Grok-3: M=3.351, Mdn=4.300, SD=2.008\n",
      "5. Mistral Large: M=3.328, Mdn=4.275, SD=1.979\n",
      "6. Gemini 1.5 Pro: M=3.288, Mdn=4.100, SD=1.934\n",
      "7. GPT-4o: M=2.978, Mdn=4.000, SD=2.046\n",
      "8. Gemma 3: M=2.976, Mdn=4.050, SD=2.063\n",
      "9. Qwen2.5-Max: M=2.953, Mdn=3.900, SD=1.996\n",
      "10. MiniMax-01: M=2.876, Mdn=4.000, SD=2.056\n",
      "11. DeepSeek-R1: M=2.802, Mdn=3.900, SD=2.071\n",
      "12. Sonar: M=2.648, Mdn=3.675, SD=2.021\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "4e448419cbe30fb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.548778Z",
     "start_time": "2025-11-30T20:28:06.539481Z"
    }
   },
   "source": [
    "# M2: Provider Country\n",
    "# H0: Models from different countries achieve the same mean scores\n",
    "# H1: Mean scores differ by country of origin\n",
    "\n",
    "print(\"M2: PROVIDER COUNTRY\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "country_counts = df_batch['provider_country'].value_counts()\n",
    "print(f\"Country distribution: {dict(country_counts)}\")\n",
    "\n",
    "# All countries have n≥144, proceed with test\n",
    "country_groups = [df_batch[df_batch['provider_country'] == country]['score'].values\n",
    "                  for country in sorted(df_batch['provider_country'].unique())]\n",
    "h_stat, p_val = kruskal(*country_groups)\n",
    "\n",
    "n = len(df_batch)\n",
    "k = len(country_groups)\n",
    "epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "print(f\"\\nKruskal-Wallis H = {h_stat:.3f}, p = {p_val:.6f}\")\n",
    "print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "country_means = df_batch.groupby('provider_country')['score'].agg(['mean', 'std', 'count']).sort_values('mean',\n",
    "                                                                                                        ascending=False)\n",
    "print(\"\\nCountry performance:\")\n",
    "print(country_means)\n",
    "\n",
    "if p_val < 0.05:\n",
    "    posthoc = posthoc_dunn(df_batch, val_col='score', group_col='provider_country', p_adjust='fdr_bh')\n",
    "    print(\"\\nPost-hoc comparisons:\")\n",
    "    print(posthoc)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M2: PROVIDER COUNTRY\n",
      "--------------------------------------------------------------------------------\n",
      "Country distribution: {'USA': 1152, 'China': 432, 'France': 144}\n",
      "\n",
      "Kruskal-Wallis H = 21.939, p = 0.000017\n",
      "Effect size (ε²) = 0.012\n",
      "Significant: YES\n",
      "\n",
      "Country performance:\n",
      "                      mean       std  count\n",
      "provider_country                           \n",
      "France            3.328299  1.979374    144\n",
      "USA               3.283247  1.967697   1152\n",
      "China             2.876910  2.037589    432\n",
      "\n",
      "Post-hoc comparisons:\n",
      "           China    France       USA\n",
      "China   1.000000  0.004172  0.000017\n",
      "France  0.004172  1.000000  0.718178\n",
      "USA     0.000017  0.718178  1.000000\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "8d9a7e75bb39c6f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.572423Z",
     "start_time": "2025-11-30T20:28:06.566114Z"
    }
   },
   "source": [
    "# M3: License Type\n",
    "# H0: Paid and free models achieve the same mean scores\n",
    "# H1: Mean scores differ between paid and free models\n",
    "\n",
    "print(\"M3: LICENSE TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "license_counts = df_batch['licence_type'].value_counts()\n",
    "print(f\"License distribution: {dict(license_counts)}\")\n",
    "\n",
    "# Mann-Whitney U test (2 groups)\n",
    "paid = df_batch[df_batch['licence_type'] == 'paid']['score'].values\n",
    "free = df_batch[df_batch['licence_type'] == 'free']['score'].values\n",
    "\n",
    "u_stat, p_val = mannwhitneyu(paid, free, alternative='two-sided')\n",
    "\n",
    "# Effect size: rank biserial correlation\n",
    "r = 1 - (2 * u_stat) / (len(paid) * len(free))\n",
    "\n",
    "print(f\"\\nMann-Whitney U = {u_stat:.3f}, p = {p_val:.6f}\")\n",
    "print(f\"Effect size (rank-biserial r) = {r:.3f}\")\n",
    "print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "license_means = df_batch.groupby('licence_type')['score'].agg(['mean', 'median', 'std', 'count'])\n",
    "print(\"\\nLicense performance:\")\n",
    "print(license_means)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M3: LICENSE TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "License distribution: {'paid': 1152, 'free': 576}\n",
      "\n",
      "Mann-Whitney U = 382221.000, p = 0.000000\n",
      "Effect size (rank-biserial r) = -0.152\n",
      "Significant: YES\n",
      "\n",
      "License performance:\n",
      "                  mean  median       std  count\n",
      "licence_type                                   \n",
      "free          2.901780    4.00  2.042590    576\n",
      "paid          3.327235    4.25  1.953572   1152\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "6ea4c31eaf195828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.599298Z",
     "start_time": "2025-11-30T20:28:06.590112Z"
    }
   },
   "source": [
    "# M4: Map Usage Type\n",
    "# H0: Map usage types do not affect mean scores\n",
    "# H1: Mean scores differ between map usage types\n",
    "\n",
    "print(\"M4: MAP USAGE TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "category_counts = df_batch['map_usage_type'].value_counts()\n",
    "print(f\"Category distribution: {dict(category_counts)}\")\n",
    "\n",
    "category_groups = [df_batch[df_batch['map_usage_type'] == cat]['score'].values\n",
    "                   for cat in sorted(df_batch['map_usage_type'].unique())]\n",
    "h_stat, p_val = kruskal(*category_groups)\n",
    "\n",
    "n = len(df_batch)\n",
    "k = len(category_groups)\n",
    "epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "print(f\"\\nKruskal-Wallis H = {h_stat:.2f}, p = {p_val:.6f}\")\n",
    "print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "category_means = df_batch.groupby('map_usage_type')['score'].agg(['mean', 'median', 'std']).sort_values('mean',\n",
    "                                                                                                           ascending=False)\n",
    "print(\"\\nMap usage type performance:\")\n",
    "print(category_means)\n",
    "\n",
    "if p_val < 0.05:\n",
    "    posthoc = posthoc_dunn(df_batch, val_col='score', group_col='map_usage_type', p_adjust='fdr_bh')\n",
    "    print(\"\\nPost-hoc comparisons:\")\n",
    "    print(posthoc)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M4: MAP USAGE TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "Category distribution: {'reading': 576, 'analysis': 576, 'interpretation': 576}\n",
      "\n",
      "Kruskal-Wallis H = 15.19, p = 0.000503\n",
      "Effect size (ε²) = 0.008\n",
      "Significant: YES\n",
      "\n",
      "Map usage type performance:\n",
      "                    mean  median       std\n",
      "map_usage_type                            \n",
      "interpretation  3.693316    4.05  1.385971\n",
      "analysis        3.033247    4.10  2.012549\n",
      "reading         2.829688    4.50  2.356468\n",
      "\n",
      "Post-hoc comparisons:\n",
      "                analysis  interpretation   reading\n",
      "analysis        1.000000        0.004564  0.000716\n",
      "interpretation  0.004564        1.000000  0.477183\n",
      "reading         0.000716        0.477183  1.000000\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "227432e178a4623c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.631016Z",
     "start_time": "2025-11-30T20:28:06.616906Z"
    }
   },
   "source": [
    "# M5: Task Type\n",
    "# H0: There are no significant differences in model performance across different task types.\n",
    "# H1: At least one task type differs significantly in performance compared to the others.\n",
    "\n",
    "print(\"M5: TASK TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "def report_significant_pairs(posthoc_df, alpha_levels=[0.05, 0.01, 0.001]):\n",
    "    sig_pairs = []\n",
    "\n",
    "    for i, row in enumerate(posthoc_df.index):\n",
    "        for j, col in enumerate(posthoc_df.columns):\n",
    "            if j <= i:  # skip duplicates and diagonal\n",
    "                continue\n",
    "            p = posthoc_df.loc[row, col]\n",
    "            if p < alpha_levels[0]:\n",
    "                if p < alpha_levels[2]:\n",
    "                    level = \"< 0.001\"\n",
    "                elif p < alpha_levels[1]:\n",
    "                    level = \"< 0.01\"\n",
    "                else:\n",
    "                    level = \"< 0.05\"\n",
    "                sig_pairs.append((row, col, p, level))\n",
    "\n",
    "    if not sig_pairs:\n",
    "        print(\"No statistically significant differences found.\")\n",
    "    else:\n",
    "        print(\"Significant post-hoc differences:\")\n",
    "        for a, b, p, lvl in sorted(sig_pairs, key=lambda x: x[2]):\n",
    "            print(f\"  {a} vs {b} — p = {p:.6f} ({lvl})\")\n",
    "\n",
    "mode_counts = df_batch['task_type'].value_counts()\n",
    "print(f\"Task type distribution:\\n{mode_counts}\\n\")\n",
    "\n",
    "# Check for small groups\n",
    "if mode_counts.min() >= 20:\n",
    "    mode_groups = [df_batch[df_batch['task_type'] == mode]['score'].values\n",
    "                   for mode in sorted(df_batch['task_type'].unique())]\n",
    "    h_stat, p_val = kruskal(*mode_groups)\n",
    "\n",
    "    n = len(df_batch)\n",
    "    k = len(mode_groups)\n",
    "    epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "\n",
    "    print(f\"Kruskal-Wallis H = {h_stat:.3f}, p = {p_val:.6f}\")\n",
    "    print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "    print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "    mode_means = df_batch.groupby('task_type')['score'].agg(['mean', 'median', 'std', 'count']).sort_values('mean',\n",
    "                                                                                                                ascending=False)\n",
    "    print(\"\\nTask type performance:\")\n",
    "    print(mode_means)\n",
    "\n",
    "    if p_val < 0.05:\n",
    "        posthoc = posthoc_dunn(df_batch, val_col='score', group_col='task_type', p_adjust='fdr_bh')\n",
    "        print(\"\\nPost-hoc comparisons (showing p < 0.05):\")\n",
    "        print(posthoc)\n",
    "        report_significant_pairs(posthoc)\n",
    "else:\n",
    "    print(\"WARNING: Some groups have n < 20. Consider grouping or skip test.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5: TASK TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "Task type distribution:\n",
      "task_type\n",
      "identify          192\n",
      "locate            192\n",
      "retrieve value    192\n",
      "compare           192\n",
      "cluster           192\n",
      "associate         192\n",
      "interpret         192\n",
      "cause/effect      192\n",
      "predict           192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal-Wallis H = 100.070, p = 0.000000\n",
      "Effect size (ε²) = 0.054\n",
      "Significant: YES\n",
      "\n",
      "Task type performance:\n",
      "                    mean  median       std  count\n",
      "task_type                                        \n",
      "cause/effect    3.847656   4.050  1.088184    192\n",
      "predict         3.818750   4.250  1.402611    192\n",
      "identify        3.590104   4.900  2.144970    192\n",
      "interpret       3.413542   4.000  1.585231    192\n",
      "compare         3.313932   4.300  1.928545    192\n",
      "associate       3.244922   4.100  1.930893    192\n",
      "locate          2.658854   4.300  2.365729    192\n",
      "cluster         2.540885   3.825  2.092346    192\n",
      "retrieve value  2.240104   0.000  2.357833    192\n",
      "\n",
      "Post-hoc comparisons (showing p < 0.05):\n",
      "                   associate  cause/effect       cluster   compare  \\\n",
      "associate       1.000000e+00      0.625748  1.091421e-03  0.687850   \n",
      "cause/effect    6.257481e-01      1.000000  1.134510e-04  0.896800   \n",
      "cluster         1.091421e-03      0.000113  1.000000e+00  0.000186   \n",
      "compare         6.878505e-01      0.896800  1.864893e-04  1.000000   \n",
      "identify        6.337239e-07      0.000011  2.124835e-17  0.000006   \n",
      "interpret       6.539071e-01      0.310075  6.642416e-03  0.388053   \n",
      "locate          9.286506e-01      0.653907  8.387094e-04  0.736383   \n",
      "predict         8.196845e-02      0.251028  2.999391e-07  0.201189   \n",
      "retrieve value  5.845602e-02      0.012203  2.302253e-01  0.018648   \n",
      "\n",
      "                    identify     interpret        locate       predict  \\\n",
      "associate       6.337239e-07  6.539071e-01  9.286506e-01  8.196845e-02   \n",
      "cause/effect    1.127766e-05  3.100749e-01  6.539071e-01  2.510285e-01   \n",
      "cluster         2.124835e-17  6.642416e-03  8.387094e-04  2.999391e-07   \n",
      "compare         5.771698e-06  3.880531e-01  7.363831e-01  2.011890e-01   \n",
      "identify        1.000000e+00  4.324394e-08  8.627934e-07  1.926866e-03   \n",
      "interpret       4.324394e-08  1.000000e+00  6.257481e-01  2.277559e-02   \n",
      "locate          8.627934e-07  6.257481e-01  1.000000e+00  9.626615e-02   \n",
      "predict         1.926866e-03  2.277559e-02  9.626615e-02  1.000000e+00   \n",
      "retrieve value  1.255138e-12  1.761248e-01  4.903040e-02  1.378714e-04   \n",
      "\n",
      "                retrieve value  \n",
      "associate         5.845602e-02  \n",
      "cause/effect      1.220257e-02  \n",
      "cluster           2.302253e-01  \n",
      "compare           1.864833e-02  \n",
      "identify          1.255138e-12  \n",
      "interpret         1.761248e-01  \n",
      "locate            4.903040e-02  \n",
      "predict           1.378714e-04  \n",
      "retrieve value    1.000000e+00  \n",
      "Significant post-hoc differences:\n",
      "  cluster vs identify — p = 0.000000 (< 0.001)\n",
      "  identify vs retrieve value — p = 0.000000 (< 0.001)\n",
      "  identify vs interpret — p = 0.000000 (< 0.001)\n",
      "  cluster vs predict — p = 0.000000 (< 0.001)\n",
      "  associate vs identify — p = 0.000001 (< 0.001)\n",
      "  identify vs locate — p = 0.000001 (< 0.001)\n",
      "  compare vs identify — p = 0.000006 (< 0.001)\n",
      "  cause/effect vs identify — p = 0.000011 (< 0.001)\n",
      "  cause/effect vs cluster — p = 0.000113 (< 0.001)\n",
      "  predict vs retrieve value — p = 0.000138 (< 0.001)\n",
      "  cluster vs compare — p = 0.000186 (< 0.001)\n",
      "  cluster vs locate — p = 0.000839 (< 0.001)\n",
      "  associate vs cluster — p = 0.001091 (< 0.01)\n",
      "  identify vs predict — p = 0.001927 (< 0.01)\n",
      "  cluster vs interpret — p = 0.006642 (< 0.01)\n",
      "  cause/effect vs retrieve value — p = 0.012203 (< 0.05)\n",
      "  compare vs retrieve value — p = 0.018648 (< 0.05)\n",
      "  interpret vs predict — p = 0.022776 (< 0.05)\n",
      "  locate vs retrieve value — p = 0.049030 (< 0.05)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "6c46cb9a19f7d963",
   "metadata": {},
   "source": [
    "## 3. Map Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "id": "4cab846e124d5719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.653521Z",
     "start_time": "2025-11-30T20:28:06.650508Z"
    }
   },
   "source": [
    "def mann_whitney_analysis(df, group_col, value_col, group1=None, group2=None):\n",
    "    unique_groups = df[group_col].unique()\n",
    "\n",
    "    if group1 is None or group2 is None:\n",
    "        if len(unique_groups) != 2:\n",
    "            raise ValueError(f\"{group_col} must have exactly two unique groups if group1/group2 are not specified.\")\n",
    "        group1, group2 = unique_groups\n",
    "\n",
    "    group1_values = df[df[group_col] == group1][value_col].values\n",
    "    group2_values = df[df[group_col] == group2][value_col].values\n",
    "\n",
    "    # Mann-Whitney U test\n",
    "    u_stat, p_val = mannwhitneyu(group1_values, group2_values, alternative='two-sided')\n",
    "\n",
    "    # Rank-biserial effect size\n",
    "    r = 1 - (2 * u_stat) / (len(group1_values) * len(group2_values))\n",
    "\n",
    "    # Descriptive stats\n",
    "    group_stats = df.groupby(group_col)[value_col].agg(['mean', 'median', 'std', 'count'])\n",
    "\n",
    "    # Output\n",
    "    print(f\"\\n{group_col} distribution: {dict(df[group_col].value_counts())}\")\n",
    "    print(f\"\\nMann-Whitney U test between '{group1}' and '{group2}':\")\n",
    "    print(f\"U = {u_stat:.3f}, p = {p_val:.6f}\")\n",
    "    print(f\"Effect size (rank-biserial r) = {r:.3f}\")\n",
    "    print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    print(group_stats)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "e71238945a741908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.683145Z",
     "start_time": "2025-11-30T20:28:06.671888Z"
    }
   },
   "source": [
    "# C1: Map Graphical Complexity\n",
    "# H0: Map graphical complexity does not affect mean scores\n",
    "# H1: Mean scores differ between low-complex and high-complex maps\n",
    "\n",
    "print(\"C1: MAP GRAPHICAL COMPLEXITY\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "mann_whitney_analysis(df_batch, group_col='graphical_complexity', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "mann_whitney_analysis(df_reading, group_col='graphical_complexity', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "mann_whitney_analysis(df_analysis, group_col='graphical_complexity', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "mann_whitney_analysis(df_interpretation, group_col='graphical_complexity', value_col='score')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1: MAP GRAPHICAL COMPLEXITY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "\n",
      "graphical_complexity distribution: {'low': 864, 'high': 864}\n",
      "\n",
      "Mann-Whitney U test between 'low' and 'high':\n",
      "U = 420971.000, p = 0.000003\n",
      "Effect size (rank-biserial r) = -0.128\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "graphical_complexity                                   \n",
      "high                  2.930787     4.0  2.086586    864\n",
      "low                   3.440046     4.3  1.861930    864\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "\n",
      "graphical_complexity distribution: {'low': 288, 'high': 288}\n",
      "\n",
      "Mann-Whitney U test between 'low' and 'high':\n",
      "U = 48043.500, p = 0.000514\n",
      "Effect size (rank-biserial r) = -0.158\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "graphical_complexity                                   \n",
      "high                  2.440625     3.9  2.405333    288\n",
      "low                   3.218750     4.5  2.244062    288\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "\n",
      "graphical_complexity distribution: {'low': 288, 'high': 288}\n",
      "\n",
      "Mann-Whitney U test between 'low' and 'high':\n",
      "U = 48051.500, p = 0.000812\n",
      "Effect size (rank-biserial r) = -0.159\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "graphical_complexity                                   \n",
      "high                  2.678472    3.85  2.133876    288\n",
      "low                   3.388021    4.10  1.819006    288\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "\n",
      "graphical_complexity distribution: {'low': 288, 'high': 288}\n",
      "\n",
      "Mann-Whitney U test between 'low' and 'high':\n",
      "U = 43094.500, p = 0.415771\n",
      "Effect size (rank-biserial r) = -0.039\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "graphical_complexity                                   \n",
      "high                  3.673264   4.050  1.376456    288\n",
      "low                   3.713368   4.225  1.397529    288\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "62c62a7c586d788c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.714586Z",
     "start_time": "2025-11-30T20:28:06.702851Z"
    }
   },
   "source": [
    "# C2 Spatial aggregation level\n",
    "# H0: Territorial level does not affect mean scores\n",
    "# H1: Mean scores differ between country and region level\n",
    "\n",
    "print(\"C2: SPATIAL AGGREGATION LEVEL\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "mann_whitney_analysis(df_batch, group_col='nuts_level', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "mann_whitney_analysis(df_reading, group_col='nuts_level', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "mann_whitney_analysis(df_analysis, group_col='nuts_level', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "mann_whitney_analysis(df_interpretation, group_col='nuts_level', value_col='score')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2: SPATIAL AGGREGATION LEVEL\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "\n",
      "nuts_level distribution: {'country': 864, 'region': 864}\n",
      "\n",
      "Mann-Whitney U test between 'country' and 'region':\n",
      "U = 392809.500, p = 0.055964\n",
      "Effect size (rank-biserial r) = -0.052\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                mean  median       std  count\n",
      "nuts_level                                   \n",
      "country     3.276736    4.10  1.954428    864\n",
      "region      3.094097    4.05  2.028290    864\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "\n",
      "nuts_level distribution: {'country': 288, 'region': 288}\n",
      "\n",
      "Mann-Whitney U test between 'country' and 'region':\n",
      "U = 46759.000, p = 0.005201\n",
      "Effect size (rank-biserial r) = -0.127\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                mean  median       std  count\n",
      "nuts_level                                   \n",
      "country     3.045833     4.5  2.326289    288\n",
      "region      2.613542     4.3  2.370622    288\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "\n",
      "nuts_level distribution: {'country': 288, 'region': 288}\n",
      "\n",
      "Mann-Whitney U test between 'country' and 'region':\n",
      "U = 45577.500, p = 0.036664\n",
      "Effect size (rank-biserial r) = -0.099\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                mean  median       std  count\n",
      "nuts_level                                   \n",
      "country     3.254861    4.10  1.896558    288\n",
      "region      2.811632    4.05  2.102218    288\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "\n",
      "nuts_level distribution: {'country': 288, 'region': 288}\n",
      "\n",
      "Mann-Whitney U test between 'country' and 'region':\n",
      "U = 37466.000, p = 0.044472\n",
      "Effect size (rank-biserial r) = 0.097\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                mean  median       std  count\n",
      "nuts_level                                   \n",
      "country     3.529514    4.05  1.536013    288\n",
      "region      3.857118    4.20  1.198057    288\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "b16fa00373c570b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.749977Z",
     "start_time": "2025-11-30T20:28:06.738509Z"
    }
   },
   "source": [
    "# C3: Map Source\n",
    "# H0: Map source does not affect mean scores\n",
    "# H1: Mean scores differ by map source\n",
    "\n",
    "print(\"C3: MAP SOURCE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "mann_whitney_analysis(df_batch, group_col='map_source', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "mann_whitney_analysis(df_reading, group_col='map_source', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "mann_whitney_analysis(df_analysis, group_col='map_source', value_col='score')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpretation subset:\")\n",
    "mann_whitney_analysis(df_interpretation, group_col='map_source', value_col='score')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3: MAP SOURCE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "\n",
      "map_source distribution: {'atlas': 864, 'statistical_office': 864}\n",
      "\n",
      "Mann-Whitney U test between 'atlas' and 'statistical_office':\n",
      "U = 365969.500, p = 0.477000\n",
      "Effect size (rank-biserial r) = 0.020\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                        mean  median       std  count\n",
      "map_source                                           \n",
      "atlas               3.105208     4.1  2.053629    864\n",
      "statistical_office  3.265625     4.1  1.928775    864\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "\n",
      "map_source distribution: {'atlas': 288, 'statistical_office': 288}\n",
      "\n",
      "Mann-Whitney U test between 'atlas' and 'statistical_office':\n",
      "U = 38704.500, p = 0.143587\n",
      "Effect size (rank-biserial r) = 0.067\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                        mean  median       std  count\n",
      "map_source                                           \n",
      "atlas               2.668056     4.4  2.386275    288\n",
      "statistical_office  2.991319     4.5  2.319158    288\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "\n",
      "map_source distribution: {'atlas': 288, 'statistical_office': 288}\n",
      "\n",
      "Mann-Whitney U test between 'atlas' and 'statistical_office':\n",
      "U = 43039.500, p = 0.425092\n",
      "Effect size (rank-biserial r) = -0.038\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                        mean  median       std  count\n",
      "map_source                                           \n",
      "atlas               3.037674    4.10  2.039373    288\n",
      "statistical_office  3.028819    4.05  1.988904    288\n",
      "--------------------------------------------------------------------------------\n",
      "Interpretation subset:\n",
      "\n",
      "map_source distribution: {'atlas': 288, 'statistical_office': 288}\n",
      "\n",
      "Mann-Whitney U test between 'atlas' and 'statistical_office':\n",
      "U = 41781.500, p = 0.876798\n",
      "Effect size (rank-biserial r) = -0.007\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                        mean  median       std  count\n",
      "map_source                                           \n",
      "atlas               3.609896   4.075  1.541515    288\n",
      "statistical_office  3.776736   4.050  1.207597    288\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "dd76e59b7f9baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.774433Z",
     "start_time": "2025-11-30T20:28:06.769736Z"
    }
   },
   "source": [
    "def analyze_categorical_effect(df, group_col, value_col='score', min_group_size=20, do_posthoc=True):\n",
    "    df_sub = df[df[group_col].notna() & (df[group_col] != '')].copy()\n",
    "    print(f\"Available observations: {len(df_sub)}\")\n",
    "\n",
    "    if len(df_sub) == 0:\n",
    "        print(\"No data available for analysis.\")\n",
    "        return\n",
    "\n",
    "    group_counts = df_sub[group_col].value_counts()\n",
    "    print(f\"{group_col} distribution:\\n{group_counts}\\n\")\n",
    "\n",
    "    if len(group_counts) < 2 or group_counts.min() < min_group_size:\n",
    "        print(f\"Insufficient data (need ≥{min_group_size} per group).\")\n",
    "        return\n",
    "\n",
    "    groups = [df_sub[df_sub[group_col] == g][value_col].values for g in sorted(df_sub[group_col].unique())]\n",
    "\n",
    "    if len(groups) == 2:\n",
    "        u_stat, p_val = mannwhitneyu(groups[0], groups[1], alternative='two-sided')\n",
    "        r = 1 - (2 * u_stat) / (len(groups[0]) * len(groups[1]))\n",
    "        print(f\"Mann–Whitney U = {u_stat:.3f}, p = {p_val:.6f}\")\n",
    "        print(f\"Effect size (rank-biserial r) = {r:.3f}\")\n",
    "        print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "    else:\n",
    "        h_stat, p_val = kruskal(*groups)\n",
    "        n, k = len(df_sub), len(groups)\n",
    "        epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "        print(f\"Kruskal–Wallis H = {h_stat:.3f}, p = {p_val:.6f}\")\n",
    "        print(f\"Effect size (ε²) = {epsilon_sq:.3f}\")\n",
    "        print(f\"Significant: {'YES' if p_val < 0.05 else 'NO'}\")\n",
    "\n",
    "        if p_val < 0.05 and do_posthoc:\n",
    "            posthoc = posthoc_dunn(df_sub, val_col=value_col, group_col=group_col, p_adjust='fdr_bh')\n",
    "            print(\"\\nPost-hoc Dunn test (adjusted p-values < 0.05):\")\n",
    "            sig_pairs = []\n",
    "            for i, row in enumerate(posthoc.index):\n",
    "                for j, col in enumerate(posthoc.columns):\n",
    "                    if j <= i:\n",
    "                        continue\n",
    "                    p = posthoc.loc[row, col]\n",
    "                    if p < 0.05:\n",
    "                        sig_pairs.append((row, col, p))\n",
    "            if not sig_pairs:\n",
    "                print(\"No significant post-hoc differences.\")\n",
    "            else:\n",
    "                for a, b, p in sorted(sig_pairs, key=lambda x: x[2]):\n",
    "                    print(f\"  {a} vs {b} — p = {p:.6f}\")\n",
    "\n",
    "    desc = df_sub.groupby(group_col)[value_col].agg(['mean', 'median', 'std', 'count']).sort_values('mean', ascending=False)\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    print(desc)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "cc85a053a1836c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.811574Z",
     "start_time": "2025-11-30T20:28:06.794870Z"
    }
   },
   "source": [
    "# C4: MAP TYPE\n",
    "# H0: There is no effect of the map type on model performance.\n",
    "# H1: There is a significant effect of map type.\n",
    "\n",
    "print(\"C4: MAP TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "analyze_categorical_effect(df_batch, 'viz_technique', min_group_size=10)\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "analyze_categorical_effect(df_reading, 'viz_technique', min_group_size=10)\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "analyze_categorical_effect(df_analysis, 'viz_technique', min_group_size=10)\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpreting subset:\")\n",
    "analyze_categorical_effect(df_interpretation, 'viz_technique', min_group_size=10)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4: MAP TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "Available observations: 864\n",
      "viz_technique distribution:\n",
      "viz_technique\n",
      "choropleth             324\n",
      "point-based symbols    324\n",
      "cartogram              216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal–Wallis H = 11.159, p = 0.003775\n",
      "Effect size (ε²) = 0.011\n",
      "Significant: YES\n",
      "\n",
      "Post-hoc Dunn test (adjusted p-values < 0.05):\n",
      "  cartogram vs choropleth — p = 0.002525\n",
      "\n",
      "Descriptive statistics:\n",
      "                         mean  median       std  count\n",
      "viz_technique                                         \n",
      "cartogram            3.789352    4.35  1.634491    216\n",
      "point-based symbols  3.439815    4.30  1.877706    324\n",
      "choropleth           3.207407    4.10  1.955173    324\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "Available observations: 288\n",
      "viz_technique distribution:\n",
      "viz_technique\n",
      "choropleth             108\n",
      "point-based symbols    108\n",
      "cartogram               72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal–Wallis H = 2.650, p = 0.265835\n",
      "Effect size (ε²) = 0.002\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                         mean  median       std  count\n",
      "viz_technique                                         \n",
      "cartogram            3.450000     4.6  2.172815     72\n",
      "point-based symbols  3.159259     4.5  2.218320    108\n",
      "choropleth           3.124074     4.6  2.324870    108\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "Available observations: 288\n",
      "viz_technique distribution:\n",
      "viz_technique\n",
      "choropleth             108\n",
      "point-based symbols    108\n",
      "cartogram               72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal–Wallis H = 19.059, p = 0.000073\n",
      "Effect size (ε²) = 0.060\n",
      "Significant: YES\n",
      "\n",
      "Post-hoc Dunn test (adjusted p-values < 0.05):\n",
      "  cartogram vs choropleth — p = 0.000146\n",
      "  cartogram vs point-based symbols — p = 0.000303\n",
      "\n",
      "Descriptive statistics:\n",
      "                         mean  median       std  count\n",
      "viz_technique                                         \n",
      "cartogram            4.223611     4.3  0.981626     72\n",
      "choropleth           3.140741     4.1  1.905478    108\n",
      "point-based symbols  3.078241     4.1  1.994072    108\n",
      "--------------------------------------------------------------------------------\n",
      "Interpreting subset:\n",
      "Available observations: 288\n",
      "viz_technique distribution:\n",
      "viz_technique\n",
      "choropleth             108\n",
      "point-based symbols    108\n",
      "cartogram               72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Kruskal–Wallis H = 15.568, p = 0.000416\n",
      "Effect size (ε²) = 0.048\n",
      "Significant: YES\n",
      "\n",
      "Post-hoc Dunn test (adjusted p-values < 0.05):\n",
      "  choropleth vs point-based symbols — p = 0.000240\n",
      "\n",
      "Descriptive statistics:\n",
      "                         mean  median       std  count\n",
      "viz_technique                                         \n",
      "point-based symbols  4.081944   4.300  1.057538    108\n",
      "cartogram            3.694444   4.225  1.445015     72\n",
      "choropleth           3.357407   3.775  1.571457    108\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "d40c0fe51a014878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.843262Z",
     "start_time": "2025-11-30T20:28:06.830809Z"
    }
   },
   "source": [
    "# C5: SYMBOL SCALING\n",
    "# H0: There is no effect of the symbol scaling on model performance.\n",
    "# H1: There is a significant effect of symbol scaling.\n",
    "\n",
    "print(\"C5: SYMBOL SCALING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "analyze_categorical_effect(df_batch, 'symbol_scaling')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "analyze_categorical_effect(df_reading, 'symbol_scaling')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "analyze_categorical_effect(df_analysis, 'symbol_scaling')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpreting subset:\")\n",
    "analyze_categorical_effect(df_interpretation, 'symbol_scaling')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C5: SYMBOL SCALING\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "Available observations: 1188\n",
      "symbol_scaling distribution:\n",
      "symbol_scaling\n",
      "proportional symbols    648\n",
      "graduated symbols       540\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 164155.500, p = 0.062328\n",
      "Effect size (rank-biserial r) = 0.062\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "symbol_scaling                                         \n",
      "proportional symbols  3.208873    4.10  1.965625    648\n",
      "graduated symbols     2.902500    4.05  2.123198    540\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "Available observations: 396\n",
      "symbol_scaling distribution:\n",
      "symbol_scaling\n",
      "proportional symbols    216\n",
      "graduated symbols       180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 17387.000, p = 0.054807\n",
      "Effect size (rank-biserial r) = 0.106\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "symbol_scaling                                         \n",
      "proportional symbols  2.857407     4.5  2.344323    216\n",
      "graduated symbols     2.371667     1.7  2.390397    180\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "Available observations: 396\n",
      "symbol_scaling distribution:\n",
      "symbol_scaling\n",
      "proportional symbols    216\n",
      "graduated symbols       180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 18590.000, p = 0.442566\n",
      "Effect size (rank-biserial r) = 0.044\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "symbol_scaling                                         \n",
      "proportional symbols  2.885185   3.975  2.064825    216\n",
      "graduated symbols     2.670278   3.900  2.145107    180\n",
      "--------------------------------------------------------------------------------\n",
      "Interpreting subset:\n",
      "Available observations: 396\n",
      "symbol_scaling distribution:\n",
      "symbol_scaling\n",
      "proportional symbols    216\n",
      "graduated symbols       180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 19521.500, p = 0.942935\n",
      "Effect size (rank-biserial r) = -0.004\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                          mean  median       std  count\n",
      "symbol_scaling                                         \n",
      "proportional symbols  3.884028    4.05  1.086422    216\n",
      "graduated symbols     3.665556    4.05  1.528302    180\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "7052ef6250674d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.876934Z",
     "start_time": "2025-11-30T20:28:06.864213Z"
    }
   },
   "source": [
    "# C6: DIAGRAM STRUCTURE\n",
    "# H0: There is no effect of the diagram structure on model performance.\n",
    "# H1: There is a significant effect of diagram structure.\n",
    "\n",
    "print(\"C6: DIAGRAM STRUCTURE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nOverall dataset:\")\n",
    "analyze_categorical_effect(df_batch, 'diagram_structure')\n",
    "print(\"-\" * 80)\n",
    "print(\"Reading subset:\")\n",
    "analyze_categorical_effect(df_reading, 'diagram_structure')\n",
    "print(\"-\" * 80)\n",
    "print(\"Analysis subset:\")\n",
    "analyze_categorical_effect(df_analysis, 'diagram_structure')\n",
    "print(\"-\" * 80)\n",
    "print(\"Interpreting subset:\")\n",
    "analyze_categorical_effect(df_interpretation, 'diagram_structure')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C6: DIAGRAM STRUCTURE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall dataset:\n",
      "Available observations: 1188\n",
      "diagram_structure distribution:\n",
      "diagram_structure\n",
      "uniform       648\n",
      "structural    540\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 181197.000, p = 0.281950\n",
      "Effect size (rank-biserial r) = -0.036\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                       mean  median       std  count\n",
      "diagram_structure                                   \n",
      "structural         3.109630   4.075  2.059428    540\n",
      "uniform            3.036265   4.025  2.031297    648\n",
      "--------------------------------------------------------------------------------\n",
      "Reading subset:\n",
      "Available observations: 396\n",
      "diagram_structure distribution:\n",
      "diagram_structure\n",
      "uniform       216\n",
      "structural    180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 18489.500, p = 0.374078\n",
      "Effect size (rank-biserial r) = 0.049\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                       mean  median       std  count\n",
      "diagram_structure                                   \n",
      "uniform            2.781944    4.45  2.348616    216\n",
      "structural         2.462222    3.90  2.400655    180\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis subset:\n",
      "Available observations: 396\n",
      "diagram_structure distribution:\n",
      "diagram_structure\n",
      "uniform       216\n",
      "structural    180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 21482.500, p = 0.064925\n",
      "Effect size (rank-biserial r) = -0.105\n",
      "Significant: NO\n",
      "\n",
      "Descriptive statistics:\n",
      "                       mean  median       std  count\n",
      "diagram_structure                                   \n",
      "structural         3.009167   4.050  2.048419    180\n",
      "uniform            2.602778   3.825  2.132310    216\n",
      "--------------------------------------------------------------------------------\n",
      "Interpreting subset:\n",
      "Available observations: 396\n",
      "diagram_structure distribution:\n",
      "diagram_structure\n",
      "uniform       216\n",
      "structural    180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mann–Whitney U = 21711.000, p = 0.044803\n",
      "Effect size (rank-biserial r) = -0.117\n",
      "Significant: YES\n",
      "\n",
      "Descriptive statistics:\n",
      "                       mean  median       std  count\n",
      "diagram_structure                                   \n",
      "structural         3.857500   4.125  1.348292    180\n",
      "uniform            3.724074   4.000  1.274791    216\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "165605e4da564b4a",
   "metadata": {},
   "source": [
    "## 4. Interactions"
   ]
  },
  {
   "cell_type": "code",
   "id": "c790bfe951a15def",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:06.907184Z",
     "start_time": "2025-11-30T20:28:06.901396Z"
    }
   },
   "source": [
    "def scheirer_ray_hare_test(df, value_col, factor1_col, factor2_col):\n",
    "    df = df.copy()\n",
    "    df['rank'] = rankdata(df[value_col])\n",
    "\n",
    "    n = len(df)\n",
    "    a = df[factor1_col].nunique()\n",
    "    b = df[factor2_col].nunique()\n",
    "\n",
    "    grand_mean_rank = df['rank'].mean()\n",
    "\n",
    "    ss_factor1 = 0\n",
    "    for level in df[factor1_col].unique():\n",
    "        subset = df[df[factor1_col] == level]\n",
    "        n_level = len(subset)\n",
    "        mean_rank = subset['rank'].mean()\n",
    "        ss_factor1 += n_level * (mean_rank - grand_mean_rank)**2\n",
    "\n",
    "    ss_factor2 = 0\n",
    "    for level in df[factor2_col].unique():\n",
    "        subset = df[df[factor2_col] == level]\n",
    "        n_level = len(subset)\n",
    "        mean_rank = subset['rank'].mean()\n",
    "        ss_factor2 += n_level * (mean_rank - grand_mean_rank)**2\n",
    "\n",
    "    ss_total = np.sum((df['rank'] - grand_mean_rank)**2)\n",
    "    ss_interaction = ss_total - ss_factor1 - ss_factor2\n",
    "    ms_total = ss_total / (n - 1)\n",
    "\n",
    "    H_factor1 = ss_factor1 / ms_total\n",
    "    H_factor2 = ss_factor2 / ms_total\n",
    "    H_interaction = ss_interaction / ms_total\n",
    "\n",
    "    df_factor1 = a - 1\n",
    "    df_factor2 = b - 1\n",
    "    df_interaction = (a - 1) * (b - 1)\n",
    "\n",
    "    p_factor1 = 1 - chi2.cdf(H_factor1, df_factor1)\n",
    "    p_factor2 = 1 - chi2.cdf(H_factor2, df_factor2)\n",
    "    p_interaction = 1 - chi2.cdf(H_interaction, df_interaction)\n",
    "\n",
    "    return {\n",
    "        'model_effect': {'H': H_factor1, 'df': df_factor1, 'p': p_factor1},\n",
    "        f'{factor2_col}_effect': {'H': H_factor2, 'df': df_factor2, 'p': p_factor2},\n",
    "        'interaction': {'H': H_interaction, 'df': df_interaction, 'p': p_interaction}\n",
    "    }\n",
    "\n",
    "\n",
    "def permutation_interaction_test(df, value_col, factor1_col, factor2_col, n_permutations=10000):\n",
    "    observed_stat = 0\n",
    "    for level in df[factor2_col].unique():\n",
    "        subset = df[df[factor2_col] == level]\n",
    "        groups = [subset[subset[factor1_col] == m][value_col].values\n",
    "                  for m in subset[factor1_col].unique()]\n",
    "        h, _ = kruskal(*groups)\n",
    "        observed_stat += h\n",
    "\n",
    "    permuted_stats = []\n",
    "    for _ in range(n_permutations):\n",
    "        df_perm = df.copy()\n",
    "        df_perm[value_col] = np.random.permutation(df_perm[value_col].values)\n",
    "\n",
    "        perm_stat = 0\n",
    "        for level in df_perm[factor2_col].unique():\n",
    "            subset = df_perm[df_perm[factor2_col] == level]\n",
    "            groups = [subset[subset[factor1_col] == m][value_col].values\n",
    "                      for m in subset[factor1_col].unique()]\n",
    "            h, _ = kruskal(*groups)\n",
    "            perm_stat += h\n",
    "        permuted_stats.append(perm_stat)\n",
    "\n",
    "    p_value = np.mean(np.array(permuted_stats) >= observed_stat)\n",
    "\n",
    "    return {'statistic': observed_stat, 'p_value': p_value}\n",
    "\n",
    "\n",
    "def test_ranking_consistency(df, value_col, factor1_col, factor2_col):\n",
    "    pivot = df.pivot_table(values=value_col, index=factor1_col,\n",
    "                           columns=factor2_col, aggfunc='mean')\n",
    "\n",
    "    rankings = pivot.rank(ascending=False)\n",
    "    categories = rankings.columns.tolist()\n",
    "    results = []\n",
    "\n",
    "    for i, cat1 in enumerate(categories):\n",
    "        for cat2 in categories[i+1:]:\n",
    "            tau, p = kendalltau(rankings[cat1], rankings[cat2])\n",
    "            results.append({\n",
    "                'category1': cat1,\n",
    "                'category2': cat2,\n",
    "                'kendall_tau': tau,\n",
    "                'p_value': p,\n",
    "                'agreement': 'high' if tau > 0.7 else 'moderate' if tau > 0.4 else 'low'\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results), rankings"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "8b4f9a254c2cacb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:59.871493Z",
     "start_time": "2025-11-30T20:28:06.925047Z"
    }
   },
   "source": [
    "# I1: Model x Map Usage Type intersection\n",
    "# H0: No interaction effect between Model and Map Usage Type.\n",
    "# H1: An interaction effect exists between Model and Map Usage Type.\n",
    "\n",
    "print(\"I1: MODEL × MAP USAGE TYPE INTERACTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"Scheirer-Ray-Hare test:\")\n",
    "results = scheirer_ray_hare_test(df_batch, 'score', 'model_name', 'map_usage_type')\n",
    "print(f\"Model effect: H = {results['model_effect']['H']:.3f}, p = {results['model_effect']['p']:.6f}\")\n",
    "print(f\"Usage type effect: H = {results['map_usage_type_effect']['H']:.3f}, p = {results['map_usage_type_effect']['p']:.6f}\")\n",
    "print(f\"Interaction: H = {results['interaction']['H']:.3f}, p = {results['interaction']['p']:.6f}\")\n",
    "\n",
    "print(\"Permutation test\")\n",
    "result = permutation_interaction_test(df_batch, 'score', 'model_name', 'map_usage_type')\n",
    "print(f\"Interaction test: stat = {result['statistic']:.3f}, p = {result['p_value']:.6f}\")\n",
    "\n",
    "print(\"Ranking consistency test\")\n",
    "comparison_results, rankings = test_ranking_consistency(\n",
    "    df_batch, 'score', 'model_name', 'map_usage_type'\n",
    ")\n",
    "print(\"\\nRanking consistency:\")\n",
    "print(comparison_results)\n",
    "print(\"\\nRankings per category:\")\n",
    "print(rankings)\n",
    "\n",
    "print(\"Simple effects analysis:\")\n",
    "interaction_results_c1 = []\n",
    "for category in sorted(df_batch['map_usage_type'].unique()):\n",
    "    subset = df_batch[df_batch['map_usage_type'] == category]\n",
    "    model_groups_cat = [subset[subset['model_name'] == model]['score'].values\n",
    "                        for model in sorted(subset['model_name'].unique())]\n",
    "    h, p = kruskal(*model_groups_cat)\n",
    "    interaction_results_c1.append({\n",
    "        'category': category,\n",
    "        'H': h,\n",
    "        'p': p,\n",
    "        'significant': p < 0.05\n",
    "    })\n",
    "    print(f\"\\n{category}: H = {h:.3f}, p = {p:.6f} {'*' if p < 0.05 else ''}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        cat_means = subset.groupby('model_name')['score'].mean().sort_values(ascending=False)\n",
    "        print(f\"  Top 3 models: {', '.join(cat_means.head(3).index.tolist())}\")\n",
    "\n",
    "# FDR correction across categories\n",
    "p_values_c1 = [r['p'] for r in interaction_results_c1]\n",
    "rejected, p_corrected, _, _ = multipletests(p_values_c1, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "print(\"\\n\\nFDR-corrected results:\")\n",
    "for i, result in enumerate(interaction_results_c1):\n",
    "    result['p_corrected'] = p_corrected[i]\n",
    "    result['significant_corrected'] = rejected[i]\n",
    "    print(f\"{result['category']}: p_corrected = {p_corrected[i]:.6f} {'*' if rejected[i] else ''}\")\n",
    "\n",
    "# Interaction heatmap data\n",
    "interaction_matrix_c1 = df_batch.pivot_table(\n",
    "    values='score',\n",
    "    index='model_name',\n",
    "    columns='map_usage_type',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(\"\\n\\nMean scores (Model × Map Usage Type):\")\n",
    "print(interaction_matrix_c1.round(3))\n",
    "\n",
    "# Calculate performance range per model\n",
    "performance_range = interaction_matrix_c1.max(axis=1) - interaction_matrix_c1.min(axis=1)\n",
    "performance_range_df = pd.DataFrame({\n",
    "    'model_name': performance_range.index,\n",
    "    'range': performance_range.values,\n",
    "    'min_category': interaction_matrix_c1.idxmin(axis=1),\n",
    "    'max_category': interaction_matrix_c1.idxmax(axis=1)\n",
    "}).sort_values(by='range', ascending=False)\n",
    "\n",
    "print(\"\\nPerformance range per model (max mean - min mean):\")\n",
    "for _, row in performance_range_df.iterrows():\n",
    "    print(f\"{row['model_name']}: range = {row['range']:.2f} \"\n",
    "          f\"(worst: {row['min_category']}, best: {row['max_category']})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1: MODEL × MAP USAGE TYPE INTERACTION\n",
      "--------------------------------------------------------------------------------\n",
      "Scheirer-Ray-Hare test:\n",
      "Model effect: H = 90.453, p = 0.000000\n",
      "Usage type effect: H = 15.191, p = 0.000503\n",
      "Interaction: H = 1621.356, p = 0.000000\n",
      "Permutation test\n",
      "Interaction test: stat = 127.843, p = 0.000000\n",
      "Ranking consistency test\n",
      "\n",
      "Ranking consistency:\n",
      "        category1       category2  kendall_tau   p_value agreement\n",
      "0        analysis  interpretation     0.242424  0.310810       low\n",
      "1        analysis         reading     0.484848  0.031050  moderate\n",
      "2  interpretation         reading     0.090909  0.737306       low\n",
      "\n",
      "Rankings per category:\n",
      "map_usage_type        analysis  interpretation  reading\n",
      "model_name                                             \n",
      "Claude 3.5 Sonnet v2       2.0             7.0      3.0\n",
      "Claude 3.7 Sonnet          1.0             1.0      1.0\n",
      "DeepSeek-R1               11.0            11.0      8.0\n",
      "GPT o3                     3.0             4.0      5.0\n",
      "GPT-4o                     7.0             3.0     11.0\n",
      "Gemini 1.5 Pro             6.0             8.0      6.0\n",
      "Gemma 3                    5.0             6.0     12.0\n",
      "Grok-3                     4.0            10.0      2.0\n",
      "MiniMax-01                12.0             2.0     10.0\n",
      "Mistral Large              8.0             5.0      4.0\n",
      "Qwen2.5-Max                9.0             9.0      7.0\n",
      "Sonar                     10.0            12.0      9.0\n",
      "Simple effects analysis:\n",
      "\n",
      "analysis: H = 46.375, p = 0.000003 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Claude 3.5 Sonnet v2, GPT o3\n",
      "\n",
      "interpretation: H = 44.476, p = 0.000006 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, MiniMax-01, GPT-4o\n",
      "\n",
      "reading: H = 36.992, p = 0.000116 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Grok-3, Claude 3.5 Sonnet v2\n",
      "\n",
      "\n",
      "FDR-corrected results:\n",
      "analysis: p_corrected = 0.000008 *\n",
      "interpretation: p_corrected = 0.000009 *\n",
      "reading: p_corrected = 0.000116 *\n",
      "\n",
      "\n",
      "Mean scores (Model × Map Usage Type):\n",
      "map_usage_type        analysis  interpretation  reading\n",
      "model_name                                             \n",
      "Claude 3.5 Sonnet v2     3.635           3.733    3.363\n",
      "Claude 3.7 Sonnet        3.893           4.409    3.504\n",
      "DeepSeek-R1              2.504           3.368    2.533\n",
      "GPT o3                   3.509           3.858    3.171\n",
      "GPT-4o                   2.941           3.902    2.092\n",
      "Gemini 1.5 Pro           3.070           3.689    3.104\n",
      "Gemma 3                  3.121           3.754    2.054\n",
      "Grok-3                   3.227           3.402    3.423\n",
      "MiniMax-01               2.444           3.955    2.227\n",
      "Mistral Large            2.903           3.841    3.242\n",
      "Qwen2.5-Max              2.616           3.461    2.783\n",
      "Sonar                    2.535           2.947    2.460\n",
      "\n",
      "Performance range per model (max mean - min mean):\n",
      "GPT-4o: range = 1.81 (worst: reading, best: interpretation)\n",
      "MiniMax-01: range = 1.73 (worst: reading, best: interpretation)\n",
      "Gemma 3: range = 1.70 (worst: reading, best: interpretation)\n",
      "Mistral Large: range = 0.94 (worst: analysis, best: interpretation)\n",
      "Claude 3.7 Sonnet: range = 0.91 (worst: reading, best: interpretation)\n",
      "DeepSeek-R1: range = 0.86 (worst: analysis, best: interpretation)\n",
      "Qwen2.5-Max: range = 0.85 (worst: analysis, best: interpretation)\n",
      "GPT o3: range = 0.69 (worst: reading, best: interpretation)\n",
      "Gemini 1.5 Pro: range = 0.62 (worst: analysis, best: interpretation)\n",
      "Sonar: range = 0.49 (worst: reading, best: interpretation)\n",
      "Claude 3.5 Sonnet v2: range = 0.37 (worst: reading, best: interpretation)\n",
      "Grok-3: range = 0.20 (worst: analysis, best: reading)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "8bfa23e6e5b97a39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:59.921989Z",
     "start_time": "2025-11-30T20:28:59.895610Z"
    }
   },
   "source": [
    "# I2: Graphical complexity x Map Usage Type\n",
    "# H0: There are no significant effects of map graphical complexity or map usage type on model performance, and no interaction between these factors.\n",
    "# H1: There is a significant interaction between graphical complexity and map usage type.\n",
    "\n",
    "print(\"I2: GRAPHICAL COMPLEXITY × MAP USAGE TYPE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ===== 1. MAIN EFFECTS =====\n",
    "\n",
    "df_c5 = df_batch[['score', 'graphical_complexity', 'map_usage_type']].copy()\n",
    "\n",
    "df_c5['rank'] = df_c5['score'].rank()\n",
    "\n",
    "model = ols('rank ~ C(graphical_complexity) + C(map_usage_type) + C(graphical_complexity):C(map_usage_type)',\n",
    "            data=df_c5).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "N = len(df_c5)\n",
    "anova_table['H'] = anova_table['F'] * (anova_table['df'] + 1)\n",
    "anova_table['p_srh'] = chi2.sf(anova_table['H'], anova_table['df'])\n",
    "\n",
    "print(\"Scheirer-Ray-Hare Test Results:\")\n",
    "print(f\"Complexity effect: H = {anova_table.loc['C(graphical_complexity)', 'H']:.3f}, \" +\n",
    "      f\"p = {anova_table.loc['C(graphical_complexity)', 'p_srh']:.6f}\")\n",
    "print(f\"Usage type effect: H = {anova_table.loc['C(map_usage_type)', 'H']:.3f}, \" +\n",
    "      f\"p = {anova_table.loc['C(map_usage_type)', 'p_srh']:.6f}\")\n",
    "print(f\"Interaction: H = {anova_table.loc['C(graphical_complexity):C(map_usage_type)', 'H']:.3f}, \" +\n",
    "      f\"p = {anova_table.loc['C(graphical_complexity):C(map_usage_type)', 'p_srh']:.6f}\")\n",
    "\n",
    "interaction_p = anova_table.loc['C(graphical_complexity):C(map_usage_type)', 'p_srh']\n",
    "print(f\"\\nInteraction significant: {'YES' if interaction_p < 0.05 else 'NO'}\")\n",
    "\n",
    "# ===== 2. SIMPLE EFFECTS =====\n",
    "if interaction_p < 0.05:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Simple effects analysis (post-hoc):\")\n",
    "    interaction_results_c5 = []\n",
    "\n",
    "    for category in sorted(df_batch['map_usage_type'].unique()):\n",
    "        subset = df_batch[df_batch['map_usage_type'] == category]\n",
    "        comp_groups = [subset[subset['graphical_complexity'] == comp]['score'].values\n",
    "                       for comp in sorted(subset['graphical_complexity'].unique())]\n",
    "        u, p = mannwhitneyu(comp_groups[0], comp_groups[1], alternative='two-sided')\n",
    "\n",
    "        # Effect size\n",
    "        n1, n2 = len(comp_groups[0]), len(comp_groups[1])\n",
    "        r = 1 - (2*u) / (n1 * n2)  # rank-biserial\n",
    "\n",
    "        interaction_results_c5.append({\n",
    "            'category': category,\n",
    "            'U': u,\n",
    "            'p': p,\n",
    "            'r': r,\n",
    "            'significant': p < 0.05\n",
    "        })\n",
    "        print(f\"\\n{category}: U = {u:.3f}, p = {p:.6f}, r = {r:.3f} {'*' if p < 0.05 else ''}\")\n",
    "\n",
    "    # FDR correction\n",
    "    p_values_c5 = [r['p'] for r in interaction_results_c5]\n",
    "    rejected_c5, p_corrected_c5, _, _ = multipletests(p_values_c5, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    print(\"\\n\\nFDR-corrected results:\")\n",
    "    for i, result in enumerate(interaction_results_c5):\n",
    "        result['p_corrected'] = p_corrected_c5[i]\n",
    "        result['significant_corrected'] = rejected_c5[i]\n",
    "        print(f\"{result['category']}: p_corrected = {p_corrected_c5[i]:.6f} {'*' if rejected_c5[i] else ''}\")\n",
    "else:\n",
    "    print(\"\\nInteraction not significant - simple effects analysis not warranted\")\n",
    "    print(\"Main effect of complexity applies uniformly across usage types\")\n",
    "\n",
    "# ===== 3. DESCRIPTIVE STATISTICS =====\n",
    "print(\"\\n\\nMean scores (Complexity × Category):\")\n",
    "interaction_matrix_c5 = df_batch.pivot_table(\n",
    "    values='score',\n",
    "    index='graphical_complexity',\n",
    "    columns='map_usage_type',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(interaction_matrix_c5.round(3))\n",
    "\n",
    "print(\"\\n\\nEffect of low complexity (difference from high):\")\n",
    "for col in interaction_matrix_c5.columns:\n",
    "    diff = interaction_matrix_c5.loc['low', col] - interaction_matrix_c5.loc['high', col]\n",
    "    print(f\"{col}: +{diff:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I2: GRAPHICAL COMPLEXITY × MAP USAGE TYPE\n",
      "--------------------------------------------------------------------------------\n",
      "Scheirer-Ray-Hare Test Results:\n",
      "Complexity effect: H = 44.492, p = 0.000000\n",
      "Usage type effect: H = 23.313, p = 0.000009\n",
      "Interaction: H = 10.667, p = 0.004827\n",
      "\n",
      "Interaction significant: YES\n",
      "\n",
      "================================================================================\n",
      "Simple effects analysis (post-hoc):\n",
      "\n",
      "analysis: U = 34892.500, p = 0.000812, r = 0.159 *\n",
      "\n",
      "interpretation: U = 39849.500, p = 0.415771, r = 0.039 \n",
      "\n",
      "reading: U = 34900.500, p = 0.000514, r = 0.158 *\n",
      "\n",
      "\n",
      "FDR-corrected results:\n",
      "analysis: p_corrected = 0.001218 *\n",
      "interpretation: p_corrected = 0.415771 \n",
      "reading: p_corrected = 0.001218 *\n",
      "\n",
      "\n",
      "Mean scores (Complexity × Category):\n",
      "map_usage_type        analysis  interpretation  reading\n",
      "graphical_complexity                                   \n",
      "high                     2.678           3.673    2.441\n",
      "low                      3.388           3.713    3.219\n",
      "\n",
      "\n",
      "Effect of low complexity (difference from high):\n",
      "analysis: +0.710\n",
      "interpretation: +0.040\n",
      "reading: +0.778\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "4430666568dda9ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:29:00.001157Z",
     "start_time": "2025-11-30T20:28:59.979318Z"
    }
   },
   "source": [
    "# I3: Model x Graphical complexity\n",
    "# H0: There is no significant effect of the model, no effect of graphical complexity, and no interaction between model and graphical complexity.\n",
    "# H1: There is a significant interaction between model and graphical complexity.\n",
    "\n",
    "print(\"I3: MODEL × GRAPHICAL COMPLEXITY INTERACTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results = scheirer_ray_hare_test(df_batch, 'score', 'model_name', 'graphical_complexity')\n",
    "print(f\"Model effect: H = {results['model_effect']['H']:.3f}, p = {results['model_effect']['p']:.6f}\")\n",
    "print(f\"Graphical complexity effect: H = {results['graphical_complexity_effect']['H']:.3f}, p = {results['graphical_complexity_effect']['p']:.6f}\")\n",
    "print(f\"Interaction: H = {results['interaction']['H']:.3f}, p = {results['interaction']['p']:.6f}\")\n",
    "\n",
    "print(\"Simple effects analysis:\")\n",
    "interaction_results_c2 = []\n",
    "for complexity in sorted(df_batch['graphical_complexity'].unique()):\n",
    "    subset = df_batch[df_batch['graphical_complexity'] == complexity]\n",
    "    model_groups_comp = [subset[subset['model_name'] == model]['score'].values\n",
    "                         for model in sorted(subset['model_name'].unique())]\n",
    "    h, p = kruskal(*model_groups_comp)\n",
    "    interaction_results_c2.append({\n",
    "        'graphical_complexity': complexity,\n",
    "        'H': h,\n",
    "        'p': p,\n",
    "        'significant': p < 0.05\n",
    "    })\n",
    "    print(f\"\\n{complexity}: H = {h:.3f}, p = {p:.6f} {'*' if p < 0.05 else ''}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        comp_means = subset.groupby('model_name')['score'].mean().sort_values(ascending=False)\n",
    "        print(f\"  Top 3 models: {', '.join(comp_means.head(3).index.tolist())}\")\n",
    "\n",
    "p_values_c2 = [r['p'] for r in interaction_results_c2]\n",
    "rejected_c2, p_corrected_c2, _, _ = multipletests(p_values_c2, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "print(\"\\n\\nFDR-corrected results:\")\n",
    "for i, result in enumerate(interaction_results_c2):\n",
    "    result['p_corrected'] = p_corrected_c2[i]\n",
    "    result['significant_corrected'] = rejected_c2[i]\n",
    "    print(f\"{result['graphical_complexity']}: p_corrected = {p_corrected_c2[i]:.6f} {'*' if rejected_c2[i] else ''}\")\n",
    "\n",
    "interaction_matrix_c2 = df_batch.pivot_table(\n",
    "    values='score',\n",
    "    index='model_name',\n",
    "    columns='graphical_complexity',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "interaction_matrix_c2['low_minus_high'] = (\n",
    "    interaction_matrix_c2['low'] - interaction_matrix_c2['high']\n",
    ")\n",
    "\n",
    "print(\"\\n\\nMean scores (Model × Graphical Complexity):\")\n",
    "print(interaction_matrix_c2.round(3))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I3: MODEL × GRAPHICAL COMPLEXITY INTERACTION\n",
      "--------------------------------------------------------------------------------\n",
      "Model effect: H = 90.453, p = 0.000000\n",
      "Graphical complexity effect: H = 21.744, p = 0.000003\n",
      "Interaction: H = 1614.803, p = 0.000000\n",
      "Simple effects analysis:\n",
      "\n",
      "high: H = 34.727, p = 0.000275 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Claude 3.5 Sonnet v2, GPT o3\n",
      "\n",
      "low: H = 72.624, p = 0.000000 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Mistral Large, GPT o3\n",
      "\n",
      "\n",
      "FDR-corrected results:\n",
      "high: p_corrected = 0.000275 *\n",
      "low: p_corrected = 0.000000 *\n",
      "\n",
      "\n",
      "Mean scores (Model × Graphical Complexity):\n",
      "graphical_complexity   high    low  low_minus_high\n",
      "model_name                                        \n",
      "Claude 3.5 Sonnet v2  3.425  3.729           0.304\n",
      "Claude 3.7 Sonnet     3.580  4.291           0.711\n",
      "DeepSeek-R1           2.419  3.184           0.765\n",
      "GPT o3                3.241  3.785           0.544\n",
      "GPT-4o                2.815  3.142           0.327\n",
      "Gemini 1.5 Pro        3.134  3.442           0.308\n",
      "Gemma 3               2.910  3.042           0.132\n",
      "Grok-3                2.961  3.740           0.779\n",
      "MiniMax-01            2.473  3.278           0.805\n",
      "Mistral Large         2.866  3.791           0.925\n",
      "Qwen2.5-Max           2.700  3.207           0.507\n",
      "Sonar                 2.645  2.650           0.005\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "5b432515673b8647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:29:00.160084Z",
     "start_time": "2025-11-30T20:29:00.119562Z"
    }
   },
   "source": [
    "# I4: Model x Spatial aggregation level\n",
    "# H0: There is no significant effect of the model, no effect of NUTS level, and no interaction between model and NUTS level.\n",
    "# H1: There is a significant interaction between model and NUTS level.\n",
    "\n",
    "print(\"I4: MODEL × SPATIAL AGGREGATION LEVEL INTERACTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results = scheirer_ray_hare_test(df_batch, 'score', 'model_name', 'nuts_level')\n",
    "print(f\"Model effect: H = {results['model_effect']['H']:.3f}, p = {results['model_effect']['p']:.6f}\")\n",
    "print(f\"NUTS level effect: H = {results['nuts_level_effect']['H']:.3f}, p = {results['nuts_level_effect']['p']:.6f}\")\n",
    "print(f\"Interaction: H = {results['interaction']['H']:.3f}, p = {results['interaction']['p']:.6f}\")\n",
    "\n",
    "print(\"Simple effects analysis:\")\n",
    "interaction_results_c3 = []\n",
    "for nuts in sorted(df_batch['nuts_level'].unique()):\n",
    "    subset = df_batch[df_batch['nuts_level'] == nuts]\n",
    "    model_groups_nuts = [subset[subset['model_name'] == model]['score'].values\n",
    "                         for model in sorted(subset['model_name'].unique())]\n",
    "    h, p = kruskal(*model_groups_nuts)\n",
    "    interaction_results_c3.append({\n",
    "        'nuts_level': nuts,\n",
    "        'H': h,\n",
    "        'p': p,\n",
    "        'significant': p < 0.05\n",
    "    })\n",
    "    print(f\"\\n{nuts}: H = {h:.3f}, p = {p:.6f} {'*' if p < 0.05 else ''}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        nuts_means = subset.groupby('model_name')['score'].mean().sort_values(ascending=False)\n",
    "        print(f\"  Top 3 models: {', '.join(nuts_means.head(3).index.tolist())}\")\n",
    "\n",
    "# FDR correction across NUTS levels\n",
    "p_values_c3 = [r['p'] for r in interaction_results_c3]\n",
    "rejected_c3, p_corrected_c3, _, _ = multipletests(p_values_c3, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "print(\"\\n\\nFDR-corrected results:\")\n",
    "for i, result in enumerate(interaction_results_c3):\n",
    "    result['p_corrected'] = p_corrected_c3[i]\n",
    "    result['significant_corrected'] = rejected_c3[i]\n",
    "    print(f\"{result['nuts_level']}: p_corrected = {p_corrected_c3[i]:.6f} {'*' if rejected_c3[i] else ''}\")\n",
    "\n",
    "interaction_matrix_c3 = df_batch.pivot_table(\n",
    "    values='score',\n",
    "    index='model_name',\n",
    "    columns='nuts_level',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "interaction_matrix_c3['country_minus_region'] = (\n",
    "    interaction_matrix_c3['country'] - interaction_matrix_c3['region']\n",
    ")\n",
    "print(\"\\n\\nMean scores (Model × NUTS):\")\n",
    "print(interaction_matrix_c3.round(3))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I4: MODEL × SPATIAL AGGREGATION LEVEL INTERACTION\n",
      "--------------------------------------------------------------------------------\n",
      "Model effect: H = 90.453, p = 0.000000\n",
      "NUTS level effect: H = 3.653, p = 0.055958\n",
      "Interaction: H = 1632.894, p = 0.000000\n",
      "Simple effects analysis:\n",
      "\n",
      "country: H = 53.150, p = 0.000000 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, Claude 3.5 Sonnet v2, GPT o3\n",
      "\n",
      "region: H = 42.932, p = 0.000011 *\n",
      "  Top 3 models: Claude 3.7 Sonnet, GPT o3, Claude 3.5 Sonnet v2\n",
      "\n",
      "\n",
      "FDR-corrected results:\n",
      "country: p_corrected = 0.000000 *\n",
      "region: p_corrected = 0.000011 *\n",
      "\n",
      "\n",
      "Mean scores (Model × NUTS):\n",
      "nuts_level            country  region  country_minus_region\n",
      "model_name                                                 \n",
      "Claude 3.5 Sonnet v2    3.690   3.464                 0.226\n",
      "Claude 3.7 Sonnet       4.097   3.774                 0.323\n",
      "DeepSeek-R1             2.838   2.765                 0.073\n",
      "GPT o3                  3.535   3.491                 0.044\n",
      "GPT-4o                  3.057   2.899                 0.158\n",
      "Gemini 1.5 Pro          3.533   3.042                 0.491\n",
      "Gemma 3                 2.994   2.959                 0.035\n",
      "Grok-3                  3.264   3.438                -0.174\n",
      "MiniMax-01              2.894   2.857                 0.036\n",
      "Mistral Large           3.416   3.240                 0.176\n",
      "Qwen2.5-Max             3.221   2.686                 0.535\n",
      "Sonar                   2.781   2.514                 0.267\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "4769dc6faafb4162",
   "metadata": {},
   "source": [
    "## 5. Clusters"
   ]
  },
  {
   "cell_type": "code",
   "id": "4343d43c248b2144",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:29:00.537685Z",
     "start_time": "2025-11-30T20:29:00.199390Z"
    }
   },
   "source": [
    "print(\"P1: CLUSTERS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_d3 = df_batch.copy()\n",
    "\n",
    "df_d3['difficulty_combo'] = (df_d3['graphical_complexity'] + '_' +\n",
    "                             df_d3['nuts_level'] + '_' +\n",
    "                             df_d3['map_source'] + '_' +\n",
    "                             df_d3['map_usage_type'])\n",
    "\n",
    "combo_counts = df_d3['difficulty_combo'].value_counts()\n",
    "\n",
    "valid_combos = combo_counts[combo_counts >= 10].index\n",
    "df_d3 = df_d3[df_d3['difficulty_combo'].isin(valid_combos)]\n",
    "\n",
    "profile_analysis = df_d3.groupby(['model_name', 'difficulty_combo'])['score'].agg([\n",
    "    'mean', 'std', 'count'\n",
    "]).unstack(fill_value=np.nan)\n",
    "\n",
    "# Cluster analysis of models based on difficulty profiles\n",
    "try:\n",
    "    # Prepare data for clustering\n",
    "    model_profiles = profile_analysis['mean'].fillna(profile_analysis['mean'].mean(axis=0))\n",
    "\n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    profiles_scaled = scaler.fit_transform(model_profiles)\n",
    "\n",
    "    # Determine optimal number of clusters (2-5)\n",
    "    silhouette_scores = {}\n",
    "    for n_clusters in range(2, min(6, len(model_profiles))):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(profiles_scaled)\n",
    "        silhouette_scores[n_clusters] = silhouette_score(profiles_scaled, cluster_labels)\n",
    "\n",
    "    optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
    "    print(f\"\\n\\nCluster Analysis:\")\n",
    "    print(f\"Silhouette scores for different k: {silhouette_scores}\")\n",
    "    print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "\n",
    "    # K-means clustering with optimal k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(profiles_scaled)\n",
    "\n",
    "    # Assign clusters to models\n",
    "    model_clusters = dict(zip(model_profiles.index, clusters))\n",
    "\n",
    "    print(f\"\\nModel cluster assignments (k={optimal_k}):\")\n",
    "    for cluster_id in range(optimal_k):\n",
    "        cluster_models = [m for m, c in model_clusters.items() if c == cluster_id]\n",
    "        print(f\"  Cluster {cluster_id}: {', '.join(cluster_models)}\")\n",
    "\n",
    "    # Characterize clusters by their performance patterns\n",
    "    cluster_characteristics = {}\n",
    "    for cluster_id in range(optimal_k):\n",
    "        cluster_models = [m for m, c in model_clusters.items() if c == cluster_id]\n",
    "        cluster_data = df_d3[df_d3['model_name'].isin(cluster_models)]\n",
    "\n",
    "        cluster_characteristics[cluster_id] = {\n",
    "            'mean_score': cluster_data['score'].mean(),\n",
    "            'std_score': cluster_data['score'].std(),\n",
    "            'best_on_low': cluster_data[cluster_data['graphical_complexity'] == 'low']['score'].mean(),\n",
    "            'best_on_high': cluster_data[cluster_data['graphical_complexity'] == 'high']['score'].mean(),\n",
    "            'models': cluster_models\n",
    "        }\n",
    "\n",
    "    print(\"\\nCluster characteristics:\")\n",
    "    for cluster_id, chars in cluster_characteristics.items():\n",
    "        print(f\"\\n  Cluster {cluster_id}:\")\n",
    "        print(f\"    Overall: M={chars['mean_score']:.3f}, SD={chars['std_score']:.3f}\")\n",
    "        print(f\"    Low graphically complex maps: M={chars['best_on_low']:.3f}\")\n",
    "        print(f\"    High graphically complex maps: M={chars['best_on_high']:.3f}\")\n",
    "\n",
    "    cluster_analysis = {\n",
    "        'model_clusters': model_clusters,\n",
    "        'optimal_k': optimal_k,\n",
    "        'silhouette_scores': silhouette_scores,\n",
    "        'cluster_characteristics': cluster_characteristics\n",
    "    }\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\n\\nSklearn not available - skipping cluster analysis\")\n",
    "    cluster_analysis = None\n",
    "\n",
    "# Statistical tests comparing clusters (not individual models)\n",
    "if cluster_analysis is not None:\n",
    "    print(\"\\n\\nStatistical tests comparing clusters per difficulty combination:\")\n",
    "    \n",
    "    # Add cluster assignment to dataframe\n",
    "    df_d3['cluster'] = df_d3['model_name'].map(cluster_analysis['model_clusters'])\n",
    "    \n",
    "    cluster_anova_results = {}\n",
    "    cluster_p_values = []\n",
    "    cluster_combo_names = []\n",
    "    \n",
    "    for combo in valid_combos:\n",
    "        combo_data = df_d3[df_d3['difficulty_combo'] == combo]\n",
    "        unique_clusters = combo_data['cluster'].dropna().unique()\n",
    "        \n",
    "        if len(unique_clusters) > 1:\n",
    "            # Kruskal-Wallis for comparing clusters\n",
    "            cluster_groups = [combo_data[combo_data['cluster'] == cluster_id]['score'].values\n",
    "                             for cluster_id in unique_clusters]\n",
    "            h_stat, p_val = kruskal(*cluster_groups)\n",
    "            \n",
    "            n = len(combo_data)\n",
    "            k = len(unique_clusters)\n",
    "            epsilon_sq = (h_stat - k + 1) / (n - k)\n",
    "            \n",
    "            cluster_anova_results[combo] = {\n",
    "                'test': 'Kruskal-Wallis',\n",
    "                'statistic': h_stat,\n",
    "                'p_value': p_val,\n",
    "                'effect_size': epsilon_sq,\n",
    "                'significant': p_val < 0.05,\n",
    "                'n_clusters': len(unique_clusters),\n",
    "                'n_obs': n\n",
    "            }\n",
    "            cluster_p_values.append(p_val)\n",
    "            cluster_combo_names.append(combo)\n",
    "    \n",
    "    print(\"\\nCombinations significant before FDR (trends):\")\n",
    "    for combo, result in cluster_anova_results.items():\n",
    "        if result['significant'] and not result.get('significant_corrected', False):\n",
    "            print(f\"  {combo}: H={result['statistic']:.2f}, p={result['p_value']:.4f}, ε²={result['effect_size']:.3f}\")\n",
    "    \n",
    "    # FDR correction across all combinations\n",
    "    if len(cluster_p_values) > 0:\n",
    "        rejected, p_corrected, _, _ = multipletests(cluster_p_values, alpha=0.05, method='fdr_bh')\n",
    "        \n",
    "        print(f\"\\nTotal combinations tested: {len(cluster_p_values)}\")\n",
    "        print(f\"Significant before correction: {sum([r['significant'] for r in cluster_anova_results.values()])}\")\n",
    "        print(f\"Significant after FDR correction: {sum(rejected)}\")\n",
    "        \n",
    "        # Update results with corrected p-values\n",
    "        for i, combo in enumerate(cluster_combo_names):\n",
    "            cluster_anova_results[combo]['p_corrected'] = p_corrected[i]\n",
    "            cluster_anova_results[combo]['significant_corrected'] = rejected[i]\n",
    "        \n",
    "        # Show significant results after correction\n",
    "        print(\"\\nSignificant differences between clusters after FDR correction:\")\n",
    "        sig_count = 0\n",
    "        for combo, result in cluster_anova_results.items():\n",
    "            if result.get('significant_corrected', False):\n",
    "                sig_count += 1\n",
    "                print(f\"\\n  {combo}:\")\n",
    "                print(f\"    H={result['statistic']:.3f}, p_corr={result['p_corrected']:.6f}, ε²={result['effect_size']:.3f}\")\n",
    "                # Show cluster means for this combination\n",
    "                combo_cluster_means = df_d3[df_d3['difficulty_combo'] == combo].groupby('cluster')['score'].mean().sort_values(ascending=False)\n",
    "                print(f\"    Cluster means:\")\n",
    "                for cluster_id, mean_score in combo_cluster_means.items():\n",
    "                    cluster_models = [m for m, c in cluster_analysis['model_clusters'].items() if c == cluster_id]\n",
    "                    print(f\"      Cluster {int(cluster_id)} ({', '.join(cluster_models)}): M={mean_score:.3f}\")\n",
    "        \n",
    "        if sig_count == 0:\n",
    "            print(\"  None - no significant differences between clusters after correction\")\n",
    "else:\n",
    "    print(\"\\n\\nCluster analysis not available - skipping statistical tests comparing clusters\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1: CLUSTERS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Cluster Analysis:\n",
      "Silhouette scores for different k: {2: 0.1617581229454909, 3: 0.1462751206484514, 4: 0.14309861286186268, 5: 0.1609622264512788}\n",
      "Optimal number of clusters: 2\n",
      "\n",
      "Model cluster assignments (k=2):\n",
      "  Cluster 0: DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar\n",
      "  Cluster 1: Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large\n",
      "\n",
      "Cluster characteristics:\n",
      "\n",
      "  Cluster 0:\n",
      "    Overall: M=2.872, SD=2.040\n",
      "    Low graphically complex maps: M=3.084\n",
      "    High graphically complex maps: M=2.660\n",
      "\n",
      "  Cluster 1:\n",
      "    Overall: M=3.499, SD=1.895\n",
      "    Low graphically complex maps: M=3.796\n",
      "    High graphically complex maps: M=3.201\n",
      "\n",
      "\n",
      "Statistical tests comparing clusters per difficulty combination:\n",
      "\n",
      "Combinations significant before FDR (trends):\n",
      "  low_region_statistical_office_analysis: H=14.10, p=0.0002, ε²=0.092\n",
      "  low_region_statistical_office_reading: H=10.38, p=0.0013, ε²=0.066\n",
      "  low_country_atlas_analysis: H=9.27, p=0.0023, ε²=0.118\n",
      "  high_country_atlas_reading: H=4.46, p=0.0347, ε²=0.049\n",
      "  high_country_atlas_analysis: H=7.42, p=0.0065, ε²=0.092\n",
      "  low_country_atlas_reading: H=9.49, p=0.0021, ε²=0.121\n",
      "  low_country_statistical_office_interpretation: H=4.40, p=0.0360, ε²=0.100\n",
      "\n",
      "Total combinations tested: 21\n",
      "Significant before correction: 7\n",
      "Significant after FDR correction: 5\n",
      "\n",
      "Significant differences between clusters after FDR correction:\n",
      "\n",
      "  low_region_statistical_office_analysis:\n",
      "    H=14.099, p_corr=0.003641, ε²=0.092\n",
      "    Cluster means:\n",
      "      Cluster 1 (Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large): M=3.405\n",
      "      Cluster 0 (DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar): M=2.362\n",
      "\n",
      "  low_region_statistical_office_reading:\n",
      "    H=10.377, p_corr=0.012232, ε²=0.066\n",
      "    Cluster means:\n",
      "      Cluster 1 (Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large): M=3.639\n",
      "      Cluster 0 (DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar): M=2.632\n",
      "\n",
      "  low_country_atlas_analysis:\n",
      "    H=9.270, p_corr=0.012232, ε²=0.118\n",
      "    Cluster means:\n",
      "      Cluster 1 (Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large): M=3.922\n",
      "      Cluster 0 (DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar): M=3.158\n",
      "\n",
      "  high_country_atlas_analysis:\n",
      "    H=7.415, p_corr=0.027163, ε²=0.092\n",
      "    Cluster means:\n",
      "      Cluster 1 (Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large): M=3.646\n",
      "      Cluster 0 (DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar): M=2.617\n",
      "\n",
      "  low_country_atlas_reading:\n",
      "    H=9.488, p_corr=0.012232, ε²=0.121\n",
      "    Cluster means:\n",
      "      Cluster 1 (Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large): M=4.336\n",
      "      Cluster 0 (DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar): M=2.886\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "f6d802ac69d6d09e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:29:00.581159Z",
     "start_time": "2025-11-30T20:29:00.577877Z"
    }
   },
   "source": [
    "# Check missing combinations\n",
    "df_batch[\n",
    "    (df_batch['graphical_complexity'] == 'high') &\n",
    "    (df_batch['nuts_level'] == 'region') &\n",
    "    (df_batch['map_source'] == 'statistical_office')\n",
    "].shape[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "880e1b5d8968a203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:29:06.631370Z",
     "start_time": "2025-11-30T20:29:06.622538Z"
    }
   },
   "source": [
    "if cluster_analysis is not None and 'model_clusters' in cluster_analysis:\n",
    "    cluster_assignments = cluster_analysis['model_clusters']\n",
    "    print(\"Using cluster assignments from P1 analysis\")\n",
    "    print(f\"Clusters: {cluster_analysis['optimal_k']}\")\n",
    "    for cluster_id in range(cluster_analysis['optimal_k']):\n",
    "        cluster_models = [m for m, c in cluster_assignments.items() if c == cluster_id]\n",
    "        print(f\"  Cluster {cluster_id}: {', '.join(cluster_models)}\")\n",
    "else:\n",
    "    cluster_assignments = {\n",
    "        'DeepSeek-R1': 0, 'GPT-4o': 0, 'Gemma 3': 0,\n",
    "        'MiniMax-01': 0, 'Qwen2.5-Max': 0, 'Sonar': 0,\n",
    "        'Claude 3.5 Sonnet v2': 1, 'Claude 3.7 Sonnet': 1,\n",
    "        'GPT o3': 1, 'Gemini 1.5 Pro': 1, 'Grok-3': 1, 'Mistral Large': 1\n",
    "    }\n",
    "    print(\"Using hardcoded cluster assignments (cluster_analysis not available)\")\n",
    "\n",
    "df_batch['cluster'] = df_batch['model_name'].map(cluster_assignments)\n",
    "\n",
    "categories = ['reading', 'analysis', 'interpretation']\n",
    "\n",
    "unique_clusters = sorted(df_batch['cluster'].dropna().unique())\n",
    "n_clusters = len(unique_clusters)\n",
    "\n",
    "print(f\"\\nAnalyzing {n_clusters} clusters\")\n",
    "\n",
    "cluster_data = {cat: {} for cat in categories}\n",
    "\n",
    "for cat in categories:\n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_data[cat][f'cluster_{int(cluster_id)}_mean'] = []\n",
    "        cluster_data[cat][f'cluster_{int(cluster_id)}_sem'] = []\n",
    "\n",
    "for cat in categories:\n",
    "    for cluster_id in unique_clusters:\n",
    "        c_data = df_batch[(df_batch['cluster'] == cluster_id) & (df_batch['map_usage_type'] == cat)]['score']\n",
    "        cluster_data[cat][f'cluster_{int(cluster_id)}_mean'].append(c_data.mean())\n",
    "        cluster_data[cat][f'cluster_{int(cluster_id)}_sem'].append(c_data.sem())\n",
    "\n",
    "df_dict = {'category': categories}\n",
    "for cluster_id in unique_clusters:\n",
    "    df_dict[f'cluster_{int(cluster_id)}_mean'] = [cluster_data[cat][f'cluster_{int(cluster_id)}_mean'][0] for cat in categories]\n",
    "    df_dict[f'cluster_{int(cluster_id)}_sem'] = [cluster_data[cat][f'cluster_{int(cluster_id)}_sem'][0] for cat in categories]\n",
    "\n",
    "cluster_performance_df = pd.DataFrame(df_dict)\n",
    "\n",
    "output_file = \"../../results/cluster_performance_summary.csv\"\n",
    "cluster_performance_df.to_csv(output_file, index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cluster assignments from P1 analysis\n",
      "Clusters: 2\n",
      "  Cluster 0: DeepSeek-R1, GPT-4o, Gemma 3, MiniMax-01, Qwen2.5-Max, Sonar\n",
      "  Cluster 1: Claude 3.5 Sonnet v2, Claude 3.7 Sonnet, GPT o3, Gemini 1.5 Pro, Grok-3, Mistral Large\n",
      "\n",
      "Analyzing 2 clusters\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "72817807b63068fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
